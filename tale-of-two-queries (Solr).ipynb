{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics & Prereqs (run once)\n",
    "\n",
    "If you don't already have the downloaded dependencies; if you don't have TheMovieDB data indexed run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET https://dl.bintray.com/o19s/RankyMcRankFace/com/o19s/RankyMcRankFace/0.1.1/RankyMcRankFace-0.1.1.jar\n",
      "GET http://es-learn-to-rank.labs.o19s.com/tmdb.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from ltr import download, index\n",
    "download.run(); index.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch to Solr\n",
    "By default examples run against elastic, the following snippet will change things to Solr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to Solr client_mode\n"
     ]
    }
   ],
   "source": [
    "from ltr import useSolr\n",
    "useSolr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Task: Optimizing \"Drama\" and \"Science Fiction\" queries\n",
    "\n",
    "In this example we have two user queries\n",
    "\n",
    "- Drama\n",
    "- Science Fiction\n",
    "\n",
    "And we want to train a model to return the best movies for these movies when a user types them into our search bar.\n",
    "\n",
    "We learn through analysis that searchers prefer newer science fiction, but older drama. Like a lot of search relevance problems, two queries need to be optimized in *different* directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Judgment List Generation\n",
    "\n",
    "To setup this example, we'll generate a judgment list that rewards new science fiction movies as more relevant; and old drama movies as relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating judgments for scifi & drama movies\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from ltr import date_genre_judgments\n",
    "judgments = date_genre_judgments.buildJudgments(judgmentsFile='data/genre_by_date_judgments.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this line to see the judgments\n",
    "# \n",
    "# for judgment in judgments:\n",
    "#    print(judgment.toRanklibFormat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection should be *easy!*\n",
    "\n",
    "Notice we have 4 proposed features, that seem like they should work! This should be a piece of cake...\n",
    "\n",
    "1. Release Year of a movie `release_year` - feature ID 1\n",
    "2. Is the movie Science Fiction `is_scifi` - feature ID 2\n",
    "3. Is the movie Drama `is_drama` - feature ID 3\n",
    "4. Does the search term match the genre field `is_genre_match` - feature ID 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted classic model: 200\n",
      "Deleted genre model: 200\n",
      "Deleted latest model: 200\n",
      "Delete _DEFAULT feature store: 200\n",
      "Delete genre feature store: 200\n",
      "Delete release feature store: 200\n",
      "Created genre feature store under tmdb: 200\n"
     ]
    }
   ],
   "source": [
    "config = [\n",
    "            {\n",
    "                \"store\": \"genre\", # Note: This overrides the _DEFAULT_ feature store location\n",
    "                \"name\" : \"release_year\",\n",
    "                \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "                \"params\" : {\n",
    "                  \"q\" : \"{!func}def(release_year,2000)\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"store\": \"genre\",\n",
    "                \"name\" : \"is_sci_fi\",\n",
    "                \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "                \"params\" : {\n",
    "                  \"q\" : \"genres:\\\"Science Fiction\\\"^=10.0\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"store\": \"genre\",\n",
    "                \"name\" : \"is_drama\",\n",
    "                \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "                \"params\" : {\n",
    "                  \"q\" : \"genres:\\\"Drama\\\"^=4.0\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"store\": \"genre\",\n",
    "                \"name\" : \"is_genre_match\",\n",
    "                \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "                \"params\" : {\n",
    "                  \"q\" : \"genres:\\\"${keywords}\\\"^=100.0\"\n",
    "                }\n",
    "            }\n",
    "]\n",
    "\n",
    "\n",
    "from ltr import setup_ltr\n",
    "setup_ltr.run(config=config, featureset='genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log from search engine -> to training set\n",
    "\n",
    "Each feature is a query to be scored against the judgment list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing 2 queries...\n",
      "REBUILDING TRAINING DATA for Science Fiction (0/2)\n",
      "REBUILDING TRAINING DATA for Drama (1/2)\n"
     ]
    }
   ],
   "source": [
    "from ltr import collectFeatures\n",
    "trainingSet = collectFeatures.trainingSetFromJudgments(judgmentInFile='data/genre_by_date_judgments.txt', \n",
    "                                                       trainingOutFile='data/genre_by_date_judgments_train.txt', \n",
    "                                                       featureSet='genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - Guaraneed Perfect Search Results!\n",
    "\n",
    "We'll train a LambdaMART model against this training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running java -jar data/RankyMcRankFace.jar -ranker 6 -metric2t NDCG@10 -tree 100 -train data/genre_by_date_judgments_train.txt -save data/genre_model.txt\n",
      "DONE\n",
      "Delete model genre: 200\n",
      "Created model genre: 201\n",
      "\n",
      "Impact of each feature on the model\n",
      "1 - 30989934.22204985\n",
      "2 - 2891683.161237409\n",
      "3 - 24.47444925009026\n",
      "4 - 0.0\n",
      "Perfect NDCG! 1.0\n"
     ]
    }
   ],
   "source": [
    "from ltr import train\n",
    "trainLog = train.run(trainingInFile='data/genre_by_date_judgments_train.txt',\n",
    "                     metric2t='NDCG@10',\n",
    "                     featureSet='genre',\n",
    "                     modelName='genre')\n",
    "\n",
    "print()\n",
    "print(\"Impact of each feature on the model\")\n",
    "for ftrId, impact in trainLog.impacts.items():\n",
    "    print(\"{} - {}\".format(ftrId, impact))\n",
    "    \n",
    "print(\"Perfect NDCG! {}\".format(trainLog.rounds[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But this search sucks!\n",
    "Try searches for \"Science Fiction\" and \"Drama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"size\": 5, \"query\": {\"sltr\": {\"params\": {\"keywords\": \"Science Fiction\"}, \"model\": \"genre\"}}}\n",
      "Why Him? \n",
      "10.492266 \n",
      "2016 \n",
      "['Comedy'] \n",
      "Ned, an overprotective dad, visits his daughter at Stanford where he meets his biggest nightmare: her well-meaning but socially awkward Silicon Valley billionaire boyfriend, Laird. A rivalry develops and Ned's panic level goes through the roof when he finds himself lost in this glamorous high-tech world and learns Laird is about to pop the question. \n",
      "---------------------------------------\n",
      "X-Men: Apocalypse \n",
      "10.492266 \n",
      "2016 \n",
      "['Science Fiction'] \n",
      "After the re-emergence of the world's first mutant, world-destroyer Apocalypse, the X-Men must unite to defeat his extinction level plan. \n",
      "---------------------------------------\n",
      "I Am Not a Serial Killer \n",
      "10.492266 \n",
      "2016 \n",
      "['Horror', 'Thriller'] \n",
      "Fifteen-year old John Cleaver is dangerous, and he knows it. He’s obsessed with serial killers, but really doesn’t want to become one. Terrible impulses constantly tempt him, so for his own sake, and the safety of those around, he lives by rigid rules to keep himself “good” and “normal”. However, when a real monster shows up in his town he has to let his dark side out in order to stop it – but without his rules to keep him in check, he might be more dangerous than the monster he’s trying to kill. \n",
      "---------------------------------------\n",
      "Tamara \n",
      "10.492266 \n",
      "2016 \n",
      "['Comedy'] \n",
      "Tamara, 15, complexed with her curves, decided its entry into second to get rid of the label of \"big\". To shut up the gossip, she made a bet with her best friend to go out with the first boy who pass the classroom door. No luck, the boy turns out to be Diego, the most handsome guy of high school. The bet is complicated for Tamara .... Between the dirty tricks of bitches of high school, a mother hen, boards \"drag\" his little sister, Tamara is a memorable year! \n",
      "---------------------------------------\n",
      "The Neon Demon \n",
      "10.492266 \n",
      "2016 \n",
      "['Thriller', 'Horror'] \n",
      "When aspiring model Jesse moves to Los Angeles, her youth and vitality are devoured by a group of beauty-obsessed women who will take any means necessary to get what she has. \n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ltr import search\n",
    "search.run(keywords=\"Science Fiction\", modelName=\"genre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Why didn't it work!?!? Training data\n",
    "\n",
    "1. Examine the training data, do we cover every example of a BAD result\n",
    "2. Examine the feature impacts, do any of the features the model uses even USE the keywords?\n",
    "\n",
    "### Ranklib only sees the data you give it, we don't have good enough coverage\n",
    "\n",
    "You need to have feature coverage, especially over negative examples. Most documents in the index are negative! \n",
    "\n",
    "One trick commonly used is to treat other queries positive results as this queries negative results. Indeed what we're missing here are negative examples for \"Science Fiction\" that are not science fiction movies. A glaring omission, we'll handle now... With the `autoNegate` flag, we'll add additional negative examples to the judgment list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating judgments for scifi & drama movies\n",
      "Done\n",
      "Recognizing 2 queries...\n",
      "REBUILDING TRAINING DATA for Science Fiction (0/2)\n",
      "REBUILDING TRAINING DATA for Drama (1/2)\n",
      "Running java -jar data/RankyMcRankFace.jar -ranker 6 -metric2t NDCG@10 -tree 100 -train data/genre_by_date_judgments_train.txt -save data/genre_model.txt\n",
      "DONE\n",
      "Delete model genre: 200\n",
      "Created model genre: 201\n",
      "\n",
      "Impact of each feature on the model\n",
      "4 - 802616758.725657\n",
      "1 - 89257217.35776828\n",
      "3 - 1573733.5830246205\n",
      "2 - 1.953984578809708e-20\n",
      "Perfect NDCG! 1.0\n"
     ]
    }
   ],
   "source": [
    "from ltr import date_genre_judgments, collectFeatures\n",
    "date_genre_judgments.buildJudgments(judgmentsFile='data/genre_by_date_judgments.txt',\n",
    "                                    autoNegate=True)\n",
    "\n",
    "collectFeatures.trainingSetFromJudgments(judgmentInFile='data/genre_by_date_judgments.txt', \n",
    "                                         trainingOutFile='data/genre_by_date_judgments_train.txt', \n",
    "                                         featureSet='genre')\n",
    "\n",
    "from ltr import train\n",
    "trainLog = train.run(trainingInFile='data/genre_by_date_judgments_train.txt',\n",
    "                     metric2t='NDCG@10',\n",
    "                     featureSet='genre',\n",
    "                     modelName='genre')\n",
    "\n",
    "print()\n",
    "print(\"Impact of each feature on the model\")\n",
    "for ftrId, impact in trainLog.impacts.items():\n",
    "    print(\"{} - {}\".format(ftrId, impact))\n",
    "    \n",
    "print(\"Perfect NDCG! {}\".format(trainLog.rounds[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try those queries...\n",
    "\n",
    "Replace keywords below with 'science fiction' or 'drama' and see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"size\": 5, \"query\": {\"sltr\": {\"params\": {\"keywords\": \"Science Fiction\"}, \"model\": \"genre\"}}}\n",
      "X-Men: Apocalypse \n",
      "10.714813 \n",
      "2016 \n",
      "['Science Fiction'] \n",
      "After the re-emergence of the world's first mutant, world-destroyer Apocalypse, the X-Men must unite to defeat his extinction level plan. \n",
      "---------------------------------------\n",
      "Spectral \n",
      "10.714813 \n",
      "2016 \n",
      "['Thriller', 'Action', 'Science Fiction'] \n",
      "A special-ops team is dispatched to fight supernatural beings that have taken over a European city. \n",
      "---------------------------------------\n",
      "Transformers: The Last Knight \n",
      "10.714813 \n",
      "2017 \n",
      "['Action', 'Science Fiction', 'Thriller', 'Adventure'] \n",
      "Autobots and Decepticons are at war, with humans on the sidelines. Optimus Prime is gone. The key to saving our future lies buried in the secrets of the past, in the hidden history of Transformers on Earth. \n",
      "---------------------------------------\n",
      "Life \n",
      "10.714813 \n",
      "2017 \n",
      "['Horror', 'Science Fiction', 'Thriller'] \n",
      "The six-member crew of the International Space Station is tasked with studying a sample from Mars that may be the first proof of extra-terrestrial life, which proves more intelligent than ever expected. \n",
      "---------------------------------------\n",
      "Monster Trucks \n",
      "10.714813 \n",
      "2016 \n",
      "['Action', 'Comedy', 'Science Fiction'] \n",
      "Looking for any way to get away from the life and town he was born into, Tripp, a high school senior, builds a Monster Truck from bits and pieces of scrapped cars. After an accident at a nearby oil-drilling site displaces a strange and subterranean creature with a taste and a talent for speed, Tripp may have just found the key to getting out of town and a most unlikely friend. \n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ltr import search\n",
    "search.run(keywords=\"Science Fiction\", modelName=\"genre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next problem\n",
    "\n",
    "- Overfit to these two examples\n",
    "- We need many more queries, covering more use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
