{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "articles = []\n",
    "\n",
    "with open('data/blog.jsonl') as f:\n",
    "    for line in f:\n",
    "        blog = json.loads(line)\n",
    "        blog['id'] = blog['url']\n",
    "        articles.append(blog)\n",
    "\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.client import ElasticClient\n",
    "client=ElasticClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconfig from disk...\n",
      "Deleted index blog [Status: 200]\n",
      "Created index blog [Status: 200]\n",
      "Reindexing...\n"
     ]
    },
    {
     "ename": "BulkIndexError",
     "evalue": "('100 document(s) failed to index.', [{'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/06/29/rolling-out-new-blog/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Rolling out new blog', 'url': 'https://opensourceconnections.com/blog/2006/06/29/rolling-out-new-blog/', 'author': 'eric-pugh', 'content': ' Weve discussed setting up a company-wide blog for a while now, and today I decided to just go ahead and do it. We looked at some of the powerful ones, but realized that simplicity is all we need, and therefore SimpleLog is an obvious answer! \\n\\n Look for postings about what is going on at OpenSource Connections. \\n', 'excerpt': ' Weve discussed setting up a company-wide blog for a while now, and today I decided to just go ahead and do it. We looked at some of the powerful ones, but realized that simplicity is all we need, and therefore SimpleLog is an obvious answer! Look for postings about what is going on at OpenSource […] \\n', 'post_date': '2006-06-29T00:00:00-0400', 'categories': ['blog', 'News'], 'id': 'https://opensourceconnections.com/blog/2006/06/29/rolling-out-new-blog/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/06/30/preparation-for-oscon/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Preparation for OSCON', 'url': 'https://opensourceconnections.com/blog/2006/06/30/preparation-for-oscon/', 'author': 'jason-hull', 'content': ' While we did not think that we could sign up, show up, and generate business, there are many separate factors that we must consider to make sure that our first big exhibition is a success. \\n\\n Media: As a company that has always focused on word-of-mouth referrals and marketing for our business, we have not developed a robust set of marketing materials. Thus, we needed to come up with our exhibit backdrop, fliers, press releases, and determine what it was that we were going to display. If you can afford it, it is worthwhile to use a couple of different resources. First, a graphic designer. Find someone who has designed for exhibits before and who has a good understanding of your target audience. If your reaction to this is “what is my target audience,” then you have more work to do before you can get to this stage. Second, a copy writer. If you cannot capture the essence of what you do and get the reader of your materials to want to engage in further conversations in 20 words or less, rewrite it. Most technical people do not have the language savvy and skills to do this; a few hours with a professional copywriter will help you. We have used Proofrock Copy and been very happy with their results. \\n\\n Message: You cant be everything to everyone. Even if you offer several packages, trying to sell all of them will likely result in failing to close on potential deals because of lack of focus. We have chosen to focus on two main areas: strategic engagements and Agile Development training. The strategic engagements are designed for our clients to develop the appropriate roadmap for getting their IT systems to the point to where they can provide the information that decision makers need to drive business forward. Agile Development training is, for the most part, self-explanatory. Its still more of a buzzword than a practice, and many teams have tried and failed to incorporate Agile because of lack of appropriate training and methodologies. While we have other offerings, such as laboratory information management systems and content management systems, we would rather focus on 200 of the 3,000 attendees than cast a wide net and hope to snag a random hit. \\n\\n Extras: Just signing up for an exhibit and renting/buying your exhibit standup materials doesnt cover everything. Dont forget that youre going to have to rent carpet, trash cans, cleaning crew, podia, tables, chairs, etc. If youve never done an exhibition before, network with people who have to see what their costs were. If you cant find someone who has, then take your estimates and double them. Additionally, dont spend yourself down to nearly nothing to exhibit. There will be follow-up work and engagements (one hopes) after the convention, and you will need the capital to fund your follow-up sales efforts and initial engagement work. \\n\\n Were going to have some exciting things at OSCON. We look forward to meeting all of you there! \\n\\n', 'excerpt': ' While we did not think that we could sign up, show up, and generate business, there are many separate factors that we must consider to make sure that our first big exhibition is a success. Media: As a company that has always focused on word-of-mouth referrals and marketing for our business, we have not developed […] \\n', 'post_date': '2006-06-30T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/06/30/preparation-for-oscon/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/12/trying-to-explain-what-open-source-is/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Trying to explain what \"Open Source\" is?', 'url': 'https://opensourceconnections.com/blog/2006/07/12/trying-to-explain-what-open-source-is/', 'author': 'jason-hull', 'content': ' Here are a couple articles related to both open source software, as well as the culture surrounding the open source world. \\n\\n Open Source in the Public Interest \\n\\n An Overview of Open Source License by American Bar Association \\n\\n Open source software: A short interpretive history \\n\\n The Cathedral and the Bazaar \\n\\n', 'excerpt': ' Here are a couple articles related to both open source software, as well as the culture surrounding the open source world. Open Source in the Public Interest An Overview of Open Source License by American Bar Association Open source software: A short interpretive history The Cathedral and the Bazaar \\n', 'post_date': '2006-07-12T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/07/12/trying-to-explain-what-open-source-is/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/12/what-are-the-costs-and-benefits-of-integration/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'What are the costs and benefits of integration?', 'url': 'https://opensourceconnections.com/blog/2006/07/12/what-are-the-costs-and-benefits-of-integration/', 'author': 'jason-hull', 'content': ' We are working to foster a relationship with a potential client. They have clients who use tools which do not integrate with each other, causing these clients to enter in information manually. \\n\\n Some of these companies have a relatively low price point that they are willing to pay for the integration of the tools that they use. However, by not looking at the long-term opportunity costs of not using the integration tools, these companies are understating costs of inaction. \\n\\n Lets assume that failure to integrate the tools means that once a month, someone has to enter in 75 entries into two different databases rather than one. Furthermore, lets assume that each set of entries takes 2 minutes, meaning that 2.5 hours per month is spent in duplicate entry. This is 30 hours a year that someone is spending entering in duplicate information. Finally, lets assume that the fully-loaded cost of this employee is $40/hour. Thats a $1,200 cost/year that the company has which it does not need. \\n\\n Are there examples in your company where manual processes are costing time, and ultimately, money? Are you costing your company more money in the long run by not investing to fix the process issues? \\n', 'excerpt': ' We are working to foster a relationship with a potential client. They have clients who use tools which do not integrate with each other, causing these clients to enter in information manually. Some of these companies have a relatively low price point that they are willing to pay for the integration of the tools that […] \\n', 'post_date': '2006-07-12T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/07/12/what-are-the-costs-and-benefits-of-integration/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/19/running-with-scissors-overriding-latest_revision-svn-check-in-capistrano/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Running with scissors: overriding latest_revision SVN check in Capistrano', 'url': 'https://opensourceconnections.com/blog/2006/07/19/running-with-scissors-overriding-latest_revision-svn-check-in-capistrano/', 'author': 'eric-pugh', 'content': ' Ruby as a language sometimes feels like you are running with scissors. Its great to get from A to B quickly with your scissors, but there is a chance you may trip and impale yourself! \\n\\n Today I was struggling with overriding what revision Capistrano uses when checking code out of Subversion as a hack to get around the lack of support for svn+ssh:// connectivity. Be default Capistrano makes a check from your local box for the latest revision, and then uses that to check out content on the remote box. However I wanted to skip the check from my local box and just pass in “HEAD” as the revision name. \\n\\n My first solution was just to hack up the Subversion class and hard code the @latest_revision to be “HEAD”. But I realized what an ugly solution tweaking my gem was! \\n\\n After banging my head a bit, I realized that Ruby is a dynamic language, and I can do all sorts of magic that maybe I shouldnt be doing. It was time to use instance_variable_set! \\n\\n I added :before_update_code that allows me to manually set the revision in my deploy.rb and therefore bypass the check: \\n\\n task :before_update_code, :roles =&gt; [:web, :app] do\\n  revision = \"HEAD\"\\n  puts \"Revision to be deployed is #{revision}\"\\n  source.instance_variable_set(\"@latest_revision\",revision)\\nend\\n \\n\\n It does kind of make me wonder if all those OOP rules about encapsulation no longer apply! \\n', 'excerpt': ' Ruby as a language sometimes feels like you are running with scissors. Its great to get from A to B quickly with your scissors, but there is a chance you may trip and impale yourself! Today I was struggling with overriding what revision Capistrano uses when checking code out of Subversion as a hack to […] \\n', 'post_date': '2006-07-19T00:00:00-0400', 'categories': ['blog', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2006/07/19/running-with-scissors-overriding-latest_revision-svn-check-in-capistrano/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/25/we-made-it-to-oscon/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'We made it to OSCON!', 'url': 'https://opensourceconnections.com/blog/2006/07/25/we-made-it-to-oscon/', 'author': 'eric-pugh', 'content': ' After 8 hours of travel, we arrived into PDX last night at 10:50 PM. Headed down to the luggage claim and saw our pop up booth packed in a large plastic shipping case, codenamed “Napolean”, come out.. Well, actually, what first came out was a red ratchet strap that theorectically was holding the heavy plastic case together! You can imagine the feeling of panic I felt contemplating two days of exhibiting with no booth! \\n\\n  \\n\\n Fortunantly 5 minutes later “Napolean” showed up, sans ratchet strap. \\n\\n', 'excerpt': ' After 8 hours of travel, we arrived into PDX last night at 10:50 PM. Headed down to the luggage claim and saw our pop up booth packed in a large plastic shipping case, codenamed “Napolean”, come out.. Well, actually, what first came out was a red ratchet strap that theorectically was holding the heavy plastic […] \\n', 'post_date': '2006-07-25T00:00:00-0400', 'categories': ['blog', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2006/07/25/we-made-it-to-oscon/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/27/oscon-1st-day-exhibit-thoughts/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'OSCON 1st day exhibit thoughts', 'url': 'https://opensourceconnections.com/blog/2006/07/27/oscon-1st-day-exhibit-thoughts/', 'author': 'jason-hull', 'content': ' The biggest thing that surprised me was the preponderance of Perl developers at the convention. For a “dying language,” Perl seems to be pretty alive and well. \\n\\n I also expected to see a lot of people who wanted to learn more about Rails and Ruby (is this redundant or what?). Maybe they were all eyeball deep in training. \\n\\n We did build a 5 minute Rails app to show the winners of our drawing for the book “Practice of an Agile Developer” by Andy Hunt. Little did we know that wed have the pleasure of being two booths down from Andy, so its been fun dragging our winners down to Andys booth to have him autograph the book. I wonder if Ill see signed books popping up on eBay. We want 10% of the profits! :) \\n\\n We did hire two promotional models and a licensed massage therapist to help out at our booth. First off, all three of them are phenomenal! Kudos to Kelsey and Susan (our direct marketing consultants) and Pamlin (our LMT)! \\n\\n I had expected the flow of people through them to be much different than it wound up being. I thought that we could send Kelsey and Susan out on the floor and stage them at the exits to sessions and have them find people and drag them over to our booth. What they quickly ascertained was that they had no connection to people (after all, if youre looking to exit the session as quickly as possible to either go smoke or connect to the Net, youre not going to want to talk to anyone). From a conventioneers point of view, they were just another set of people to walk by en route to somewhere else. So, they came back, hung around the booth, and did a great job of engaging people and bringing them in to talk to us. Also, they were both incredibly quick studies and can now give our elevator speech better than we can! \\n\\n We also expected Pamlin to be a hit and for a line to go around the corner for her services. What we have discovered is that people are pretty reticent to have their feet rubbed. If we come back next year, were going to have her bring a backrub chair instead of the footrub recliner. However, Pamlin is also very bright and engaging, and while I doubt that she did massage services for more than 6 people (outside of the OSC team), I doubt there was more than a total of 30 minutes out of the 600 that the exhibit was open that she wasnt talking to someone. \\n\\n If youre ever going to exhibit in Portland (not for OSCON) and want to hire people who can help you out with your booth, then drop me a line and Ill put you in contact with them. One caveat: you cant have them for OSCON 2007. Theyre ours! \\n\\n We also conducted a vendor presentation yesterday, which well put online shortly. While I initially felt pretty unahppy about the results, after talking to Eric, I realized that it served its purpose. It was free advertising. Never turn down a chance to give a 20 minute spiel about what you do, even if the audience is pretty small. You never know whos going to hear the few key phrases that they need to hear to perk their ears and ask a few more questions. \\n\\n Finally, the two conversational topics that I discussed the most are Agile Development and business process analysis. Theres definitely a hunger for good information and training about Agile Development. Additionally, in my discussions, I think that I can safely say that, in general, IT managers have trouble convincing their business counterparts of the business case for changes in software systems. Knowing that a change is necessary is a first step, but being able to frame the discussion in the terms that the business managers understand is critical. A part of me is a little disappointed that the range of discussions wasnt a little wider, as I feel like our real strength is in our distributed development capabilities, namely our ability to take on projects and ramp up and integrate extremely capable teams in a rapid timeframe, but you go where the market demands, and it seems that business process analysis and Agile Development are the main pain points that Im seeing, at least of the attendees Ive spoken with. \\n', 'excerpt': ' The biggest thing that surprised me was the preponderance of Perl developers at the convention. For a “dying language,” Perl seems to be pretty alive and well. I also expected to see a lot of people who wanted to learn more about Rails and Ruby (is this redundant or what?). Maybe they were all eyeball […] \\n', 'post_date': '2006-07-27T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/07/27/oscon-1st-day-exhibit-thoughts/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/29/decompressing-from-oscon/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Decompressing from OSCON', 'url': 'https://opensourceconnections.com/blog/2006/07/29/decompressing-from-oscon/', 'author': 'eric-pugh', 'content': ' Im sitting at TopPot in Seattle slowly digesting all the things that we did and learned at OSCON! Ive got a stack of contacts to follow up with, and feel very invigorated about the state of the open source world. \\n\\n Our BoF: Scrum War Stories was very well recieved, with 14 particpants and some at times heated discussion! Exactly what you want at a BoF! We helped solve some job difficulties, learned about some new books, and talked about Scrum in the real world. As I promised, Ill have notes posted later this week. I also mentioned our Rugby addon for Scrum project tracking with Trac. I took advantage of Googles Project Host being unveiled at OSCON and did a quick landgrab for “rugby”. Ill have SVN updated over the next couple of days on our new site at http://code.google.com/p/rugby/. \\n\\n Ill also post the after action review of OSCON this week. \\n', 'excerpt': ' Im sitting at TopPot in Seattle slowly digesting all the things that we did and learned at OSCON! Ive got a stack of contacts to follow up with, and feel very invigorated about the state of the open source world. Our BoF: Scrum War Stories was very well recieved, with 14 particpants and some at […] \\n', 'post_date': '2006-07-29T00:00:00-0400', 'categories': ['blog', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2006/07/29/decompressing-from-oscon/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/01/battle-of-the-scaffolds-aug-9th/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Battle of the Scaffolds Aug 9th', 'url': 'https://opensourceconnections.com/blog/2006/08/01/battle-of-the-scaffolds-aug-9th/', 'author': 'eric-pugh', 'content': ' Join Eric Pugh of OpenSource Connections August 9th at RubyJam as he pits two competing scaffolds designed for quickly ripping out a CRUD interface: AjaxScaffold and Streamlined. Learn the strengths and weaknesses of each. See the design choices the developers took to minimize the code intrusion of their tools into your application. See how much fun tabluar editing of data is when you have Ajax goodness! \\n\\n 6:30 PM, Room 160 at Darden Business School \\n\\n', 'excerpt': ' Join Eric Pugh of OpenSource Connections August 9th at RubyJam as he pits two competing scaffolds designed for quickly ripping out a CRUD interface: AjaxScaffold and Streamlined. Learn the strengths and weaknesses of each. See the design choices the developers took to minimize the code intrusion of their tools into your application. See how much […] \\n', 'post_date': '2006-08-01T00:00:00-0400', 'categories': ['blog', 'Code', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2006/08/01/battle-of-the-scaffolds-aug-9th/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/02/scrum-war-stories-recap/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Scrum War Stories Recap', 'url': 'https://opensourceconnections.com/blog/2006/08/02/scrum-war-stories-recap/', 'author': 'eric-pugh', 'content': ' As I promised at the close of our BoF: Scrum War Stories, I would write up a couple of the notes I made during our discussions. They arent in any specific order, and I only have some of the names of people who spoke written down Unfortunately those name tags at OSCON seemed to really want to flip around! If I ever host a conference, I am putting the names of people on both sides of the badge. \\n\\n Before I begin I want to thank everybody who showed up! 14 people was a very healthy number of folks. Enough so that we can generate some real ideas, with people who were just learning about it up to people who are certified ScrumMasters and have been using it in the real world. \\n\\n Mauro Talevi led off with a quick introduction on Scrum. One of the key points he made is that while processes like XP or RUP are “prescriptive”, Scrum is “adaptive”. XP says: “If you take my medicine faithfully and fully, then things will be better”, whereas Scrum says: “Lets honestly try some principles that are very common sense and see if we can change peoples behavior”. I really appreciated that distinction. Medicine versus Therapy. \\n\\n He also pointed out that Scrum is a process for developers, but first and foremost is a method of communicating with the rest of the business. And that because it extends outside of the development team, what seems simple is actually incredibly hard to implement. And that lip service to Scrum processes doesnt work. \\n\\n We then chatted a lot about Jasons situation where he has internal clients at a university. He wondered if you could use Scrum with internal clients. He wants to use it, has been championing it, and it hasnt gone anywhere. After the group asked some more questions about his situation, in many ways Scrum was not a fit. In his situation, the business folks were not onboard with Scrum, and his attempts to gather requirements was failing. The advice was that: \\n\\n \\n   another job was better! A couple folks with university backgrounds had experience frustrations of the type that Jason was feeling. \\n   on a more constructive side, the group said he should just get enough requirements to start a prototype, and once the clients had something to look at, the rest of the requirements would become solid. Even if the original prototype was tossed out. \\n   Use interview process to elicit requirements. Someone mentioned a tool called DENIM (Denim?) for drawing simple GUIS for use in interviews. Another mention was made of using storyboard and tool that helps with that. Search Google for “XUL + Berlin”. \\n   Scrum doesnt work without a team. If you are a developer of one then you cant do Scrum. I showed how I organize my day to day life with a nice notebook that I scribble in. A notebook with “what I have to do” is not a stand up meeting! \\n \\n\\n The conversation drifted away from Scrum to requirements gathering for a while. The question came up, how do you take a 30 month project and figure out what you can do in 4 months of work. The answer seemed to be “ask the client, they know at some gut level what the minimum is”, or cancel the project completely, and solve the problem in a different, not IT way. \\n\\n Aaron Farr then brought the topic back to Scrum as he said he thinks Scrum works even better with internal customers then external clients. A consulting firm with external clients has to justify every billable hours, so there is more of a framework and focus on managing scope and deliverables. Internal customers rarely are directly paying the developers, so they feel more leeway to change things around. This feeds directly back to the usefulness of Scrum. He also pointed out that you should let “Management be management”. They set the budget and tasking. You as a developer dont. All you set is time. \\n\\n The improvement in your team, as measured by your Velocity was brought up. Was it a factor of using Scrum? Was it just the team becoming better developers? Or is it that over time you become more familiar with your domain? Some suggestions was that the additional stability provided to your team by Scrum leads to better developers (less stress) and the interactive approach helps build knowledge of the domain. \\n\\n A scary question was asked: “Can you lose your job?” Mauro replied yes, and explained that someone he knew in Scrum circles had “lost” their job because their job was to introduce Scrum, and while management had asked for Scrum, they were not willing to change their processes. Lip service was what they were looking for, and the ScrumMaster they brought in wanted to make actual behavior changes in how software development was handled. It was a sobering anecdote that ScrumMasters are often “Change Agents” which may ruffle a lot of feathers. And without management support, that can be a disaster. \\n\\n “Slack” by Tom DeMarco was mentioned as a good book for people interested in Scrum. I hadnt heard of it, but added it to my Amazon wish-list! \\n\\n Lastly, we talked about tools. Tools, always a favorite for software developers! Someone brought up a web based wiki/spreadsheet, and after a bit of confusion we realized it was Dan Bricklins project. Dan and I gave presentations at a symposium once, and I learned a huge amount from him! I also mentioned “Rugby”, which is almost ready for public consumption. Ill be posting more fully on it later, but it will be available from http://code.google.com/p/rugby/ . There is a Google Group where I will be posting more information. \\n\\n I was very gratified at the turnout for my BoF, and am looking forward to hosting more at future conferences! If you have any questions, want to talk more about Scrum, please feel free to contact me at epugh@opensourceconnections.com . Thanks to everyone who showed up! \\n\\n', 'excerpt': ' As I promised at the close of our BoF: Scrum War Stories, I would write up a couple of the notes I made during our discussions. They arent in any specific order, and I only have some of the names of people who spoke written down Unfortunately those name tags at OSCON seemed to really […] \\n', 'post_date': '2006-08-02T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2006/08/02/scrum-war-stories-recap/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/03/reflections-on-oscon/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Reflections on OSCON', 'url': 'https://opensourceconnections.com/blog/2006/08/03/reflections-on-oscon/', 'author': 'jason-hull', 'content': ' It appears to me that, after having talked to countless people at OSCON, there is still a significant disconnect between IT and the rest of the business. \\n\\n I say this because IT representatives had a pretty good idea of what they wanted to do and why. However, when it came to getting someone to pony up the coin to make the changes necessary to move forward, IT representatives, for the most part, were at a loss for how to shake out the money tree. \\n\\n The biggest reason is that business views IT as a cost center, and so spending on IT needs to be minimized as much as possible. When I asked what the criteria for making decisions was, the inevitable answer was money. The bottom line loomed so large that it drowned out any other competing interest. This is short-sighted and reflective of a company trying to make this quarters numbers without looking at how its going to make next quarters numbers, much less next years numbers. \\n\\n To me, this is analogous to building a house out of particle board. Sure, once the house is done, the total cost of building the house will be extremely low. It will also be a cheap house and will serve no habitable purpose. \\n\\n Even for companies that are willing to spend to improve their IT systems, often, they did not know the business purpose they were trying to achieve. They did not know where the weaknesses in process were that the appropriate application of technology could improve. Furthermore, they did not consider total cost of ownership rather than up front price. I liken this to putting caulk around a leak. It might work. But it might also be only a temporary fix and cost more in the long run. Only good solid analysis of the problem and true understanding of a set of requirements can determine if what youre seeking is truly the answer that you want. \\n\\n Finally, there is an appetite for knowledge about Agile Development, but seemingly few resources available. We gave away Andy Hunts book Practices of an Agile Developer, that can help teams and developers get started down the path. \\n\\n All in all, the convention was time well spent. We met a lot of people and got in touch with what was going on in the open source community. We will definitely plan on being at OSCON 2007, and we will make sure we leave enough time to do more discovery of the Columbia River gorge! \\n\\n', 'excerpt': ' It appears to me that, after having talked to countless people at OSCON, there is still a significant disconnect between IT and the rest of the business. I say this because IT representatives had a pretty good idea of what they wanted to do and why. However, when it came to getting someone to pony […] \\n', 'post_date': '2006-08-03T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/08/03/reflections-on-oscon/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/04/eric-pugh-to-present-at-vptc-2007-trends-seminar/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric Pugh To Present At VPTC 2007 Trends Seminar', 'url': 'https://opensourceconnections.com/blog/2006/08/04/eric-pugh-to-present-at-vptc-2007-trends-seminar/', 'author': 'jason-hull', 'content': ' Eric Pugh will be a guest panelist at the September 2006 VPTC meeting. He will be covering trends in technology that we can expect to see in 2007. More details to follow. \\n', 'excerpt': ' Eric Pugh will be a guest panelist at the September 2006 VPTC meeting. He will be covering trends in technology that we can expect to see in 2007. More details to follow. \\n', 'post_date': '2006-08-04T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2006/08/04/eric-pugh-to-present-at-vptc-2007-trends-seminar/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/04/why-open-source-works/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Why Open Source Works', 'url': 'https://opensourceconnections.com/blog/2006/08/04/why-open-source-works/', 'author': 'eric-pugh', 'content': ' Last night I experienced again why open source works. I was beating my head getting sorting to work in Ruport (Ruby Reporting Package), and instead of opening a support ticket I posted to the mailing list: \\n\\n http://lists.stonecode.org/pipermail/ruport-stonecode.org/2006-August/thread.html#227 \\n\\n `Nuff said. \\n', 'excerpt': ' Last night I experienced again why open source works. I was beating my head getting sorting to work in Ruport (Ruby Reporting Package), and instead of opening a support ticket I posted to the mailing list: http://lists.stonecode.org/pipermail/ruport-stonecode.org/2006-August/thread.html#227 `Nuff said. \\n', 'post_date': '2006-08-04T00:00:00-0400', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2006/08/04/why-open-source-works/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/09/mandatory-upgrade-of-rails-115/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Mandatory Upgrade of Rails 1.1.5!', 'url': 'https://opensourceconnections.com/blog/2006/08/09/mandatory-upgrade-of-rails-115/', 'author': 'eric-pugh', 'content': ' Saw a post on Riding Rails about an extremely dangerous security hole in Rails. Read the full warning from DHH here. \\n\\n For me to update the software for this blog meant: \\n\\n sudo gem update rails\\ncap restart\\n \\n\\n See you at RubyJam tonight! \\n\\n', 'excerpt': ' Saw a post on Riding Rails about an extremely dangerous security hole in Rails. Read the full warning from DHH here. For me to update the software for this blog meant: sudo gem update rails cap restart See you at RubyJam tonight! \\n', 'post_date': '2006-08-09T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2006/08/09/mandatory-upgrade-of-rails-115/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/15/osc-wins-3rd-place-at-ruportday/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'OSC wins 3rd Place at RuportDay', 'url': 'https://opensourceconnections.com/blog/2006/08/15/osc-wins-3rd-place-at-ruportday/', 'author': 'eric-pugh', 'content': ' Okay, so its not the SuperBowl, but I won 3rd place during the 2006 Ruport Day! \\n\\n Ruport Day was an attempt to pull together a bunch of folks and hammer out new features, documentation, and tutorials, with cash prizes for 1st through 3rd places. \\n\\n The wrap-up email is here. \\n\\n I joined the crew around 8:30 PM, and put in a couple hours, learning enough about Ruport to contribute some ideas, read a lot of Ruby source, and put in a small recipe. \\n\\n Ruport is the first project that Ive contributed to since doing development in Ruby, and they are a great group, very supportive. \\n\\n', 'excerpt': ' Okay, so its not the SuperBowl, but I won 3rd place during the 2006 Ruport Day! Ruport Day was an attempt to pull together a bunch of folks and hammer out new features, documentation, and tutorials, with cash prizes for 1st through 3rd places. The wrap-up email is here. I joined the crew around 8:30 […] \\n', 'post_date': '2006-08-15T00:00:00-0400', 'categories': ['blog', 'Community', 'News'], 'id': 'https://opensourceconnections.com/blog/2006/08/15/osc-wins-3rd-place-at-ruportday/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/16/social-networking-20-a-blessing-and-a-curse/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Social Networking 2.0, A Blessing and a Curse', 'url': 'https://opensourceconnections.com/blog/2006/08/16/social-networking-20-a-blessing-and-a-curse/', 'author': 'jason-hull', 'content': ' When I was in the Army, a useful skill that I had was knowing who could do what and being a favor broker. Managing a much larger network is vastly different. \\n\\n Gartner recently identified emerging technologies, including the Web 2.0s social networking capabilities. The network is there. The ability to readily both data mine and qualify the network is not. \\n\\n If you go to myspace or flickr or blogger, you can find a maze of people who have posted random information. As one of the Technorati people says, “50 million blogs…some of them have to be good.” \\n\\n Yes, some of them have to be good. But how do you know? \\n\\n First, it helps to know what the tools of Web 2.0 are. Tim OReilly gives a great overview here. \\n\\n The crux of the value of Web 2.0 is in information aggregation. Most any piece of information that someone could seek is available on the web, but determining where that information is, and, once found, the value of the information remains a challenge. The value creation of the web beyond mere presentation of information (funny how mere presentation of information is accepted; yet, 10 years ago, would have been a taboo thought) is in aggregation and filtering. Here is where folksonomy (defined here:) helps out. \\n\\n The basic premise behind folksonomy is the same behind market theory. Over time, collective intelligence is better than singular intelligence. So, by using tagging and then community acceptance, information is found, organized, and voted on. It is the Survivor voting off ceremony of the Internet. Good information is tagged, approved, and disseminated. Bad information gets relegated to some dark corner of the Internet or gets sent to your inbox as spam. \\n\\n However, the data mining capabilities are still in infancy. A business example that we face illustrates this point. When we are ready to take on more developers into our team, we will use a variety of methods to find those people. Craigslist, Linked In, and Sourceforge will be three of our venues, along with others. However, only directly will we be able to use a community vote to determine who the “winner” is. Resumes do not have bookmark counts like they do in del.icio.us. Code does not have a beauty contest. \\n\\n In the end, we are responsible for the decisions we make. We will still have to review code and conduct interviews ourselves. After all, even if there were a social network for resumes and candidates, we are the ones spending the money to hire, and we can only look in the mirror when we spend wisely or poorly. \\n\\n', 'excerpt': ' When I was in the Army, a useful skill that I had was knowing who could do what and being a favor broker. Managing a much larger network is vastly different. Gartner recently identified emerging technologies, including the Web 2.0s social networking capabilities. The network is there. The ability to readily both data mine and […] \\n', 'post_date': '2006-08-16T00:00:00-0400', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2006/08/16/social-networking-20-a-blessing-and-a-curse/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/22/selenium-boot-camp/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Selenium Boot Camp', 'url': 'https://opensourceconnections.com/blog/2006/08/22/selenium-boot-camp/', 'author': 'eric-pugh', 'content': ' In true something or other style, at last nights Selenium Boot Camp the teacher was the student. We decided to hold an after hours “boot camp” so we could beef up our skills at automated testing. And while technically I was the teacher, I ended up learning just as much about doing Selenium testing as the students! Darn those hard to answer questions from professional QA people (thanks Cristen!). \\n\\n So, the biggest thing we learned about was using the Web Developer plugin for FireFox. That plugin really helps simplify testing with Selenium. So, a couple tips: \\n\\n \\n   Trying to figure out the name or ID of some content that is returned by an AJAX call? Typically doing “View Source” wont return that content! However, with the Web Developer, henceforth called WD, you can do “View Source -&gt; View Generated Source” and see the source for your AJAX generated HTML. \\n   Trying to figure out the field names and ids? Use “Forms -&gt; Display Form Details” to see all the form element data. Much faster then digging through source. \\n   However, if you are just building up a bunch of type or select lines to populate a form, then use “Forms -&gt; Populate Form Fields” puts the names of the form elements into the fields in large text. \\n   Lastly, if you want a quick summary of the form, then use “Forms -&gt; View Form Information”. You can get information like label or max length or size and quickly write up all your form data entry actions. \\n \\n\\n We also learned how important sensible id= tags are in HTML pages. Without them you have to resort to all sorts of odd hacks and xpath queries to find what you want to click on. Unfortunantly AjaxScaffold doesnt support id= everywhere, but it was easy to add. \\n\\n', 'excerpt': ' In true something or other style, at last nights Selenium Boot Camp the teacher was the student. We decided to hold an after hours “boot camp” so we could beef up our skills at automated testing. And while technically I was the teacher, I ended up learning just as much about doing Selenium testing as […] \\n', 'post_date': '2006-08-22T00:00:00-0400', 'categories': ['blog', 'News'], 'id': 'https://opensourceconnections.com/blog/2006/08/22/selenium-boot-camp/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/09/06/developers-need-project-managers-too/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Developers need project managers too!', 'url': 'https://opensourceconnections.com/blog/2006/09/06/developers-need-project-managers-too/', 'author': 'jason-hull', 'content': ' Oftentimes, lead developers wind up playing the role of project manager. For a small project, its OK because the level of administrative overhead is small. For large projects, its the wrong call. \\n\\n In resource constrained environments, lead developers are often asked to wear many hats. In small companies, this is both understandable and acceptable. Spending the extra money on a dedicated project manager when the lead developer can play that rol–albeit not as effectively–for only the opportunity cost of time may not make financial sense. \\n\\n However, once a team is working on a project with critical mass, utilizing a project manager becomes essential. \\n\\n Reason 1: Developers develop better than they manage. Though this is a generalization, and there are developers who manage quite well, the reason that they are on projects as developers is because they can deliver solid code. While they may be good at customer management, administration, milestone setting, and all of the other things that a project manager excels at, theyre probably better at coding. In economics, its the idea of comparative advantage. \\n\\n Reason 2: Every minute a developer spends on project management is a minute not spent on coding. Most projects have timelines for a reason, and anything that could divert a developer from delivering on that timeline is something that brings on additional risk to the project. \\n\\n Project managers handle the administrative tasks that set up the developers to be able to get into a zone and crank out great code. They knock down obstacles that come up. They are the face of the project and interact with the customer, keeping the developer from having to answer the customer questions that come up. The project manager can also help manage expectations and keep the project from veering like a driverless car. \\n\\n Project managers are not a panacea to a project. Putting a project manager on a project will not guarantee delivery. Its still up to the developers on the project to actually produce the code that satisfies the customer needs. When time and resources are constrained, then a willingness to invest in project management skills can increase the chances of successful delivery. \\n', 'excerpt': ' Oftentimes, lead developers wind up playing the role of project manager. For a small project, its OK because the level of administrative overhead is small. For large projects, its the wrong call. In resource constrained environments, lead developers are often asked to wear many hats. In small companies, this is both understandable and acceptable. Spending […] \\n', 'post_date': '2006-09-06T00:00:00-0400', 'categories': ['blog', 'Productivity', 'Project Management'], 'id': 'https://opensourceconnections.com/blog/2006/09/06/developers-need-project-managers-too/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/09/07/brazilian-scrum-session/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Brazilian Scrum session', 'url': 'https://opensourceconnections.com/blog/2006/09/07/brazilian-scrum-session/', 'author': 'eric-pugh', 'content': ' Going to be in Brazil in October? Leandro Cruz from Web007 will be leading a session on Scrum during the Borland Conference on Oct. 6 through 8th. Hes done a lot of work with spreading Scrum among Brazilian agile developers and promises to have a great session. \\n', 'excerpt': ' Going to be in Brazil in October? Leandro Cruz from Web007 will be leading a session on Scrum during the Borland Conference on Oct. 6 through 8th. Hes done a lot of work with spreading Scrum among Brazilian agile developers and promises to have a great session. \\n', 'post_date': '2006-09-07T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2006/09/07/brazilian-scrum-session/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/01/the-long-tail-of-the-it-supply-chain/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'The Long Tail of the IT supply chain', 'url': 'https://opensourceconnections.com/blog/2006/10/01/the-long-tail-of-the-it-supply-chain/', 'author': 'jason-hull', 'content': ' In the past two years, Chris Andersons Long Tail has become relatively common in the business lexicon. Does the long tail apply to coders? \\n\\n Common business knowledge says that companies should focus on their core competencies. Having fat staff that doesnt contribute to the focus of the company reduces overall efficiency of the companys resources. Return on assets and revenue per employee drops. Additionally, internal teams tend to lose their edge and do not keep up with the latest trends and knowledge. \\n\\n The answer to this problem is outsourcing tasks that require specialized knowledge. A common example is utilization of external law firms for major court cases. While companies maintain legal counsel for ordinary, non-specialized tasks such as employment contracts and basic SEC filing, few companies will look to their internal corporate legal staffs to lead the defense of a lawsuit against the company. \\n\\n This process also applies to IT staffs. Internal corporate IT staffs are generally well-skilled, but generalists. They can keep the engine running, but are not staffed appropriately to handle large projects. Hence, companies look to external agencies for staff augmentation. Not only can external agencies help smooth out staffing requirements, but these contracted developers can bring in new knowledge to the existing IT teams. \\n\\n In applying Long Tail theory, corporate IT staffs are the head of the curve, and the contracted developers are the tail. \\n\\n Typical recruiting processes focus on the head rather than on the tail. This makes economic sense for corporate recruiters and for recruiting firms. They seek to place developers in full-time jobs, and the economic incentives of working to develop the capabilities to deliver short-term contract developers with specific skills do not provide the profitability and value to move down the tail. Recruiting agencies utilize push processes; coders who want full-time jobs go to recruiters, and the recruiters push those coders to companies that are looking to hire coders. \\n\\n When looking for project staffing or short-term (under 1 year in duration) staff augmentation, look down the long tail for solutions. If you want to go down the long tail for your project or staff needs, contact us. \\n\\n Also, if you are one of those coders who lives in the Long Tail and doesnt want a full-time job, but also doesnt want to have to consistently self-market, send us a resume, code sample, and rate sheet. We are constantly looking to build up our contact list of exceptional coders who are interested in doing onsite short-term contracts. \\n\\n', 'excerpt': ' In the past two years, Chris Andersons Long Tail has become relatively common in the business lexicon. Does the long tail apply to coders? Common business knowledge says that companies should focus on their core competencies. Having fat staff that doesnt contribute to the focus of the company reduces overall efficiency of the companys resources. […] \\n', 'post_date': '2006-10-01T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/10/01/the-long-tail-of-the-it-supply-chain/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/12/continous-integration-presentation-for-cojug/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Continous Integration Presentation for COJUG', 'url': 'https://opensourceconnections.com/blog/2006/10/12/continous-integration-presentation-for-cojug/', 'author': 'eric-pugh', 'content': ' On Tuesday, October 10th I had the opportunity to speak to the Columbus Ohio Java User Group. They are a pretty large group, that actually has seperate lunch and dinner sessions to fit into peoples schedules! \\n\\n I spoke on Continous Integration, focusing on the case for CI, as well as the challenges in instituting CI on a long term basis. Because this was a Java user group, I focused on CruiseControl and Continuum. I have posted the slides for download. \\n\\n Thanks to Chris Judd for the invitiation and being a great host. I met some cool people, and had a really good time. My first visit to Ohio was a great visit. \\n\\n', 'excerpt': ' On Tuesday, October 10th I had the opportunity to speak to the Columbus Ohio Java User Group. They are a pretty large group, that actually has seperate lunch and dinner sessions to fit into peoples schedules! I spoke on Continous Integration, focusing on the case for CI, as well as the challenges in instituting CI […] \\n', 'post_date': '2006-10-12T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2006/10/12/continous-integration-presentation-for-cojug/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/16/whos-watching-road-show-is-starting/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': '“Who’s Watching” road show is starting!', 'url': 'https://opensourceconnections.com/blog/2006/10/16/whos-watching-road-show-is-starting/', 'author': 'eric-pugh', 'content': '  \\n\\n Join me and others for the Cyber Security Roadshow being put on by the “Whos Watching” campaign to increase public awareness of the profile people leave using the Internet. \\n\\n Ill be talking tonight and Wednesday about the scams and “phishing” attacks that target Senior Citizens. \\n\\n', 'excerpt': ' Join me and others for the Cyber Security Roadshow being put on by the “Whos Watching” campaign to increase public awareness of the profile people leave using the Internet. Ill be talking tonight and Wednesday about the scams and “phishing” attacks that target Senior Citizens. \\n', 'post_date': '2006-10-16T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2006/10/16/whos-watching-road-show-is-starting/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/20/selenium-presentation-neon-guild/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Selenium presentation @ Neon Guild', 'url': 'https://opensourceconnections.com/blog/2006/10/20/selenium-presentation-neon-guild/', 'author': 'eric-pugh', 'content': ' Hi Guilders: \\n\\n Heres your Friday-before reminder: \\n\\n Next Neon Guild Meeting: October 23, 2006 6-8pm\\nTopic: Selenium\\nPresenter: Eric Pugh, OpenSource Connections \\n\\n Selenium is a test tool for web applications. Selenium tests run directly in\\na browser, just as real users do. And they run in Internet Explorer, Mozilla\\nand Firefox on Windows, Linux, and Macintosh. No other test tool covers such\\na wide array of platforms. \\n\\n If you do any sort of development work, this will be a very useful session\\nto attend! \\n\\n If you dont do development work, come for the pizza and chitchat before the\\npresentation. \\n', 'excerpt': ' Hi Guilders: Heres your Friday-before reminder: Next Neon Guild Meeting: October 23, 2006 6-8pm Topic: Selenium Presenter: Eric Pugh, OpenSource Connections Selenium is a test tool for web applications. Selenium tests run directly in a browser, just as real users do. And they run in Internet Explorer, Mozilla and Firefox on Windows, Linux, and Macintosh. […] \\n', 'post_date': '2006-10-20T00:00:00-0400', 'categories': ['blog', 'News', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2006/10/20/selenium-presentation-neon-guild/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/24/recap-of-seleniumneon-guild/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Recap of  Selenium@Neon Guild', 'url': 'https://opensourceconnections.com/blog/2006/10/24/recap-of-seleniumneon-guild/', 'author': 'eric-pugh', 'content': ' “Nothing is ever easy” has been my motto for a while, and last night difficulties in getting a working projector going at the Neon Guild reinforced that motto! \\n\\n To make a long story short, I left my mini DVI -&gt; VGA adapter in Columbus Ohio. I got a replacement, only to discover 90 minutes before my Selenium presentation that it was the wrong adapter! \\n\\n Eventually I ended up with my laptop VPNed into another site running the demo, the conference room desktop connected to the projector, and a free trial version of WebEx connecting the two! \\n\\n While things painted a bit slow on the projector, everything worked out. \\n\\n I wanted to thank Jason See and Jeff Cooper for their effort in making sure the network was setup for my presentation on Selenium. \\n\\n For those interested in the slides you can download them. \\n\\n If you have any other questions about Selenium, please drop me a note! \\n\\n', 'excerpt': ' “Nothing is ever easy” has been my motto for a while, and last night difficulties in getting a working projector going at the Neon Guild reinforced that motto! To make a long story short, I left my mini DVI -&gt; VGA adapter in Columbus Ohio. I got a replacement, only to discover 90 minutes before […] \\n', 'post_date': '2006-10-24T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2006/10/24/recap-of-seleniumneon-guild/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/25/how-to-dedupe-your-itunes-collection/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'How to dedupe your iTunes collection', 'url': 'https://opensourceconnections.com/blog/2006/10/25/how-to-dedupe-your-itunes-collection/', 'author': 'eric-pugh', 'content': ' Update 5/25/20 Rinse appears to be gone, or just out of date and bad.  Not sure, with Apple Music etc if we dedupe these days! \\n\\n Update 4/24/2011. TidySongs is now Rinse! Same great product, but new vendor with a deeper music database that seems to match better. I’ve updated the links. \\n\\n Update 5/16/2010. When I am old and grey, I am going to tell my children about the most popular blog post I ever wrote, this one about iTunes deduping! I finally have to pass the baton of deduping on to \\n\\n TidySongs, a product from a company that coincidentally is in my home town of Charlottesville, Virginia! \\n\\n While iTunes provides a “View Duplicates” function, it intentionally doesnt provide anything to help you delete all the duplicates. Apples theory being that you should be very careful with all your music! And an automated system cant detect betweend duplicate songs, and just two versions of the same song. \\n\\n There are a couple AppleScripts out there that can help find all your duplicates as well. However, then you still have to manually go through the playlist and delete them. \\n\\n I unfortunantly have duplicated 780 songs, adding an extra 1.8GB of music files! As you can imagine, manually fixing this was not going to happen. Fortunantly I was able to programmatically solve this. I used the AppleScript Corral All Dupes to find all the duplicates, and made a minor tweak to it so that it would put into my “Dupes” playlist only the second version of the song. Just fire up Script Editor, and then open up the Corral All Dupes applescript application. \\n\\n Find the line that looks like this: \\n\\n â€” copy the list of dupes to the \"Dupes\" playlist\\nrepeat with y from 1 to length of dupesRef\\n \\n\\n And change the line to look like this \\n\\n repeat with y from 1 to (length of dupesRef) - 1\\n \\n\\n This will take all but the last last duplicate and put it on your Dupes playlist. \\n\\n Then, once it is done, just highlight them all, and hold down Option and Delete. The Option key makes iTunes delete the actual music files, versus just remove them from the playlist. This was a tidbit that took quite a bit of searching to find! \\n\\n PS, Corral All Dupes is painfully slow, but making this hack was much easier then in the PERL enabled version. \\n\\n', 'excerpt': ' ong&gt;Update 4/24/2011. TidySongs is now Rinse! Same great product, but new vendor with a deeper music database that seems to match better. I’ve updated the links. Update 5/16/2010. When I am old and grey, I am going to tell my children about the most popular blog post I ever wrote, this one about iTunes deduping! […] \\n', 'post_date': '2006-10-25T00:00:00-0400', 'categories': ['blog', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2006/10/25/how-to-dedupe-your-itunes-collection/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/11/01/bug-4814103-submitted-to-apple/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Bug 4814103 submitted to Apple!', 'url': 'https://opensourceconnections.com/blog/2006/11/01/bug-4814103-submitted-to-apple/', 'author': 'eric-pugh', 'content': ' I discovered a bug in Apples implementation of Java. When selecting multiple leaves in a JTree, and then ctrl + drag, the mouseDragged event should be fired. However, on a Mac, the mouseDragged event never fires! \\n\\n We tested on Linux and Windows, and everything works. Argh. At any rate, hopefully Problem ID 4814103 will soon be fixed:-) \\n\\n Not sure if others can see it, but the site is here https://bugreport.apple.com. \\n\\n The joys of doing Swing development! \\n', 'excerpt': ' I discovered a bug in Apples implementation of Java. When selecting multiple leaves in a JTree, and then ctrl + drag, the mouseDragged event should be fired. However, on a Mac, the mouseDragged event never fires! We tested on Linux and Windows, and everything works. Argh. At any rate, hopefully Problem ID 4814103 will soon […] \\n', 'post_date': '2006-11-01T00:00:00-0500', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2006/11/01/bug-4814103-submitted-to-apple/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/11/02/roping-in-the-cowboy-coders/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Roping In the Cowboy Coders', 'url': 'https://opensourceconnections.com/blog/2006/11/02/roping-in-the-cowboy-coders/', 'author': 'jason-hull', 'content': ' When an IT team needs help with a big project or a new task, they will often look to outsiders for help in delivering their objectives. Oftentimes, they will bring in an elite coder, one with superior skills and knowledge, and look to that coder to be the white knight and save the team. \\n\\n Unfortunately, managers are overawed far too often by the elite coder, and they take a far too hands-off management style, letting that person run roughshod and do whatever he or she wants. What managers forget is that theres a horizon beyond the current project, and when the external help is gone, the remaining IT team needs to maintain and update whatever was left behind. Often, this means that the team is left holding the bag, trying to figure out the code and how to work with it. \\n\\n Just as any company that hires a consultant, just gets a deck, and lets the consultant leave, it is incumbent on the manager to MANAGE the external resources as well. \\n\\n How so? \\n\\n 1) Integrate the external resources with the internal team. For all intents and purposes, for as long as the contract lasts, the contractors are part of the team. Have a kickoff. Do some social events, even if they are on the company clock and the company dime. Managers need everyone to work together.\\n2) Set expectations. Managers should demand well documented, clean code and walkthroughs of the code base so that when the team has to do maintenance, its not the first time anyone has seen the code.\\n3) Get the contractors skin in the game. Put some percentage of the total payment into an escrow to be released a certain time after the code goes live. The contractor should be responsible for bugs, which often dont appear until the release. Demand testing, at least unit testing, and regression testing if possible.\\n4) Pair program. This isnt so that someone is consistently watching over the contractors shoulder, but, rather, so that the internal team can learn from the person who was brought in with special knowledge. There should be knowledge transfer, be it through seminars, brown bag lunches, or observation. \\n\\n This means that a manager looking to bring in external resources needs to do more than look at a resume. Solo riders cure the symptom, but probably dont cure the root cause. This means that the manager needs to do a thorough job in screening; the problems of a bad relationship will last with the team much longer than the relationship will. \\n', 'excerpt': ' When an IT team needs help with a big project or a new task, they will often look to outsiders for help in delivering their objectives. Oftentimes, they will bring in an elite coder, one with superior skills and knowledge, and look to that coder to be the white knight and save the team. Unfortunately, […] \\n', 'post_date': '2006-11-02T00:00:00-0500', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/11/02/roping-in-the-cowboy-coders/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/11/08/rails-and-functional-testing-parameter-pain/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Rails and Functional Testing parameter pain', 'url': 'https://opensourceconnections.com/blog/2006/11/08/rails-and-functional-testing-parameter-pain/', 'author': 'eric-pugh', 'content': ' Ruby on Rails once again lived up to my expectations that it is incredibly powerful, but can als cause real pain! \\n\\n I had a functional test that proved that my action for dropping days from a calender of estimates worked. However, then when running the action through the webapp, it never actually dropped the days! \\n\\n Well, thanks to Jamie Orchard Hays and Chris Hapgood at our local RubyJam, we discovered an “oddity” in how rails works. My action had logic like this: \\n\\n date = params[:date]\\n....\\nif (estimate.date == date)\\n      estimate.destroy\\nend\\n \\n\\n And the estimates were never destoyed! But in my functional test call the estimates were destroyed: \\n\\n dropdate = @sprint.start_date + 2\\n\\nget :drop_day,{:id =&gt; @sprint.id, :date=&gt; dropdate},{:current_user =&gt; @user}\\n \\n\\n So, it turns out that in my functional tests I was passing in dropdate as an actual Ruby Date object, but in the real web action, the date was coming in as a String! Therefore the call: \\n\\n estimate.date == date\\n \\n\\n was never true! I changed my call for getting date to: \\n\\n date = params[:date].to_date\\n \\n\\n and that fixed everything. However, what I think should ALSO have happened was the call to get :drop_day method should have converted everything to String, or whatever else you would expect params[] to return. \\n\\n', 'excerpt': ' Ruby on Rails once again lived up to my expectations that it is incredibly powerful, but can als cause real pain! I had a functional test that proved that my action for dropping days from a calender of estimates worked. However, then when running the action through the webapp, it never actually dropped the days! […] \\n', 'post_date': '2006-11-08T00:00:00-0500', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2006/11/08/rails-and-functional-testing-parameter-pain/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/11/11/better-itunes-song-deduping/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Better iTunes song deduping', 'url': 'https://opensourceconnections.com/blog/2006/11/11/better-itunes-song-deduping/', 'author': 'eric-pugh', 'content': ' **Update 4/24/2011. TidySongs is now Rinse! Same great product, but new vendor with a deeper music database that seems to match better. Ive updated the links. ** \\n\\n \\n   \\n     \\n       *Update 5/16/2010. When I am old and grey, I am going to tell my children about the most popular blog post I ever wrote, this one about iTunes deduping! I finally have to pass the baton of deduping on to \\n     \\n   \\n \\n\\n TidySongs, a product from a company that coincidentally is in my home town of Charlottesville, Virginia!&lt;/p&gt;\\n* * * \\n\\n Im happy to share my hacked version of Doug Adams Corral iTunes Dupes AppleScript. You can grab my version from here. \\n\\n His version uses some wicked fast PERL to find all the duplicate songs based on info in the Library, and then puts them all in a Dupes playlist. However, I wanted to filter by Name, Artist, and Album, and have a single playlist where I could delete in one fell swoop all the duplicates. So I tweaked his AppleScript to have another prompt that asks if you want all dupes to go in the playlist, or just copies 2…X to go in. \\n\\n I run it once with “All” to make sure I have what I want, and then rerun it with “Just Dupes” and build the playlist of files to delete. Works great, and Im mailing him a copy, maybe itll be in the 1.1 version! \\n\\n I was also very happy with the application Seek and Destroy Music Duplicates. It is written in Java using WebStart, and gave some good results as well. It is better in that you can pick which copy of the duplications you want to keep, and color codes each set of duplicates. \\n\\n The tool iDupe really didnt do that much for me, and the demo is limited to just doing 3 deletes. Seek and Destroy is a better choice. \\n', 'excerpt': ' Update 4/24/2011. TidySongs is now Rinse! Same great product, but new vendor with a deeper music database that seems to match better. Ive updated the links. Update 5/16/2010. When I am old and grey, I am going to tell my children about the most popular blog post I ever wrote, this one about iTunes deduping! […] \\n', 'post_date': '2006-11-11T00:00:00-0500', 'categories': ['blog', 'Productivity', 'Software'], 'id': 'https://opensourceconnections.com/blog/2006/11/11/better-itunes-song-deduping/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/11/29/labsapache-now-open/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Labs@Apache now open!', 'url': 'https://opensourceconnections.com/blog/2006/11/29/labsapache-now-open/', 'author': 'eric-pugh', 'content': ' During 2006 the Apache Incubator process has really taken off. Incubator is a place for existing projects to enter the Apache Software Foundation, and build up community around them. Once projects have attracted committers they then graduate. \\n\\n However this has led to many Apache committers (like me!) who have new ideas going off to places like Google Codes Project Hosting and SourceForge, versus going through the paperwork of the Incubator process. \\n\\n So, to provide a low cost place to start a project, Apache Labs was born. It is meant as a place that any ASF committer can start their own projects, but still leverage all the community and infrastructure that Apache has to offer! \\n\\n Hats off to the Apache Labs PMC ! \\n\\n', 'excerpt': ' During 2006 the Apache Incubator process has really taken off. Incubator is a place for existing projects to enter the Apache Software Foundation, and build up community around them. Once projects have attracted committers they then graduate. However this has led to many Apache committers (like me!) who have new ideas going off to places […] \\n', 'post_date': '2006-11-29T00:00:00-0500', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2006/11/29/labsapache-now-open/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/12/03/more-reports-means-less-information/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'More reports means less information', 'url': 'https://opensourceconnections.com/blog/2006/12/03/more-reports-means-less-information/', 'author': 'jason-hull', 'content': ' Just as people spend far too much time in meetings, they also spend far too much time sifting through reports trying to determine what the most important information to running a business is. With the proliferation of database technology and the ease of creating reports to “summarize” that information, decision makers in an enterprise often find themselves unable to get their hands on what they need to drive business forward. This is not because the information is not available, but, rather, it is not available in a useful format. \\n\\n What is necessary to complement the proliferation of information, or, as analysts like to say, “slicing and dicing” information, is a way of filtering that information. More reports exist today with an equivalent amount of utility. Therefore, filtering and sifting through the reports has become todays equivalent to filtering and sifting through the raw data 10-15 years ago. \\n\\n\\n The key to effective management is getting the right reports to the right people at the right time. Often business analysts feel the need to justify their jobs through creating and proliferating reports, most of which either waste leaders time or fill up deleted items folders and trashcans. Test what reports are necessary by eliminating them. See how many people in the organization can no longer make decisions because the reports are no longer there. \\n\\n How can IT help? Catalog and cordon off the reports. Make them accessible from a central location, but create a pull demand system instead of a push supply system. By having a central repository of reports and opt-in subscriptions, an organization can determine what it has and what it needs in a rapid fashion. Furthermore, it can cut down on the clutter in senior managements inboxes and free up time for strategic leadership and management, rather than in the weeds detail orientation. \\n\\n Another benefit of this way of managing reports is that it creates a market economy for reporting. Let the body of the organization determine what is important, much as web 2.0 sites allow for filtering of the best what is available. Find out the most popular reports, the most popular author, or trace down a trail just as you might someones movie or book preferences. \\n\\n Does your company suffer from the curse of a cornucopia of information? Contact us and see how we can help. \\n\\n', 'excerpt': ' Just as people spend far too much time in meetings, they also spend far too much time sifting through reports trying to determine what the most important information to running a business is. With the proliferation of database technology and the ease of creating reports to “summarize” that information, decision makers in an enterprise often […] \\n', 'post_date': '2006-12-03T00:00:00-0500', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/12/03/more-reports-means-less-information/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/12/13/i-got-a-great-time-slot-for-speakingcodemash/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'I got a great time slot for speaking@CodeMash', 'url': 'https://opensourceconnections.com/blog/2006/12/13/i-got-a-great-time-slot-for-speakingcodemash/', 'author': 'eric-pugh', 'content': ' I just checked the Agenda page for CodeMash and I am on Friday just before lunch! I was worried I would be on Friday after lunch, which is always a tough timeslot as people are thinking about cutting out early because their brains are too full! \\n\\n CodeMash is only $99 and has an incredible list of presenters. Im looking forward to seeing Bruce Eckel talk about why dynamic languages offer so much, and Mary Poppendieck talk about “Lean” software development. Beyond Agile is Lean? \\n\\n', 'excerpt': ' I just checked the Agenda page for CodeMash and I am on Friday just before lunch! I was worried I would be on Friday after lunch, which is always a tough timeslot as people are thinking about cutting out early because their brains are too full! CodeMash is only $99 and has an incredible list […] \\n', 'post_date': '2006-12-13T00:00:00-0500', 'categories': ['blog', 'Conference', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2006/12/13/i-got-a-great-time-slot-for-speakingcodemash/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/about-us/eric-pugh/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric Pugh', 'url': 'https://opensourceconnections.com/about-us/eric-pugh/', 'author': 'eric-pugh', 'content': ' Fascinated by the “craft” of software development, Eric Pugh has been heavily involved in the open source world as a developer, committer, and user for the past 5 years. \\n\\n He is an emeritus member of the Apache Software Foundation and lately has been mulling over how we move from the read/write web to the data web. In biotech, financial services and defense IT, he has helped European and American companies develop coherent strategies for embracing open source software. Eric became involved in Solr when he submitted the patch SOLR-284 for Parsing Rich Document types such as PDF and MS Office formats that became the single most popular patch as measured by votes! He co-authored Enterprise Solr Search. \\n', 'excerpt': ' Fascinated by the “craft” of software development, Eric Pugh has been heavily involved in the open source world as a developer, committer, and user for the past 5 years. \\n\\n He is an emeritus member of the Apache Software Foundation and lately has been mulling over how we move from the read/write web to the data web. In biotech, financial services and defense IT, he has helped European and American companies develop coherent strategies for embracing open source software. Eric became involved in Solr when he submitted the patch SOLR-284 for Parsing Rich Document types such as PDF and MS Office formats that became the single most popular patch as measured by votes! He co-authored Enterprise Solr Search. \\n', 'post_date': '2007-01-02T00:00:00-0500', 'categories': ['about-us'], 'id': 'https://opensourceconnections.com/about-us/eric-pugh/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/about-us/scott-stults/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Scott Stults', 'url': 'https://opensourceconnections.com/about-us/scott-stults/', 'author': 'scott-stults', 'content': ' Scott Stults has led implementation teams on a variety of Department of Defense, UK Ministry of Defense, and commercial projects where implementing search has been constrained by sophisticated security requirements. He has implemented Multi-Level Security (MLS) in a Lucene-based environment and is working with the Solr community to develop best practices for securing Solr. As a co-founder of OpenSource Connections, which has been working with Solr since 2007, Mr. Stults leads the Solr Security Practice for the company.  In 2011 he presented at the Basis Technology Open Source Search Conference on Multi-Level Security with Solr: Searching Documents at Various Classifications.  More recently Mr. Stults was a presenter at Lucene Revolution on Indexing Big Data on Amazon AWS. \\n', 'excerpt': ' Scott Stults has led implementation teams on a variety of Department of Defense, UK Ministry of Defense, and commercial projects where implementing search has been constrained by sophisticated security requirements. He has implemented Multi-Level Security (MLS) in a Lucene-based environment and is working with the Solr community to develop best practices for securing Solr. As a co-founder of OpenSource Connections, which has been working with Solr since 2007, Mr. Stults leads the Solr Security Practice for the company.  In 2011 he presented at the Basis Technology Open Source Search Conference on Multi-Level Security with Solr: Searching Documents at Various Classifications.  More recently Mr. Stults was a presenter at Lucene Revolution on Indexing Big Data on Amazon AWS. \\n', 'post_date': '2007-01-02T00:00:00-0500', 'categories': ['about-us'], 'id': 'https://opensourceconnections.com/about-us/scott-stults/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/01/15/you-never-know-where-people-will-find-you/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'You never know where people will find you', 'url': 'https://opensourceconnections.com/blog/2007/01/15/you-never-know-where-people-will-find-you/', 'author': 'jason-hull', 'content': ' Thanks to Pruppert, word about our iTunes deduplicate script is spreading. He posted on the Mac World Forum and had an excellent write-up on how the script differed from previous scripts. \\n\\n The surprise to us was how quickly Erics new post popped up on other places in the Internet. None of us know Pruppert from a random stranger; yet, he posted about us (and did an excellent job of writing about what it did) and generated a significant amount of traffic. Our websites traffic doubled since the posting, and just under 50% of the traffic has been from that posting. While we dont expect every blog post to hit like that and establish thought leadership, this shows the value of continuing to post blogs. \\n\\n', 'excerpt': ' Thanks to Pruppert, word about our iTunes deduplicate script is spreading. He posted on the Mac World Forum and had an excellent write-up on how the script differed from previous scripts. The surprise to us was how quickly Erics new post popped up on other places in the Internet. None of us know Pruppert from […] \\n', 'post_date': '2007-01-15T00:00:00-0500', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2007/01/15/you-never-know-where-people-will-find-you/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/01/26/migrating-from-simplelog-to-wordpress/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Migrating from Simplelog to WordPress', 'url': 'https://opensourceconnections.com/blog/2007/01/26/migrating-from-simplelog-to-wordpress/', 'author': 'eric-pugh', 'content': ' After 7 months and 34 posts, weve outgrown Simplog. Were just finishing migrating all the content to our new WordPress blog, but Im sure youll see some bumps in the road as we get URLs fix, image references resolved, and all the other malarkey that moving platforms requires. \\n\\n While Simplelog was a great tool, and its simplicity was wonderful, weve gotten to the point where we want to be able to handle things like: \\n\\n \\n   \\n     Aggregating multiple feeds \\n   \\n   \\n     Open access to many users \\n   \\n   \\n     Properly ping Technorati on updates! \\n   \\n   \\n     Be able to post using thick client tools. \\n   \\n \\n\\n If you find something broken, please feel free to drop me a note at epugh@opensourceconnections.com. \\n', 'excerpt': ' After 7 months and 34 posts, weve outgrown Simplog. Were just finishing migrating all the content to our new WordPress blog, but Im sure youll see some bumps in the road as we get URLs fix, image references resolved, and all the other malarkey that moving platforms requires. While Simplelog was a great tool, and […] \\n', 'post_date': '2007-01-26T00:00:00-0500', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/01/26/migrating-from-simplelog-to-wordpress/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/02/05/using-mod_auth_mysql-as-a-single-sign-on-tool/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Using mod_auth_mysql as a single sign-on tool', 'url': 'https://opensourceconnections.com/blog/2007/02/05/using-mod_auth_mysql-as-a-single-sign-on-tool/', 'author': 'scott-stults', 'content': ' I recently migrated our Subversion repositories and trac sites from one server to another. This gave me the chance to reorganize our layout and authentication mechanism. I chose to replace our existing .htaccess files with mod_auth_mysql because it fit two key criteria: \\n\\n \\n   Its easy to administer – Logging into the server and running htpasswd every time I need to add a user or change a password is a PITA \\n   Most of the applications we use offer MySQL authentication functions, so I can grant access to several things at once. \\n \\n\\n The docs on how to set it up were fairly clear, with one exception: I would have liked to have seen an example of how to use multiple tables for group membership. After a little more Googling I ran across such an example, taken from  Integration of Jira User Management with Apache.\\nCommon database normalization techniques suggest that users and passwords go into one table, groups in another, and a third table should be used to join the two by IDs. This is what I was after, and thats what Jiras integration doc showed me. It was also confirmation that I had chosen an appropriate central authentication mechanism. \\n\\n Eric was nice enough to whip up a Rails CRUD utility to manage the tables (which will be posted soon) and from there it was a simple matter to instruct Apache to use those tables whenever it needed authentication. By the way, a great way to do that is with a separate file such as “mysql-auth.inc” and just use the Apache Include directive to include that file wherever you need authentication. \\n\\n', 'excerpt': ' I recently migrated our Subversion repositories and trac sites from one server to another. This gave me the chance to reorganize our layout and authentication mechanism. I chose to replace our existing .htaccess files with mod_auth_mysql because it fit two key criteria: Its easy to administer – Logging into the server and running htpasswd every […] \\n', 'post_date': '2007-02-05T00:00:00-0500', 'categories': ['blog', 'Code', 'System Administration'], 'id': 'https://opensourceconnections.com/blog/2007/02/05/using-mod_auth_mysql-as-a-single-sign-on-tool/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/02/13/how-to-remove-plugins-installed-as-svnexternals/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'How to remove plugins installed as svn:externals', 'url': 'https://opensourceconnections.com/blog/2007/02/13/how-to-remove-plugins-installed-as-svnexternals/', 'author': 'eric-pugh', 'content': ' I love how easy it is to keep up with the latest and greatest of a plugin in Rails: script/plugin install -x https://some.subversion.server/plugin. \\n\\n Unfortunantly, if you then want to remove it, you need to then go and muck around with subversion externals in /vendor/plugins. It took me much hunting around and playing with svn proplist and svn propget to figure it out. It turns out to be as simple as just \\n\\n \\ncd ./vendor/plugins and then svn propedit svn:externals . --editor-cmd vi\\n \\n\\n and removing the line. Then just commit the changes plugins directory! \\n\\n The canonical information on properties is available from the Redbook \\n', 'excerpt': ' I love how easy it is to keep up with the latest and greatest of a plugin in Rails: script/plugin install -x https://some.subversion.server/plugin. Unfortunantly, if you then want to remove it, you need to then go and muck around with subversion externals in /vendor/plugins. It took me much hunting around and playing with svn proplist […] \\n', 'post_date': '2007-02-13T00:00:00-0500', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/02/13/how-to-remove-plugins-installed-as-svnexternals/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/02/16/ajaxscaffold-and-file-uploads/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'AjaxScaffold and File Uploads', 'url': 'https://opensourceconnections.com/blog/2007/02/16/ajaxscaffold-and-file-uploads/', 'author': 'eric-pugh', 'content': \" Weve had a little Expenses Rails app for tracking charges and funneling them back to Accounting. One of the key bits is that we can upload a picture of the receipt to each expense. Its remarkable how good resolution camera phones have these days, and its a lot better then walking around with a pocketful of receipts while on a business trip! \\n\\n So we used the basic Rails scaffolding, but I am a big fan of Richard Whites Ajax Scaffold. And since it is now a Rails Plugin, I wanted to give it a try. I dropped it into the app, and everything worked fine. That is until I tried to upload my image of a receipt. Bam… I started thinking this was a weakness of Ajax Scaffold, but after a bit of digging around it turns out binary data cant be sent via AJAX calls! Ugh… \\n\\n Well, after playing around with various options for a while, i decided that I wasnt going to use something weird like a Flash based uploader or what not. Instead, when adding a new expense, I do a regular post via form_tag that takes you back to the list page, and when editing a receipt, where image changing isnt supported anyway, I use the ajax goodness via form_remote_tag. \\n\\n I can tell which method is being invoked on _new_edit.rhtml partial by doing: &lt; % if params[:action] == 'edit' %&gt; , and use the appropriate form tag. The only issue was that to keep the other Ajax calls working properly, the form_tag id had to use the full :id =&gt; element_form_id(@options) id. The only real downside is that when creating a new expense, if there is an error, you are popped out of the table view, into a page with just the new expense partial, but you can still save your data. \\n\\n At any rate, Ajax Scaffold as plugin has grown more mature then ever. I really appreciate how easy it is to do things like change sorting order, or add your own filters to the data. And the fact that all the raw Ajax Scaffold template stuff stays in /views/ajax_scaffold/, and allows you to override individual .rthtml templates by adding them to your /views/model/ directory is just great. It also become a lot cleaner and easier to understand the internal workings as well. I am very much looking forward to Ajax Scaffold 4.0! \\n\", 'excerpt': ' Weve had a little Expenses Rails app for tracking charges and funneling them back to Accounting. One of the key bits is that we can upload a picture of the receipt to each expense. Its remarkable how good resolution camera phones have these days, and its a lot better then walking around with a pocketful […] \\n', 'post_date': '2007-02-16T00:00:00-0500', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/02/16/ajaxscaffold-and-file-uploads/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/02/23/continous-integration-tools-market-is-splitting/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Continous Integration Tools Market is splitting…', 'url': 'https://opensourceconnections.com/blog/2007/02/23/continous-integration-tools-market-is-splitting/', 'author': 'eric-pugh', 'content': ' In the beginning there was CruiseControl, the original Continous Integration tool. Most people, including myself, cut there teeth on CruiseControl. Then, over time, a couple of opensource projects started spawning commercial tools, like AntHill and AntHillPro, and I thought all the new innovation in CI tooling was going to be by commercial companies. \\n\\n Well, I am glad to see that isnt the case. At the heavy/powerful, and light and simple end of the spectrum there are two new tools to add to the evaluation lists: Hudson and CruiseControl.rb. Neither of them is currently listed on the Continuous Integration Server Feature Matrix page, but they both offer new approaches and features to CI. \\n\\n Hudson is Java based, and provides similar functionality to CruiseControl and Continuum. It is better then CruiseControl in that it allows you to configure new jobs via the web interface, and has a reasonable well thought out plugin architecture. It looks like it has a leg up on Continuum because it seems more polished, and designed to manage larger numbers of projects. \\n\\n The key things that I like about Hudson is that it supports distributed builds, and scheduling builds outside of Hudson, and just reporting results. \\n\\n The distributed builds are based on deploying a “slave agent” to each slave builder. You can specify for your projects if they need to be built on one specific server, or if they can be built on any server. It also tries to move long running builds to the slaves versus the master project. You will have the usual challenges of deploying all the tools to each slave builder however. But if you are building many heterogenous projects, like C code, PHP, Java, Ruby, then you can simplify the setup task by having seperate server for each type of environment. For one client, we have seperate Continuum instance building a single .NET project on Windows, and this would have been a great place to have a slave builder instead. \\n\\n The external builds stuff is really exciting, and an original idea. If you already have a build setup, like maybe doing builds on Linux and Solaris for example, and dont want to throw it away, then you can just tweak Hudson to read in the result of your external build, so you can get the reporting and notification abilities of Hudson! This is a great way to slowly introduce CI into an organization that has preexisting processes without causing a lot of disruption. \\n\\n CruiseControl.rb, while sharing its name with CruiseControl and CruiseControl.NET looks like a completely redone implementation in Ruby. Instead of just being a rewrite of CruiseControl, like CC.NET is, it has been written in a thoroughly “Thinking in Ruby” fashion. Out goes the complex XML config file, in comes a very simple Ruby script for configuration. Still there are two seperate processes, a build agent and a dashboard gui (a simple Rails app), but both are started up together. It definitly passes the 15 Minute rule, as I was able to deploy it and have it running in no time. You can see it online at http://labs.opensourceconnections.com:3333, where I have dropped two projects, Horseshow, a Rails project, and Boozer, a user auth plugin for Rails… \\n\\n This looks like a great choice for projects who are already using Ruby, and dont need/want the complexity/power of a full blown CI tools like Continuum or Hudson. Where is looks like it falls down is if you have tens of projects that you want to manage. Or lots of different SCM systems. You also have to log on to the server and use a command line cruise tool to add projects. And edit a project config ruby file to specify who the recipients are. But, for a small team where sharing out access is fine, or for just a couple projects, it looks like just the ticket. For Ruby projects at least, its the new King of the Hill. \\n', 'excerpt': ' In the beginning there was CruiseControl, the original Continous Integration tool. Most people, including myself, cut there teeth on CruiseControl. Then, over time, a couple of opensource projects started spawning commercial tools, like AntHill and AntHillPro, and I thought all the new innovation in CI tooling was going to be by commercial companies. Well, I […] \\n', 'post_date': '2007-02-23T00:00:00-0500', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/02/23/continous-integration-tools-market-is-splitting/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/02/28/citconf-the-continuous-integration-testing-conference-is-coming/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'CitConf: The Continuous Integration Testing Conference is coming!', 'url': 'https://opensourceconnections.com/blog/2007/02/28/citconf-the-continuous-integration-testing-conference-is-coming/', 'author': 'eric-pugh', 'content': ' CitConf is a focused conference on Continuous Integration Testing, and takes place three time a year around the globe. This years North American location will be Fort Worth, Texas, on April 27th and 28th. \\n\\n CitConf uses the OpenSpaces format which was pioneered by Bruce Eckels as a way to lower the management overhead of typical conferences. At CodeMash I joined Bruce and some others in a OpenSpace format session, and as long as the group is small, and interested it works quite well. Since CitConf is capped at 100 people, it seems like an entire OpenSpaces format conference would work. \\n\\n At any rate, the conference is FREE, as most of the costs are either borne by sponsors or eliminated via the OpenSpaces format. \\n', 'excerpt': ' CitConf is a focused conference on Continuous Integration Testing, and takes place three time a year around the globe. This years North American location will be Fort Worth, Texas, on April 27th and 28th. CitConf uses the OpenSpaces format which was pioneered by Bruce Eckels as a way to lower the management overhead of typical […] \\n', 'post_date': '2007-02-28T00:00:00-0500', 'categories': ['blog', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2007/02/28/citconf-the-continuous-integration-testing-conference-is-coming/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/01/using-sqlite3-capistrano-mongrel-cluster-oh-my/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Using SQLite3 &#038; Capistrano &#038; Mongrel Cluster oh my!', 'url': 'https://opensourceconnections.com/blog/2007/03/01/using-sqlite3-capistrano-mongrel-cluster-oh-my/', 'author': 'eric-pugh', 'content': \" The biggest slam against using file based databases like SQLite is that they are actual files embedded in your application, and that you have to go through extra hoops when upgrading your application. For example, if you have your production prod.sqlite3 file in ./db, then every time you update your application using Capistrano youll replace your production database with a fresh one! \\n\\n Well, my first attempt to work around this involved excluding the ./db directory from checkout and then creating a db directory in /shared/db. Symlinking from /shared/db to ./db worked, but was clumsy, and required extra code in my deployment recipe. \\n\\n A light bulb finally dawned that the path in databases.yml for my production database could be something like: \\n\\n \\nproduction:\\nadapter: sqlite3\\ndatabase: ../../shared/db/prod.sqlite3\\n \\n\\n Just go up two directories and over to the shared/db directory and locate the database file there! I tried it out, and it worked great. I ran cap deploy_with_migrations and soon enough had a shared sqlite3 database. I then fired up the app with cap cold_deploy and everything ground to a halt :( . I was getting an error about “database cant be opened. Eventually, after pulling my hair out I discovered that while starting mongrel with ./server/script works great with relative paths to the database, starting with mongrel_rails requires a complete path: \\n\\n \\nproduction:\\nadapter: sqlite3\\ndatabase: /opt/apps/horseshow/shared/db/prod.sqlite3\\n \\n\\n Victory at last! \\n\\n To automate the generation of the shared/db directory, just add to your deploy.rb recipe: \\n\\n \\ndesc 'A setup task to put shared system, log, and database directories in place';\\ntask :setup, :roles =&gt; [:app, :db, :web] do\\nrun &lt;&lt;-CMD\\nmkdir -p -m 775 #{release_path} #{shared_path}/system #{shared_path}/db &amp;&amp;\\nmkdir -p -m 777 #{shared_path}/log\\nCMD\\nend\\n \\n\", 'excerpt': ' The biggest slam against using file based databases like SQLite is that they are actual files embedded in your application, and that you have to go through extra hoops when upgrading your application. For example, if you have your production prod.sqlite3 file in ./db, then every time you update your application using Capistrano youll replace […] \\n', 'post_date': '2007-03-01T00:00:00-0500', 'categories': ['blog', 'Code', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/03/01/using-sqlite3-capistrano-mongrel-cluster-oh-my/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/05/a-simple-example-of-tomcat-realms-and-security/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'A simple example of Tomcat Realms and Security', 'url': 'https://opensourceconnections.com/blog/2007/03/05/a-simple-example-of-tomcat-realms-and-security/', 'author': 'eric-pugh', 'content': ' Last week a colleague of mine called me up because he was struggling with setting up Tomcat JDBCRealm for use with a relatively simple straightforward webapp. Wed recently released the 1.0 version of GateKeeper, and he wanted to use it to manage his users and roles. The GateKeeper side of things went just fine, but the JDBCRealm setup on his webapp was proving very balky. \\n\\n He fired up VNC, and I logged in and checked out his settings. And there was nothing wrong! At least, nothing that looked odd in any way. We then googled for some help, maybe a simple sample setup, but to no avail! Oddly enough, nowhere on the internet is a good example of using a Tomcat Realm to protect a webapp. There are various examples, but they just show a part of the puzzle, maybe just the &lt;security -constaint/&gt; section in the web.xml, or a Realm definition: &lt;realm className=\"org.apache.catalina.realm.MemoryRealm\" /&gt;. Reading the servlet spec for web.xml helps, but doesnt give you details on the Tomcat specific details. \\n\\n So, over the weekend I set out to create a simple example, and I planned on using the jsp-examples app the ships with Tomcat. After poking around jsp-examples I discovered what I had been looking for all along! There is a full example of protecting a webapp using a Realm! The example for some odd reason is NOT linked from the home page of jsp-examples, but it is there. http://localhost:8080/security/protected and log in as user role1, with the password tomcat. \\n\\n Ill walk you really quickly through the relevant portions of the configuration files. First off you define what URLs you want protected by which roles in your web-apps web.xml file: \\n\\n ```\\n&lt;security -constraint&gt;\\n&lt;display -name&gt;Example Security Constraint&lt;/display&gt;\\n&lt;web -resource-collection&gt;\\n&lt;/web&gt;&lt;web -resource-name&gt;Protected Area&lt;/web&gt;\\n \\n\\n &lt;url -pattern&gt;/security/protected/*&lt;/url&gt;\\n \\n\\n &lt;http -method&gt;DELETE&lt;/http&gt;\\n&lt;http -method&gt;GET&lt;/http&gt;\\n&lt;http -method&gt;POST&lt;/http&gt;\\n&lt;http -method&gt;PUT&lt;/http&gt; \\n\\n &lt;auth -constraint&gt;\\n \\n\\n &lt;role -name&gt;tomcat&lt;/role&gt;\\n&lt;role -name&gt;role1&lt;/role&gt;\\n&lt;/auth&gt;\\n&lt;/security&gt; \\n\\n\\n\\n &lt;login -config&gt;\\n&lt;auth -method&gt;FORM&lt;/auth&gt;\\n&lt;realm -name&gt;Example Form-Based Authentication Area&lt;/realm&gt; \\n\\n &lt;/login&gt; \\n\\n\\n\\n &lt;security -role&gt;\\n&lt;role -name&gt;role1&lt;/role&gt;\\n&lt;/security&gt;\\n&lt;security -role&gt;\\n&lt;role -name&gt;tomcat&lt;/role&gt;\\n&lt;/security&gt;\\n``` \\n\\n The first &lt;security -constraint/&gt; stanza specifies the URLs of the pages that we want to protect, as well as what roles are required to allow access. Anything in the /security/protected/* pattern will require the user has either the role role1 or tomcat. \\n\\n The next stanza, &lt;login -config/&gt; specifies how you gain access to the protected URLs. In this example, we are using FORM based security, so we specify the URLs for the login/logout pages. If you are using BASIC authentication then your stanza is much simpler: \\n\\n \\n&lt;login -config&gt;\\n&lt;auth -method&gt;BASIC&lt;/auth&gt;\\n&lt;realm -name&gt;Example BASIC Authentication Area&lt;/realm&gt;\\n&lt;/login&gt;\\n \\n\\n The remaining stanzas, &lt;security -role/&gt; are the roles that are used in this webapp, and they are elements that are often forgotten in a web.xml. \\n\\n Now that we have defined that only users who have roles role1 or tomcat can access the application, we then need to configure Tomcat. This is done through server.xml, and can be a bit of a rat hole to figure everything out. So, extracted from server.xml we have the following XML stanzas. Ive removed most of the commenting so you can see the overall structure of the document: \\n\\n ``` \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n ``` \\n\\n Now, instead of going from top to bottom, well start from the definition for the specific host, and work our way out. The challenge that my colleague and I had was that we thought we needed to somehow map a &lt;security -constraint/&gt; in the web.xml to some sort of definition in server.xml. We were mucking around with all sorts of &lt;realm /&gt; stanzas embedded in &lt;host /&gt; stanzas and trying to match &lt;realm -name/&gt; in the web.xml to the &lt;realm name=XX/&gt; element in server.xml. What we didnt realize until I found the jsp-examples sample security code is that because the realm is defined inside of the &lt;engine /&gt; stanza, it applies to all hosts! And that there is NO explicit mapping between webapps and realms at a level more detailed then at an Engine level. All webapps defined in all hosts that share the same engine share the same realm! So the complete stanza looks like: \\n\\n ``` \\n\\n\\n\\n\\n\\n ``` \\n\\n Now, I dont know what you would do if you wanted to use different Realms for each webapp, maybe define multiple Engines I guess. Our UserDatabaseRealm is not fully defined here, instead it refers to a global resource called UserDatabase. That is defined outside in our &lt;globalnamingresources /&gt; stanza: \\n\\n ``` \\n\\n\\n\\n\\n\\n\\n\\n\\n ``` \\n\\n Weve defined a resource call UserDatabase that reads in data in the conf/tomcat-users.xml file and exposes it as a user database. \\n\\n Hopefully this will walk you through all the setup steps required for adding a Realm to your webapp. For me, the key insight was that the realm definition inside of the engine definition applies to all the web-apps in all the hosts. I am working on cutting our 1.0.1 version of Gatekeeper which will demo using a JDBCRealm. I will post a follow up on that. \\n', 'excerpt': ' Last week a colleague of mine called me up because he was struggling with setting up Tomcat JDBCRealm for use with a relatively simple straightforward webapp. Wed recently released the 1.0 version of GateKeeper, and he wanted to use it to manage his users and roles. The GateKeeper side of things went just fine, but […] \\n', 'post_date': '2007-03-05T00:00:00-0500', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/03/05/a-simple-example-of-tomcat-realms-and-security/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/06/adding-tls-support-to-tracs-wikinotifyscript/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Adding TLS Support to Tracs WikiNotifyScript', 'url': 'https://opensourceconnections.com/blog/2007/03/06/adding-tls-support-to-tracs-wikinotifyscript/', 'author': 'scott-stults', 'content': ' Weve been using the WikiNotifyScript from trac-hacks.org for quite a while now. It helps us stay appraised of changes to all of our various wikis and its pretty easy to set up. However, when I had the brilliant idea of switching it to use Gmail as the SMTP server I ran into a snag: Gmail only supports logins through TLS. Recent Trac releases support TLS through smtplib, but unfortunately WikiNotifyScript doesnt share that code. \\n\\n After a quick grep through the trac source I found the magic incantation nestled inside notification.py. It was a pretty simple matter to port what trac does over to WikiNotifyScript, so after a brief round of testing I posted the patch over on WikiNotifyScripts trac. Hopefully thatll save somebody some trouble. \\n\\n', 'excerpt': ' Weve been using the WikiNotifyScript from trac-hacks.org for quite a while now. It helps us stay appraised of changes to all of our various wikis and its pretty easy to set up. However, when I had the brilliant idea of switching it to use Gmail as the SMTP server I ran into a snag: Gmail […] \\n', 'post_date': '2007-03-06T00:00:00-0500', 'categories': ['blog', 'Code', 'System Administration'], 'id': 'https://opensourceconnections.com/blog/2007/03/06/adding-tls-support-to-tracs-wikinotifyscript/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/06/re-system-logs-as-reproducible-scripts/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'RE: System logs as reproducible scripts', 'url': 'https://opensourceconnections.com/blog/2007/03/06/re-system-logs-as-reproducible-scripts/', 'author': 'eric-pugh', 'content': ' Duane Gran recently pinged me about thoughts on “System logs as reproducible scripts”. Its a topic that Ive been running into recently as weve gone into testing a web based application, and dealing with some of our users very difficult to reproduce bug reports. \\n\\n The challenge with a log that can be “played back” is that often the system will prevent the same set of events from happening again. For example, if you record a series of events that includes creating a user, then when you play them back the user creation step will fail with a “user already exists” type of error. \\n\\n However, this isnt to say that this isnt a good idea. With in narrow scopes, this has been done. For example, there are tools that intercept your SQL transactions and record them for use in rebuilding indexes and debugging after the fact issues. Ive also seen a tool that attempted to record all your SQL statements, and then replay them in reverse to restore your database to a known state! \\n\\n Right now the tools available dont help us follow the path of execution through a web app for a specific user very well. We can see part of the picture, via grepping through a webserver log for a session id, but its difficult to tie that into a log of SQL statements issued for that session. And there arent any good simple tools for connecting data collected from Google Analytics, and matching it up to other data sources like server logs or SQL transaction logs. \\n\\n On the server side, there are tools like DTrace that provide a developer with indepth visibility into what is happening to an application. DTrace was used by some of the PostgresSQL developers at OSCON 2006 to find many bottlenecks in the performance of PostgresSQL for example. Now we need to bubble up one more level up and be able to view the actions performed by a specific user that may cause activity on multiple tiers and systems! \\n\\n I used to work with Canoo WebTest, a tool for functional testing of websites. And one thing it did that was wonderful was to record on the local filesystem a copy of every HTML page that it recieved back from the server. This meant that you could go back and “see” what your Canoo Functional Test “saw” at each step. Selenium is my current favorite for Functional testing. But it doesnt record each page as it runs through them, so you have to figure out what tests failed by just the error message that was created when running a suite of tests. \\n\\n Maybe what we need, at least from a web application perspective, is the ability to save each page displayed to the user? I can envision the webserver sending a copy of each page back to the user, but also saving a copy locally, and aggregating them based on session id, and naming (and thus ordering) them based on time? Ajax calls of course might be just the raw XML that was sent back to the client between full HTML page loads. While this might put inordinate load on a large public website, it might be just the ticket for when you are doing development/testing of a website. A bug report with a timestamp and session id could be tied back to the sequence of webpages, and the developer could visually see each step that was taken to generate the error. \\n\\n Ideally the list of pages could be tied together in some sort of slideshow that the developer could play back to see what the user did. While this approach isnt the generic “System logs as reproducible scripts” that Duane was looking for, it is a step in the right direction! \\n', 'excerpt': ' Duane Gran recently pinged me about thoughts on “System logs as reproducible scripts”. Its a topic that Ive been running into recently as weve gone into testing a web based application, and dealing with some of our users very difficult to reproduce bug reports. The challenge with a log that can be “played back” is […] \\n', 'post_date': '2007-03-06T00:00:00-0500', 'categories': ['blog', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/03/06/re-system-logs-as-reproducible-scripts/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/09/congratulations/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Congratulations!', 'url': 'https://opensourceconnections.com/blog/2007/03/09/congratulations/', 'author': 'jason-hull', 'content': ' Congratulations to OSC principal Scott Stults and his wife on the birth of their first baby, a healthy and as of yet unnamed son. \\n\\n Naturally, Scott cannot allow something like this to pass without introducing technology, so he has a webcam set up in the hospital room. \\n\\n Our hopes are that the baby takes after his mother… \\n', 'excerpt': ' Congratulations to OSC principal Scott Stults and his wife on the birth of their first baby, a healthy and as of yet unnamed son. Naturally, Scott cannot allow something like this to pass without introducing technology, so he has a webcam set up in the hospital room. Our hopes are that the baby takes after […] \\n', 'post_date': '2007-03-09T00:00:00-0500', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2007/03/09/congratulations/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/13/a-nice-surprise-courtesy-of-continuum-easy-updating-of-repository-information/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'A nice surprise courtesy of Continuum: Easy updating of repository information', 'url': 'https://opensourceconnections.com/blog/2007/03/13/a-nice-surprise-courtesy-of-continuum-easy-updating-of-repository-information/', 'author': 'eric-pugh', 'content': ' I discovered an unexpected feature that Continuum has. At one client site we are building around 30 different projects from CVS. Over the weekend the DNS name of the CVS server was changed as part of a corporate renaming process. I expected to have to go and update each projects collection of CVS\\\\Root files for the new repository, as well as update the CVS checkout information in Continuum. \\n\\n I started by updating one project in Continuum, and then when I went onto the filesystem I couldnt find the previously checked out project! My first thought was “Oh nooooo, everything has blown up”. It turned out that Continuum was smart enough to pick up the changed SCM information, and to remove the currently checked out code and replace it with the new code! \\n\\n This is one of those features that I wouldnt have expected Continuum, especially at the 1.0.3 versions level of maturity, to support, and saved us a couple hours of linux work. \\n', 'excerpt': ' I discovered an unexpected feature that Continuum has. At one client site we are building around 30 different projects from CVS. Over the weekend the DNS name of the CVS server was changed as part of a corporate renaming process. I expected to have to go and update each projects collection of CVS\\\\Root files for […] \\n', 'post_date': '2007-03-13T00:00:00-0400', 'categories': ['blog', 'Code', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/03/13/a-nice-surprise-courtesy-of-continuum-easy-updating-of-repository-information/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/21/comparing-datetime-and-date/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Comparing DateTime and Date', 'url': 'https://opensourceconnections.com/blog/2007/03/21/comparing-datetime-and-date/', 'author': 'eric-pugh', 'content': ' For my project Novo, Ive been working on a script to sync my Apple iCal to Googles gCal. Think of it as a poor mans version of SpanningSync. \\n\\n One of our challenges is that sometimes we are dealing with Ruby DateTime objects, and other times we are dealing with Date objects. And of course, you cant compare the two to each other (argh!). \\n\\n So initially I would convert them to strings, and then create Time objects and then compare them. And if they were in UTC format, I had a hardcoded value that swapped in my offset from UTC. Of course, with the early arrival (ending???) of Daylight Savings Time change in the US, this caused one week all my appointments to be synced into gCal one hour off! \\n\\n So I took advantage of chatting with Chris Hapgood about his challenges with dates and timezones and implemented TZInfo. \\n\\n But, much to my disgust, when I hand in a DateTime to TZInfo, I get back a proper UTC formatted DateTime. And when I hand in a Time to TZInfo, I get back a proper UTC formatted Time object! So, I am still stuck converting to String, and then reparsing into Time for comparisions. \\n\\n Ive looked around, and the only thing Ive found was from a site that has Ruby Cookbook tips, but it just seems like I should be able to more simply parse/compare the two! Especially since I dont know if I am dealing with DateTimes or Times, and so have to put in some funky logic to figure it out and do the right parsing…. \\n', 'excerpt': ' For my project Novo, Ive been working on a script to sync my Apple iCal to Googles gCal. Think of it as a poor mans version of SpanningSync. One of our challenges is that sometimes we are dealing with Ruby DateTime objects, and other times we are dealing with Date objects. And of course, you […] \\n', 'post_date': '2007-03-21T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/03/21/comparing-datetime-and-date/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/27/is-your-employees-time-your-time/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Is your employees’ time your time?', 'url': 'https://opensourceconnections.com/blog/2007/03/27/is-your-employees-time-your-time/', 'author': 'jason-hull', 'content': ' A recent survey by Clearswift and Yougov shows that 59% of all employees aged 18-29 believe that they should be able to use Web 2.0 social networking sites for their personal use during work time and using corporate computers. \\n\\n This is certainly a shifting tide from the corporate culture of a bygone past when your time was the companys time, and you spent all day doing company work. But is this a bad thing? \\n\\n There are benefits to allowing employees to use the web for personal business during work hours. To expect almost any employee to work for eight hours straight (or even four hours straight, then an hour for lunch, and then four hours straight) is, almost without exception, unrealistic. The average persons attention span is somewhere between 50 and 55 minutes, and beyond that, concentration and results decline. They will need to take a break somehow. Many of them will use the time wisely and take care of other business which then eliminates a potential worry and allows them to focus on the task at hand. \\n\\n\\n\\n There are also risks to allowing them to use the web for personal use. One is the possibility of using social networking sites to air corporate dirty laundry. After all, if something has happened which the employee disagrees with, then its a simple matter to anonymously log into a social networking site and begin griping. Thats life. Theyre going to gripe sometimes, and to hide from the negative side of management is disregarding a duty. \\n\\n Where the line must exist is in giving away company secrets. However, that needs to be handled up front with non-disclosure agreements and employment agreements. Establish the rules and the punishments for failing to abide by the rules up front. Trying to stifle a leak later is a calamitous exercise. \\n\\n Companies that fail to embrace web 2.0s social networking powers are missing out on a great opportunity, particularly if they fail to do so out of fear of the airing of problems. Let others see a true picture of the company, and if it is one that does good work and takes care of its people, then an internal uprising of good words will quell the occasional disgruntled posting. Trying to overly monitor activity and stifle what is being said about a company is an Orwellian road to failure. Instead, focus on creating a good environment where people get to do the work that they enjoy and want to say positive things about the company. \\n\\n', 'excerpt': ' A recent survey by Clearswift and Yougov shows that 59% of all employees aged 18-29 believe that they should be able to use Web 2.0 social networking sites for their personal use during work time and using corporate computers. This is certainly a shifting tide from the corporate culture of a bygone past when your […] \\n', 'post_date': '2007-03-27T00:00:00-0400', 'categories': ['blog', 'Opinion', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/03/27/is-your-employees-time-your-time/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/30/business-process-management-and-workflow/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Business Process Management and Workflow', 'url': 'https://opensourceconnections.com/blog/2007/03/30/business-process-management-and-workflow/', 'author': 'scott-stults', 'content': ' Business Process Management (BPM) is increasingly appearing in technical articles and executive seminars, but most of the developers I talk to misinterpret BPM to be MBA jargon for workflow management (WFM). Thats not surprising since workflows handle tasks in a single application, and for the majority of organizations that is sufficient. However, BPM is a much larger concept and addresses things like enterprise orchestration rather than document approval states. Here is an excellent article describing the differences in more detail. \\n\\n', 'excerpt': ' Business Process Management (BPM) is increasingly appearing in technical articles and executive seminars, but most of the developers I talk to misinterpret BPM to be MBA jargon for workflow management (WFM). Thats not surprising since workflows handle tasks in a single application, and for the majority of organizations that is sufficient. However, BPM is a […] \\n', 'post_date': '2007-03-30T00:00:00-0400', 'categories': ['blog', 'Business'], 'id': 'https://opensourceconnections.com/blog/2007/03/30/business-process-management-and-workflow/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/03/erics-ruby-gems/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric’s Ruby Gems', 'url': 'https://opensourceconnections.com/blog/2007/04/03/erics-ruby-gems/', 'author': 'eric-pugh', 'content': \" Following Mike Clark’s idea. Im curious to see what gems Ive got installed in 6 months! \\n\\n \\nxativa:~ eric$ gem list|grep '^[a-zA-Z]'\\nactionmailer (1.3.2, 1.3.1, 1.2.5, 1.2.4, 1.2.3, 1.2.1, 1.1.3, 1.0.1)\\nactionpack (1.13.2, 1.13.1, 1.12.5, 1.12.4, 1.12.3, 1.12.1, 1.11.0, 1.9.1)\\nactionwebservice (1.2.2, 1.2.1, 1.1.6, 1.1.5, 1.1.4, 1.1.2, 1.1.1, 0.9.3, 0.8.1)\\nactiverecord (1.15.2, 1.15.1, 1.14.4, 1.14.3, 1.14.2, 1.14.1, 1.13.0, 1.11.1)\\nactivesupport (1.4.1, 1.4.0, 1.3.1, 1.2.3, 1.1.1)\\najax_scaffold_generator (3.1.5, 2.1.0)\\natom (0.3)\\nbuilder (2.0.0)\\ncalendar_grid (1.0.2)\\ncamping (1.5)\\ncapistrano (1.4.0, 1.3.1, 1.2.0, 1.1.0)\\ncgi_multipart_eof_fix (2.0.2)\\ncheat (1.0.2)\\nchronic (0.1.4)\\ncolor-tools (1.3.0)\\ndaemons (1.0.4, 0.4.4)\\ndev-utils (1.0.1)\\nextensions (0.6.0)\\nezcrypto (0.7)\\nfastercsv (1.1.0, 0.2.1)\\nfastthread (0.6.3)\\nflex_egenial_scaffold (0.0.1)\\ngcalapi (0.1.0, 0.0.3)\\ngem_plugin (0.2.2, 0.2.1)\\ngooglecalendar (0.0.2)\\nhoe (1.1.7)\\nhpricot (0.4.43)\\nicalendar (0.98)\\nlibxml-ruby (0.3.8.4)\\nmailfactory (1.2.3, 1.2.2)\\nmarkaby (0.5)\\nmechanize (0.5.4)\\nmetaid (1.0)\\nmime-types (1.15)\\nmoney (1.7.1)\\nmongrel (1.0.1, 0.3.13.3)\\nmongrel_cluster (1.0.1.1, 0.2.1)\\nneedle (1.3.0)\\nnet-sftp (1.1.0)\\nnet-ssh (1.0.10, 1.0.9)\\npaginator (1.0.8)\\npayment (1.0.1)\\npdf-writer (1.1.3, 1.1.1)\\nrails (1.2.2, 1.2.1, 1.1.6, 1.1.5, 1.1.4, 1.1.2, 1.1.1, 0.14.3, 0.13.1)\\nrake (0.7.1, 0.6.2)\\nrb-appscript (0.3.0)\\nRedCloth (3.0.4)\\nruby-web (1.1.1)\\nrubyforge (0.4.0)\\nrubygems-update (0.9.2, 0.9.0)\\nrubyosa (0.1.0)\\nrubyzip (0.9.1)\\nruport (0.8.10, 0.8.1, 0.7.2, 0.7.1, 0.7.0, 0.6.1, 0.4.23, 0.4.19, 0.4.13)\\nscruffy (0.2.2)\\nSelenium (1.0.1)\\nsentry (0.3.1)\\nshipping (1.5.0, 1.3.0)\\nsources (0.0.1)\\nsqlite-ruby (2.2.2)\\nsqlite3-ruby (1.2.1, 1.1.0)\\nstreamlined_generator (0.0.3, 0.0.2)\\ntattle (1.0.1)\\ntransaction-simple (1.3.0)\\ntzinfo (0.3.3)\\nunicode (0.1)\\nvpim (0.360)\\nwebrick-webdav (1.0)\\n \\n\", 'excerpt': '\\n  \\n    \\n      Following Mike Clark’s idea. Im curious to see what gems Ive got installed in 6 months! xativa:~ eric$ gem list\\n      grep ‘^[a-zA-Z]’ actionmailer (1.3.2, 1.3.1, 1.2.5, 1.2.4, 1.2.3, 1.2.1, 1.1.3, 1.0.1) actionpack (1.13.2, 1.13.1, 1.12.5, 1.12.4, 1.12.3, 1.12.1, 1.11.0, 1.9.1) actionwebservice (1.2.2, 1.2.1, 1.1.6, 1.1.5, 1.1.4, 1.1.2, 1.1.1, 0.9.3, 0.8.1) activerecord (1.15.2, 1.15.1, 1.14.4, 1.14.3, 1.14.2, […]\\n    \\n  \\n\\n', 'post_date': '2007-04-03T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/04/03/erics-ruby-gems/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/04/does-the-virtual-world-equal-the-real-world/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Does the virtual world equal the real world?', 'url': 'https://opensourceconnections.com/blog/2007/04/04/does-the-virtual-world-equal-the-real-world/', 'author': 'jason-hull', 'content': ' This is the question that the FBI is asking of Second Life as they investigate Second Lifes casinos. The three biggest casinos, according to the CNN article, make $1,500/month each. Seems like a small thing for the FBI to be investigating given the other crimes in the country, but is this actually an effort to start to establish some sort of case precedent for potential legal scraps in the future? \\n\\n Given that more and more businesses are moving into Second Life, without a way to establish and enforce contracts, the denizens of Second Life who enter into transactions must certainly heed the warning caveat emptor. As it currently stands, people who do things in Second Life are only buying, effectively, the right to certain bits and pieces of the Linden Labs server farm. With nothing but the loosest of guidelines to provide cover, Second Life can sometimes bring back the reminiscent feel of the Internet in the early 90s. \\n\\n Enter the FBI. While the real world crackdown on online gambling by the U.S. Justice Department certainly has the Feds busy, true established case law is very sparse on the subject. I spoke with a former counsel with Party Poker while we were exhibiting at the OReilly Open Source Convention (OSCON) last year, and she told me that because of the lack of established statutes and case law, the courts could come down either way on online gambling activities. Perhaps the Justice Department is looking to get a ruling on a similar set of circumstances in Second Life to help bolster the Internet gambling ban. \\n\\n', 'excerpt': ' This is the question that the FBI is asking of Second Life as they investigate Second Lifes casinos. The three biggest casinos, according to the CNN article, make $1,500/month each. Seems like a small thing for the FBI to be investigating given the other crimes in the country, but is this actually an effort to […] \\n', 'post_date': '2007-04-04T00:00:00-0400', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/04/04/does-the-virtual-world-equal-the-real-world/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/09/figuring-out-the-local-timezone-in-ruby-on-osx/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Figuring out the local timezone in Ruby on OSX', 'url': 'https://opensourceconnections.com/blog/2007/04/09/figuring-out-the-local-timezone-in-ruby-on-osx/', 'author': 'eric-pugh', 'content': ' I am starting to hit some of the odd corners of Ruby. For example, I want to know what the local timezone of my Mac is. I can run Time.now and parse the output, but unfortunately I get back EDT, and the TZinfo library cant parse that because its not a standard timezone, throwing an TZInfo::InvalidTimezoneIdentifier. \\n\\n I did discover however that on OSX the file /etc/localtime is sym-linked to the correct timezone file! When I did ls -l /etc/localtime I got back /usr/share/zoneinfo/US/Eastern, which gives me something to parse that TZInfo will understand. \\n\\n Below is my unit test that demonstrates my progress in hacking to a solution! Hopefully this will help anyone else. \\n\\n My solution is very brittle, but should work for now. Anyone have a better suggestion, please speak up!!! \\n\\n ```ruby\\ndef test_getting_local_timezone\\nt = Time.now\\nassert_equal EDT, t.strftime(%Z) \\n\\n assert_raise(TZInfo::InvalidTimezoneIdentifier) { Timezone.get(`EDT)} \\n\\n result = %x[ls -l /etc/localtime]\\nputs result \\n\\n assert_match ‘/etc/localtime -&gt; /usr/share/zoneinfo/US/Eastern’, result, ‘Make sure we get back US/Eastern. This only works when you are in US/Eastern Timezone!’ \\n\\n string = ‘lrwxr-xr-x 1 root wheel 30 Jan 17 20:38 /etc/localtime -&gt; /usr/share/zoneinfo/US/Eastern’\\nsplit = string.split(‘/’)\\nassert_equal 8, split.size\\ntimezone = ‘#{split[split.size-2]}/#{split.last}’\\nassert_equal ‘US/Eastern’, timezone \\n\\n end\\n``` \\n', 'excerpt': ' I am starting to hit some of the odd corners of Ruby. For example, I want to know what the local timezone of my Mac is. I can run Time.now and parse the output, but unfortunately I get back EDT, and the TZinfo library cant parse that because its not a standard timezone, throwing an […] \\n', 'post_date': '2007-04-09T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/04/09/figuring-out-the-local-timezone-in-ruby-on-osx/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/11/google-calendar-api-accepts-bad-data/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Google Calendar API accepts bad data!', 'url': 'https://opensourceconnections.com/blog/2007/04/11/google-calendar-api-accepts-bad-data/', 'author': 'eric-pugh', 'content': ' If youve been reading my posts lately, youve noticed lots of posts about parsing working with Time and Dates in Ruby. This has been because my hobby project has been to write a Ruby tool for synchronizing my Apple iCal calendar to my Google Calendar. \\n\\n This project is published on RubyForge as Novo, and is finally nearing a 0.1 release. \\n\\n As Ive been working on flushing out a lot of the bugs, Ive learned quite a bit about the GData API. And one of the things Ive noticed is that you can create bad data in their system via the REST API pretty easily. My code had a bug where it wasnt converting Times properly when inserting events into gCal, so I managed to put the same event in twice, once without start and end times, and once with! Unfortunately I cant delete the bad entry through the Google Calendar interface. It shows up in searches, but not in the listing: \\n\\n  \\n\\n Because of a couple of bad calendar entries that I created during development, Ive add an ignore option so that the bad entries can be permanently ignored. \\n\\n As I get closer to the Novo 0.1 release Ill post more about the tool \\n', 'excerpt': ' If youve been reading my posts lately, youve noticed lots of posts about parsing working with Time and Dates in Ruby. This has been because my hobby project has been to write a Ruby tool for synchronizing my Apple iCal calendar to my Google Calendar. This project is published on RubyForge as Novo, and is […] \\n', 'post_date': '2007-04-11T00:00:00-0400', 'categories': ['blog', 'Code', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/04/11/google-calendar-api-accepts-bad-data/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/12/producing-html-output-from-nunit/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Producing HTML output from NUnit?', 'url': 'https://opensourceconnections.com/blog/2007/04/12/producing-html-output-from-nunit/', 'author': 'eric-pugh', 'content': ' As part of our build process we run NUnit and NCover over some C# code. We are currently focusing on getting our code coverage up from the measly ~18% that the project is at. \\n\\n One of the developers asked me to make it easier to find out which test failed versus parsing through 100s of lines of raw build output. We already have NCover producing nice HTML reports of the code coverage metrics, so I figured I could do the same with the NUnit XML file as well. \\n\\n Much to my dismay, it appears that you are expected to use the NUnit GUI application to parse the failure results! The only existing conversions to HTML that I could find was this blog posting on Automating NUnit and MSTest Builds. I tried out the conversion from XML to text output, and that was better, but very ugly. \\n\\n Daniel Irvine commenting on the new NUnit 2.4 release also mentions that the XSLT transformation of the raw data is something hes looking for as well! \\n\\n If anyone has any suggestions, please let me know. I hope I havent talked myself into creating the XSLT transformation tool for NUnit!! \\n', 'excerpt': ' As part of our build process we run NUnit and NCover over some C# code. We are currently focusing on getting our code coverage up from the measly ~18% that the project is at. One of the developers asked me to make it easier to find out which test failed versus parsing through 100s of […] \\n', 'post_date': '2007-04-12T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/04/12/producing-html-output-from-nunit/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/16/upgrading-to-subversion-14-on-a-fedora-core-4-server/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Upgrading to Subversion 1.4 on a Fedora Core 4 Server', 'url': 'https://opensourceconnections.com/blog/2007/04/16/upgrading-to-subversion-14-on-a-fedora-core-4-server/', 'author': 'scott-stults', 'content': ' Yesterday Eric asked me to upgrade our Subversion version from 1.2 to 1.4 in order to take advantage of the new XML responses needed by CruiseControl.rb. My first clue that this wasnt going to be easy was that the stock yum repositories only carry version 1.2. After a little digging I found an RPM that had version 1.4, but that carried with it a stack of other RPM dependencies that I decided not to try to untangle (been there, hated that.) \\n\\n CollabNet Subversion \\n\\n My next step was to try the recommended enterprise configuration from CollabNet. I really didnt realize what I was getting myself into, but the result was a 1.4 version of Subversion bundled with its own Apache server. Now, Ive been tweaking our trac-Apache-Subversion deployment quite a bit to make project creation quick and properly integrated. The thought of throwing in another Apache server into the mix didnt seem manageable, and recreating what I did with our current Apache server looked like a serious undertaking. So, “rpm –erase” and back to the drawing board. \\n\\n subversion-1.4.3.tar.bz2 \\n\\n “When in doubt, build from the source.” Building Subversion from the sources is pretty much what Ive come to expect from the ./configure, make, make install cycle. I made sure I also downloaded the subversion-deps tarball recommended in the release notes, and followed it to the letter. The result was a broken svn client. \\n\\n svn undefined symbol: SSL_load_error_strings \\n\\n The Subversion server seemed to be working well behind Apache and trac, but Erics CC.rb builds were failing with an SSL error. I verified the error from the command-line and did some more Googling. A few hits down I ran across this post and this email thread which helped me greatly. The only thing standing in my way was a stupid bit of automation I failed to account for. \\n\\n Could not read status line: Secure connection truncated \\n\\n I banged my head against this one for much longer. Google failed me, rebuilds failed me. I had a thought that maybe I forgot to restart Apache after one of the rebuilds, and I noticed that it was complaining that the svn modules had already been loaded so they wouldnt be loaded again. I had seen this in an earlier restart and just thought, “Okay, Ill clean that up once I get this Subversion thing to work.” However, if I had bothered to look at the httpd.conf Id have seen that my “make install” had added the correct LoadModule line pointing to the new module, but the old LoadModule was left in place pointing to the old module. The old LoadModule happened before the new one, so I was loading an incompatible module. Once I pulled out the old module there was joy in Mudville once again. \\n\\n', 'excerpt': ' Yesterday Eric asked me to upgrade our Subversion version from 1.2 to 1.4 in order to take advantage of the new XML responses needed by CruiseControl.rb. My first clue that this wasnt going to be easy was that the stock yum repositories only carry version 1.2. After a little digging I found an RPM that […] \\n', 'post_date': '2007-04-16T00:00:00-0400', 'categories': ['blog', 'System Administration'], 'id': 'https://opensourceconnections.com/blog/2007/04/16/upgrading-to-subversion-14-on-a-fedora-core-4-server/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/18/a-web-20-bubble/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'A Web 2.0 Bubble?', 'url': 'https://opensourceconnections.com/blog/2007/04/18/a-web-20-bubble/', 'author': 'jason-hull', 'content': ' Reuters reported this morning that the number of contributors to many Web 2.0 sites such as YouTube and Flickr is much smaller than the number of people who come to look at the content generated. With the glaring exception of Wikipedia, the average tends to run around 500 viewers for each contributor. At first glance, this might seem like a shock given that Web 2.0 applications are supposed to make it easier for the user to participate and contribute, but further examination shows that maybe its not surprising after all. \\n\\n First, let us look at the ease with which users can add content. The original “category killer” was the blog, where within minutes, people would be able to set up their own commentary site and become the next Bill Kristol or Fred Barnes. While creation of blogs continues at a rapid pace, Technorati reports that there are 1.5 million posts daily to a population of approximately 57 million blogs, or about a 2% contribution rate. That is for a medium which requires no additional equipment besides a computer. Once you add in digital equipment necessary to create the media for many Web 2.0 sites, it is not surprising that the contribution rate drops. \\n\\n\\n Secondly, it seems that human nature is a contributing factor to this phenomenon. Garret Hardins \\n\\n Tragedy of the Commons succinctly explains what is happening here. Any time you have a contribution to the public good (as the site owners would argue these sites are), many more people will take advantage of the public good than will contribute to it. These “free riders” are happy to take part and take advantage of the common good, but few will pony up resources to keep it going for everyone else. That is why public radio has to have fundraising drives all of the time and why street performers only have the scantest of change in their tip jars. \\n\\n Does this mean that the Web 2.0 sites should pack up and go home? No. Aside from the most altruistic of creators, the purpose of these sites is profit. Profit is generated on these sites almost exclusively from advertising revenue. What draws advertising revenue? Visits to the site. So, even if these sites have an incredibly skewed proportion of contributors to viewers, they still have viewers, and the contributors are free staff, meaning that the cost of content generation is zero. One of the biggest variable costs in a fixed media such as a newspaper, the staff needed to create the content, is eliminated in Web 2.0 sites. As Flickr and YouTube have proven, it does not take many content creators to drive an enormous amount of traffic. \\n\\n', 'excerpt': ' Reuters reported this morning that the number of contributors to many Web 2.0 sites such as YouTube and Flickr is much smaller than the number of people who come to look at the content generated. With the glaring exception of Wikipedia, the average tends to run around 500 viewers for each contributor. At first glance, […] \\n', 'post_date': '2007-04-18T00:00:00-0400', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/04/18/a-web-20-bubble/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/26/parsing-ruby-for-porting/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Parsing Ruby for Porting', 'url': 'https://opensourceconnections.com/blog/2007/04/26/parsing-ruby-for-porting/', 'author': 'scott-stults', 'content': ' Ive recently started a research project to port a Ruby workflow engine (OpenWFEru) to Python. I thought that if I could write a basic Ruby parser I could at least form the skeleton of my project (since package, module, and class notations are similar between the languages, and mapping the Abstract Syntax Tree to actual code would be a breeze.) \\n\\n I did a little Googling to find a Ruby grammar that I could work from, and there seemed to be a little activity around using Antlr. Antlr does support generating Python parsers, so I downloaded it and the Ruby grammar and gave it a shot. \\n\\n When I ran Antlr against the grammar I got a bunch of warnings about lexical non-determinism. That didnt surprise me given Rubys complexity, but a parser and a lexer was generated and I hoped that it would suffice. However, my hopes were immediately dashed when I fed actual Ruby code into the lexer: \\n\\n error: exception caught while lexing: unexpected char: `# \\n\\n It didnt understand comments!\\nI really only wanted to spend a little time on this portion of the project (whats commonly referred to as a “spike”) so thats as far as I took it. The Antlr docs spoke of comment ambiguity in the Python parsers, but I didnt have time to dig deeper.\\nAlong the way I Googled to see how the Python community handles its parser generator needs, and ran across this excellent analysis. YAPPS seemed to be the clear winner in that case, but in order to use a different parser I would probably need to translate the only Ruby grammar I found into a different syntax. \\n\\n So for now Ill be using the parser generator between my ears and lexing with my eyes. If anyones had better success at parsing Ruby, please leave a comment below. \\n\\n', 'excerpt': ' Ive recently started a research project to port a Ruby workflow engine (OpenWFEru) to Python. I thought that if I could write a basic Ruby parser I could at least form the skeleton of my project (since package, module, and class notations are similar between the languages, and mapping the Abstract Syntax Tree to actual […] \\n', 'post_date': '2007-04-26T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/04/26/parsing-ruby-for-porting/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-code-metrics/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'CITcon 2007: Code Metrics', 'url': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-code-metrics/', 'author': 'eric-pugh', 'content': ' Notes from the Code Metrics session: \\n\\n What kind of code metrics do you collect? \\n\\n \\n   Complexity \\n   Coverage \\n   Dependencies \\n   Documentation \\n   Code Style \\n   \\n     of unit tests, line of code \\n   \\n   Code Duplicates \\n   Volatility \\n   Velocity \\n \\n\\n Great first metric is volatility or churn: the number of commits in a specific area contracted to complexity. Volatility comes from version control data, complexity is produced by a script. Gives you a solid feel of where potential bugs are, typically where there are lots of commits in a complex area as measured by your complexity tool. \\n\\n “Cyclomatic Complexity” apparently has lots of research behind it proving that high complexity leads to bugs, and that this is really good spot to look at in reducing code. \\n\\n Metrics are much more valuable when you have them in a historical context. Hackystat (a favored tool of mine!) gets a plug. Sabre has developed a home grown system that parses reports and adds them to Mysql… They could use HackyStat for similar function. \\n\\n Demo/introduction of Panopticode. Visualizes metrics with the goal of making the use of metrics simple and ubiquitous. \\n\\n I think Ill be looking very closely at Panopticode, and how visualizations can help make metrics more relevant to management and teams, versus just some charts that are never acted on. \\n', 'excerpt': ' Notes from the Code Metrics session: What kind of code metrics do you collect? * Complexity * Coverage * Dependencies * Documentation * Code Style * # of unit tests, line of code * Code Duplicates * Volatility * Velocity Great first metric is volatility or churn: the number of commits in a specific area […] \\n', 'post_date': '2007-04-28T00:00:00-0400', 'categories': ['blog', 'Conference', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-code-metrics/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-notes/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'CITcon 2007 Notes', 'url': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-notes/', 'author': 'eric-pugh', 'content': ' Im at CITcon (pronounced kitcon) 2007 in Dallas/Ft Worth. There are around 60 people here from all across the United States, including some of the heavy hitters of the Testing/Agile world including Martin Fowler, Chief Scientist of ThoughtWorks, Jason Huggins, inventor of Selenium, and Bret Pettichord, inventor of Watir, plus many more. Its been a great opportunity to meet many other folks that Ive heard of like Andrew Glover, president of Stelligent, who has been one of the key users and writers about DBUnit. \\n\\n CITcon uses the “OpenSpaces” format for running a conference. OpenSpaces encourages adhoc converstation and audience involvment by leaving the schedule and topics up to the particpants. No boring lectures, just lots of group discussion. \\n\\n Last night we were given the basic schedule of sessions and rooms:\\n \\n\\n Then we came up with various session ideas. We came up with more sessions then we had time for, so over drinks people discussed the various proposals, and voted with tick marks what sessions interested them. Eventually a schedule solidified through negotiation between folks. My proposal is in “Green Lantern” at 3:15 PM, second row, fifth column in the chart!\\n \\n\\n This morning we were all standing in the hall seeing what the schedule had changed to:\\n \\n', 'excerpt': ' Im at CITcon (pronounced kitcon) 2007 in Dallas/Ft Worth. There are around 60 people here from all across the United States, including some of the heavy hitters of the Testing/Agile world including Martin Fowler, Chief Scientist of ThoughtWorks, Jason Huggins, inventor of Selenium, and Bret Pettichord, inventor of Watir, plus many more. Its been a […] \\n', 'post_date': '2007-04-28T00:00:00-0400', 'categories': ['blog', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-notes/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-retrospective/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'CITcon 2007: Retrospective', 'url': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-retrospective/', 'author': 'eric-pugh', 'content': ' Its been an incredible day of meeting amazing people who are doing amazing things. Being with 40 of my peers in the CI field for a day and a half has been wonderfully invigorating. \\n\\n We had a wonderful setup, with plenty of large rooms and some great snacks: \\n\\n  \\n\\n The rooms had many rolling office chairs in each, and no tables, which led to ad hoc groupings and a flexible mindset towards the conference: \\n\\n  \\n\\n We wrapped up with a “retrospective” where we shared what we got out of the time, and our thoughts about the conference. A little different from a 5000 person conference like OSCON! \\n\\n  \\n\\n  \\n\\n Being able to have discussions with people like Martin Fowler over a beer or in a small group environment made this possibly my best conference ever! \\n', 'excerpt': ' Its been an incredible day of meeting amazing people who are doing amazing things. Being with 40 of my peers in the CI field for a day and a half has been wonderfully invigorating. We had a wonderful setup, with plenty of large rooms and some great snacks: The rooms had many rolling office chairs […] \\n', 'post_date': '2007-04-28T00:00:00-0400', 'categories': ['blog', 'Conference', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-retrospective/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-rspec-is-the-new-testunit/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'CITcon 2007: RSpec is the new Test::Unit', 'url': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-rspec-is-the-new-testunit/', 'author': 'eric-pugh', 'content': ' My first session was entitled RSpec is great of what? and talked about a tool that helps you do “Behavior Driven Development”. The key difference between RSpec as a validation tool from other xUnit tools like JUnit or Test::Unit is that instead of using “Assert” style validations we use “Should” style validations. Here is a short example of pulling up a web page and verifying the words “Administer Bookshelf” show up. \\n\\n $ie = $ie || Watir::IE.new\\n$ie.goto http://localhost:3000/login/login\\n$ie.text.should include(Administer Bookshelf) \\n\\n Compare the last line to something in the older “Assert” style: \\n\\n assert $ie.text.include?(`Adminster Bookshelf) \\n\\n The should syntax reads much easier! And by removing the word “test” from your vocabulary you remove the Tester/Developer divide. “Should” is something you would define before writing the code. “Test” is something you do after you write the code! \\n', 'excerpt': ' My first session was entitled RSpec is great of what? and talked about a tool that helps you do “Behavior Driven Development”. The key difference between RSpec as a validation tool from other xUnit tools like JUnit or Test::Unit is that instead of using “Assert” style validations we use “Should” style validations. Here is a […] \\n', 'post_date': '2007-04-28T00:00:00-0400', 'categories': ['blog', 'Conference', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-rspec-is-the-new-testunit/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/03/openwfepy-and-dynamic-language-toolkit/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'OpenWFEpy and Dynamic Languages Toolkit', 'url': 'https://opensourceconnections.com/blog/2007/05/03/openwfepy-and-dynamic-language-toolkit/', 'author': 'scott-stults', 'content': ' As I noted in an earlier post, I just started a project called OpenWFEpy. Its a Python port of the OpenWFE workflow engine, and if youd like to be on the mailing list just let me know. \\n\\n In between bouts of manually converting the files, Ive been searching for some automation I can use to help me. One possibility I explored was creating a Ruby parser using Antlr. For whatever reason that didnt prove as fruitful as Id hoped, but Andrew left me an interesting comment regarding an Eclipse plugin project called Dynamic Languages Toolkit (DLTK). \\n\\n As the name implies, DLTK is designed to be a common framework from which to build dynamic language IDEs. If youve tried to use Eclipse for anything other than Java programming, youve probably witnessed widely varying feature sets between language plugins. Its API bridges the gap between the Eclipse framework and a language parser, so once you have a parser built and plugged into the API, all the cool features of a great IDE are immediately available to you. \\n\\n Included in the toolkit is a Ruby IDE that they built on their API. They didnt include the grammar, but as long as the parser isnt coupled too tightly I could either use it stand-alone or add some sort of “Convert to Python” refactoring. This path seems a little more promising than building from scratch the parser Ill need, but as with the earlier spike, if I spend too much time getting to know the tools Ill have less time to do the actual work.   \\n', 'excerpt': ' As I noted in an earlier post, I just started a project called OpenWFEpy. Its a Python port of the OpenWFE workflow engine, and if youd like to be on the mailing list just let me know. In between bouts of manually converting the files, Ive been searching for some automation I can use to […] \\n', 'post_date': '2007-05-03T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/05/03/openwfepy-and-dynamic-language-toolkit/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/03/rspec-simplifies-communications/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'RSpec simplifies communications?', 'url': 'https://opensourceconnections.com/blog/2007/05/03/rspec-simplifies-communications/', 'author': 'eric-pugh', 'content': ' At CITcon, I learned a lot about RSpec, a Ruby library for writing out specifications that is used in BDD: Behavior Driven Development. \\n\\n This has got me to thinking about one of the key challenges in software development: communciation. We spend massive amounts of time retelling requirements from one person to another, and translating them from one format to another. A Business Analyst writes up the requirements in a Word document. A developer translates those requirements into unit tests and code, and lastly a Tester verifies the functionality using yet another suite of testing tools! Its no wonder so many software development projects suffer delays. \\n\\n One of the key points that Martin Fowler made at CITcon was that he expected the roles of Business Analyst and Tester to merge, and the roles of Developer and Tester to merge. If you think about it, it makes sense. The Business Analyst knows best what the results should be, so shouldnt that person be the one testing the code works correctly? And, the Developer is the one who knows (or should know!) what the weakest points in the code are, and so they should be best suited to test the code. \\n\\n So what does merging roles have to do with RSpec? Easy, RSpec is currently the best lightweight way of writing specifications the way a Business Analyst might, that are runnable tests that a Tester might run. Now, I know that there are lots of ways of poking holes in this statement, but as a thought experiment, Rob, a colleague of mine, and I are going to attempt this, with me filling the role of the merged Business Analyst/Tester, and him as the developer. We need to write a bit of code for a shipping module for an ecommerce site that has somewhat unusual pricing rules. I have written some RSpec specifications that currently fail, and hell write the code until they pass. All without us communicating except via the specifications that Ive written. \\n\\n I ran rake spec:doc and produced this summary of the specifications I had written: \\n\\n ```\\nShipping for non-combineable products\\n- should have the base price for just one\\n- should multiple linerarly the base price for more then one \\n\\n Shipping for combineable product\\n- should have the base price, and extra fields filled in, but not used for just one\\n- should add shipping_factor_second to shipping base for two items\\n- should add shipping_factor_third to shipping_factor_second to shipping_base for three items\\n- should keep adding on the third_shipping_factor for any additional items beyond 3 \\n\\n shipping for multiple types of products\\n- should handle combinable and noncombinable products in same cart\\n``` \\n\\n Quite nice output from just pulling data out of some RSpec code, looks somewhat like what I would write as some requirements. Ill be posting a followup on how Rob does with just those specifications to use in grokking my meaning! \\n', 'excerpt': ' At CITcon, I learned a lot about RSpec, a Ruby library for writing out specifications that is used in BDD: Behavior Driven Development. This has got me to thinking about one of the key challenges in software development: communciation. We spend massive amounts of time retelling requirements from one person to another, and translating them […] \\n', 'post_date': '2007-05-03T00:00:00-0400', 'categories': ['blog', 'Code', 'Opinion', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/05/03/rspec-simplifies-communications/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/03/scrum-war-stories-is-coming/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Scrum War Stories is coming!', 'url': 'https://opensourceconnections.com/blog/2007/05/03/scrum-war-stories-is-coming/', 'author': 'eric-pugh', 'content': ' Come share your experiences with implementing Scrum with your peers at West Main Seafood next Wednesday, May 9th from 5:30 to 8. Over beer and dinner well share hard won lessons from the trenches of Scrum, what the cool tools are to support Scrum teams, and maybe even get philosophical and talk about where we think Scrum will be in a couple of years! \\n\\n Jeff Sutherland, co-creator of Scrum came to Charlottesville to present to the Neon Guild about Scrum. When he asked who was using it, maybe 40% of the room raised their hands! So clearly there are already a pool of Scrum practitioners, but we dont have a forum for sharing our experiences. Scrum War Stories will be a very casual event, open to anyone, from those doing Scrum, to those thinking about it! \\n\\n When: May 9th from 5:30 to 8 PM \\n\\n Where: West Main Seafood (old Awful Arthurs) map \\n\\n Who: Anyone who is using Scrum, thinking about Scrum, or quit using Scrum! \\n\\n Help: Eric@ 434-466-1467 or epugh@opensourceconnections.com \\n', 'excerpt': ' Come share your experiences with implementing Scrum with your peers at West Main Seafood next Wednesday, May 9th from 5:30 to 8. Over beer and dinner well share hard won lessons from the trenches of Scrum, what the cool tools are to support Scrum teams, and maybe even get philosophical and talk about where we […] \\n', 'post_date': '2007-05-03T00:00:00-0400', 'categories': ['blog', 'Community', 'News'], 'id': 'https://opensourceconnections.com/blog/2007/05/03/scrum-war-stories-is-coming/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/03/turning-waterfall-contracts-into-scrum-contracts/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Turning Waterfall Contracts into Scrum Contracts', 'url': 'https://opensourceconnections.com/blog/2007/05/03/turning-waterfall-contracts-into-scrum-contracts/', 'author': 'scott-stults', 'content': ' This Monday we were fortunate to hear Dr. Jeff Sutherland give a presentation on Scrum at our monthly Neon Guild meeting. He was going to be doing some training at Inova Solutions, but the Guild got a great overview of Scrum as an added bonus. \\n\\n One of the difficulties Dr. Sutherland touched on during his presentation was introducing Scrum to managers who only know of the “waterfall” method of running projects. I think this mainly impacts contracting organizations at two key points: Requirements Gathering and Delivery. \\n\\n Chunking \\n\\n The first challenge is to break large projects into smaller ones. Customers envision the final product with varying clarity. However, when they put their trust in an outside organization to deliver it they want to know exactly what they are going to be getting for their money. So, at the outset of a project they seek to protect their investment through rigorous requirements gathering and design phases. This gets exacerbated every time those involved go through a failed project, because smart managers seek to fix their processes and not the minutiae particular to any one project. Therefore the process that bares the brunt of their scrutiny is Requirements Gathering (and by association, Design.)\\nI believe the key here is to show how breaking their project into smaller chunks limits their overall exposure and gives them the flexibility to adjust the project requirements as business needs change. After all, the goal of any project is to address business needs and not a particular distillation of them represented by a requirements document. The map is not the territory. \\n\\n Deliverables \\n\\n However, the chunking of the project must also include a modification of delivery expectations. In Waterfall projects, success is measured by three questions: Was it on time, Was it within budget, and Do all features work? What burns longer projects is the Sisyphean nature of technology, in that the features you build become obsolete as you create them. The longer it takes you to deliver, the more irrelevant the project becomes. Therefore, each subproject or Sprint addresses what the customer needs right now, rather than several months down the road. In a lot of ways this breaks the PMI definition of “project” in that the end state is less defined. But since you are incorporating change into the contract, that end state is going to be much more useful to the client. \\n\\n The Contract \\n\\n Which brings us to the contract itself. You will need to translate your Scrum project into a contract that will pass legal scrutiny. This means that you have to adjust traditional contracts that state “We will do X by Y for $Z.” Those contracts place little or no responsibility on the client beyond an initial requirements specification, acceptance testing, and payment. In Scrum, customer participation in the Sprint Review is essential, and belongs in the contract. One strategy could be to only contract for the initial Sprint. But if the client is already thinking Big Project, you could trade features that are contractual obligations for Sprint Reviews that are contract termination clauses. In either case, the responsibility of project “success” is going to be shared much more than in a traditional project. As compensation, “success” will no longer be check marks on a project plan but a measurable increase in business value. \\n\\n', 'excerpt': ' This Monday we were fortunate to hear Dr. Jeff Sutherland give a presentation on Scrum at our monthly Neon Guild meeting. He was going to be doing some training at Inova Solutions, but the Guild got a great overview of Scrum as an added bonus. One of the difficulties Dr. Sutherland touched on during his […] \\n', 'post_date': '2007-05-03T00:00:00-0400', 'categories': ['blog', 'Business', 'Project Management'], 'id': 'https://opensourceconnections.com/blog/2007/05/03/turning-waterfall-contracts-into-scrum-contracts/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/08/capturing-rake-return-codes/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Capturing Rake return codes', 'url': 'https://opensourceconnections.com/blog/2007/05/08/capturing-rake-return-codes/', 'author': 'eric-pugh', 'content': ' Based on Martin Fowlers whole pitch on declarative versus imperative builds, I converted a basic Ruby script into a Rake based script. However, the one gotcha I hit was that running rake dist, the return code wasnt returned. Yes, rake would say it failed: \\n\\n \\n(in E:/irocket/continuum/working-directory/6)\\nrake aborted!\\nI should fail the build\\nE:/irocket/continuum/working-directory/6/rakefile:310\\n \\n\\n We are using Continuum, a very simple to set up CI tool, and it requires whatever script it calls to return 0 on success, and &gt; 0 on failure. So even though Rake would say the build failed, it always return 0. It turns out that some people have run into this problem: \\n\\n \\n   Rake bug on Windows \\n   Ruby Gem Creates Broken Batch File for Rake \\n \\n\\n I didnt want to hack up my rake.bat and rake.cmd files, so instead I am calling ruby directly: \\n\\n \\nruby -x e:\\\\irocket\\\\ruby\\\\bin\\\\rake.bat dist\\n \\n\\n Hopefully the next version of Rake will have this resolved! The Continuum project went through this same pain for Ant and Maven scripts, and have posted their fixed batch files. \\n', 'excerpt': ' Based on Martin Fowlers whole pitch on declarative versus imperative builds, I converted a basic Ruby script into a Rake based script. However, the one gotcha I hit was that running rake dist, the return code wasnt returned. Yes, rake would say it failed: (in E:/irocket/continuum/working-directory/6) rake aborted! I should fail the build E:/irocket/continuum/working-directory/6/rakefile:310 We […] \\n', 'post_date': '2007-05-08T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/05/08/capturing-rake-return-codes/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/08/corrupting-jruby-to-my-pythonic-ways/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Corrupting JRuby to My Pythonic Ways', 'url': 'https://opensourceconnections.com/blog/2007/05/08/corrupting-jruby-to-my-pythonic-ways/', 'author': 'scott-stults', 'content': ' Last week I downloaded the source to JRuby and began poking around its source. My hope is that eventually I can convince it that converting Ruby source to Python is a better use of its time than Java class files. Ive had to decipher large Java projects before and I was dreading the prospect of untangling inter-class dependencies, but as it turns out, JRuby is a great example of how to modularize. I think its also an example of how unit tests can show developers new to a project how to use it.\\nThe packages in JRuby are mostly dedicated to interpreting Abstract Syntax Trees (AST) into Java, but the lexer and parser packages are tantalizingly close to the root. After a quick survey of the classes contained therein, I took a look at what sort of unit tests were available specifically for the parser. \\n\\n One of the things I found during my package perusal was something called an AST node visitor. Better than that, I found a specific package for node rewriting. Better still, there was a unit test for it! Presumably this is for code reformatting of Ruby itself, but\\nAfter running the unit test and checking out what it did, I created a new project and started hacking. The built in rewriter doesnt do anything interesting – it just regurgitates what its fed without comments – so my first job was to try a little tweak that rewrites a Ruby subclass from “subclass &lt; parentclass” to Pythons “subclass(parentclass):”. Since JRuby already told me how to test this thing, it was simplicity itself to verify that my change had its desired affect. \\n\\n Ive only begun to pick at the syntax differences between Ruby and Python, but going through each compilation unit has the advantage of providing a road map. Its also started me thinking about one layer above base syntax to simple code refactoring. Another interesting possibility is the use of AST graphs as a tool for code review. I guess I should reexamine the joys of Metaprogramming! \\n\\n', 'excerpt': ' Last week I downloaded the source to JRuby and began poking around its source. My hope is that eventually I can convince it that converting Ruby source to Python is a better use of its time than Java class files. Ive had to decipher large Java projects before and I was dreading the prospect of […] \\n', 'post_date': '2007-05-08T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/05/08/corrupting-jruby-to-my-pythonic-ways/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/10/scrum-war-stories-recap-2/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Scrum War Stories Recap', 'url': 'https://opensourceconnections.com/blog/2007/05/10/scrum-war-stories-recap-2/', 'author': 'eric-pugh', 'content': ' Last night we had wonderful participation for our first Scrum War Stories dinner, with 9 folks from 7 different organizations showing up at West Main. The discussions we had were wide ranging and for me the value was in the interaction with my peers! \\n\\n The main themes that came up over dinner from my POV were: \\n\\n \\n   \\n     Change is hard. People reach a comfort level in their own niche, and dont see the larger problems challenging the business that they need to change to overcome. \\n   \\n   \\n     Oldstyle approaches to supervising project teams dont work. With 3 week Sprints, there isnt enough time for an outside group to influence the Scrum team. I argued that instead of an outside group supervising/inspecting the Scrum team, they need to merge. They need to be members of the team, or be the Product Owner. \\n   \\n   \\n     Strong Product Owners are key! \\n   \\n \\n\\n  \\n\\n Scott Stults mentioned that the term “Sprint” really is a misnomer, because you arent sprinting to a finish line, but instead maintaining a constant pace, that allows time for other things like process improvement, people on vacation, technical development. He proposed the term “Relay”, which I really liked. In a relay, different people handle the baton, and the results arent measured on any individuals performance, but the performance of the team as a whole. \\n\\n Not sure how we get the Scrum world to change from “Sprint” to “Relay”, but I may start trying to use it in everyday speech. \\n\\n Many thanks to everyone who showed up, and a big thank you to Aaron Buchanan from Inova for cosponsoring the event with me, it wouldnt have happened without his enthusiasm. \\n', 'excerpt': ' Last night we had wonderful participation for our first Scrum War Stories dinner, with 9 folks from 7 different organizations showing up at West Main. The discussions we had were wide ranging and for me the value was in the interaction with my peers! The main themes that came up over dinner from my POV […] \\n', 'post_date': '2007-05-10T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2007/05/10/scrum-war-stories-recap-2/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/15/learn-about-selenium-betech-tomorrow/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Learn about Selenium @beTech tomorrow!', 'url': 'https://opensourceconnections.com/blog/2007/05/15/learn-about-selenium-betech-tomorrow/', 'author': 'eric-pugh', 'content': ' Ill be presenting Selenium for beTech tomorrow in Newcomb Hall at 2 PM! \\n\\n Im throwing out my old Selenium presentation that has served me well, taking me to such conferences as OSCON in Portland, Oregon, a testing conference in Valencia, Spain, and of course at our own local Neon Guild conference and doing something completely new, focusing on themes and possibilities of using Selenium versus dry technical details. See you tomorrow! \\n', 'excerpt': ' Ill be presenting Selenium for beTech tomorrow in Newcomb Hall at 2 PM! Im throwing out my old Selenium presentation that has served me well, taking me to such conferences as OSCON in Portland, Oregon, a testing conference in Valencia, Spain, and of course at our own local Neon Guild conference and doing something completely […] \\n', 'post_date': '2007-05-15T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2007/05/15/learn-about-selenium-betech-tomorrow/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/24/how-to-ignore-files-in-subversion/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'How to ignore files in Subversion', 'url': 'https://opensourceconnections.com/blog/2007/05/24/how-to-ignore-files-in-subversion/', 'author': 'eric-pugh', 'content': ' For some reason, adding files and directories to ignore in Subversion is much harder then in CVS. \\n\\n The syntax, as it you are editing a .cvsignore file is: \\n\\n svn propedit svn:ignore . –editor-cmd vi \\n\\n Just add your patterns and then do \\n\\n svn ci -m `adding new svn:ignore patterns . \\n', 'excerpt': ' For some reason, adding files and directories to ignore in Subversion is much harder then in CVS. The syntax, as it you are editing a .cvsignore file is: svn propedit svn:ignore . –editor-cmd vi Just add your patterns and then do svn ci -m `adding new svn:ignore patterns . \\n', 'post_date': '2007-05-24T00:00:00-0400', 'categories': ['blog', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/05/24/how-to-ignore-files-in-subversion/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/29/tech-leads-should-lead/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Tech leads should lead', 'url': 'https://opensourceconnections.com/blog/2007/05/29/tech-leads-should-lead/', 'author': 'jason-hull', 'content': ' Our tech leads love being eyeball deep in code because they love being coders.\\xa0 However, sometimes this creates problems because we need them to lead multiple projects.\\xa0 When tech leads get too deep into the code, two things happen: 1) they cannot pull away to perform the same role on other projects, and 2) they do not maintain perspective on the code that theyre deep into.\\xa0 Tech leads need to be there to perform code review and to crack the tough nuts.\\xa0 Other team members are there to code.\\xa0 IT managers are wise to help their tech leads maintain their distance. \\n', 'excerpt': ' Our tech leads love being eyeball deep in code because they love being coders.\\xa0 However, sometimes this creates problems because we need them to lead multiple projects.\\xa0 When tech leads get too deep into the code, two things happen: 1) they cannot pull away to perform the same role on other projects, and 2) they […] \\n', 'post_date': '2007-05-29T00:00:00-0400', 'categories': ['blog', 'Productivity', 'Project Management', 'scrum'], 'id': 'https://opensourceconnections.com/blog/2007/05/29/tech-leads-should-lead/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/30/rails-plugin-fixture_references-has-out-of-date-docs/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Rails plugin ‘fixture_references’ has out of date docs', 'url': 'https://opensourceconnections.com/blog/2007/05/30/rails-plugin-fixture_references-has-out-of-date-docs/', 'author': 'eric-pugh', 'content': ' So I shot about 2 hours today trying to figure out why the use of the fixture_references plugin was causing my fixtures to not load, based on a “Can not convert String to Integer” error. I mucked around with my .yml files, thinking it was in my formatting. Finally giving up, I took a quick peek at the changelog, and discovered the API had changed, but the documentation hadnt! \\n\\n In my fixture I was doing what the docs said: \\n\\n vehicle_make_id: &lt; %= vehicle_makes(:acura)[‘id’] %&gt; \\n\\n But the API had changed so it should be: \\n\\n vehicle_make_id: &lt; %= vehicle_makes(:acura, ‘id’) %&gt; \\n\\n This is why I hate when people use blogs as documentation sites versus wikis.. Blogs are temporal in nature, and dont lend themselves to updates. Hopefully this will spur the developers to update the docs, after all, the plugin is a really nice plugin! \\n\\n This was a problem with AjaxScaffold as well, but the creator didnt make the same mistake with ActiveScaffold, the successor project. \\n', 'excerpt': ' So I shot about 2 hours today trying to figure out why the use of the fixture_references plugin was causing my fixtures to not load, based on a “Can not convert String to Integer” error. I mucked around with my .yml files, thinking it was in my formatting. Finally giving up, I took a quick […] \\n', 'post_date': '2007-05-30T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/05/30/rails-plugin-fixture_references-has-out-of-date-docs/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/06/06/file-uploads-with-selenium/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'File Uploads with Selenium', 'url': 'https://opensourceconnections.com/blog/2007/06/06/file-uploads-with-selenium/', 'author': 'eric-pugh', 'content': ' A colleague pinged my on how to do a file upload from a Selenium script. My smart ass reply was “Did you look at the file_upload tag?”. And then I realized that File Upload is one of those things that the JavaScript security model in browsers makes very difficult. You have to explicitly select a file, which makes sense since you wouldnt want to visit a site that had some evil JavaScript on it that magically uploaded your Quicken data file or some other file that is in a well known location. \\n\\n There are some workarounds, including mucking around with your security model: \\n\\n http://cakebaker.wordpress.com/2006/03/29/file-upload-with-selenium/ \\n\\n The Selenium FAQ also talks about using SeleniumIDE to work around the JavaScript security model. This is also a good solution when testing across multiple servers as well! \\n\\n However, the solution I find preferable is to take advantage of the 80% solution/20% effort that Selenium is out of the box, and not test file uploads directly. Instead, add a helper action like /fileupload?file=path/to/my/file.txt that you can invoke from Selenium. Have the helper action do the basic file upload, just like the webpage does, and then return to testing your site post file upload! This is the simplest, most cross platform approach. Its also a very good pattern for working around other gotchas in Selenium. \\n', 'excerpt': ' A colleague pinged my on how to do a file upload from a Selenium script. My smart ass reply was “Did you look at the file_upload tag?”. And then I realized that File Upload is one of those things that the JavaScript security model in browsers makes very difficult. You have to explicitly select a […] \\n', 'post_date': '2007-06-06T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/06/06/file-uploads-with-selenium/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/06/15/showing-sphereit/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Showing “Sphere”it', 'url': 'https://opensourceconnections.com/blog/2007/06/15/showing-sphereit/', 'author': 'jason-hull', 'content': ' Several of our recent projects have involved different methods of data sorting, manipulation, and visualization. An example of this is now available with the University of Virginia Librarys BlacklightDL project. One of the issues that we run into is determining similarity and trying to predict whether or not certain results will actually be similar to what is being searched for. \\n\\n At issue is the balance between the engine interpolating what the searcher wants and, on the other side, making the searcher be as precise as possible with his search terms. On one end is a sample search with one term and a multitude of results (for example, a Google search for the term dog) and on the other end, a search for a long string of text. Most searchers dont want to spend their time either typing in the volumes of text or dont know exactly how to pull out the most pertinent pieces of what they are looking for. \\n\\n Enter Sphere. Sphere looks at the entirety of the content of a page that you are looking at and searches for blog posts which contain similar information. Rather than looking simply at the links within a page, it searches based on the entirety of the comment. This provides enough detail to create more accurate results without forcing the user to enter in excessive (and potentially inaccurate and superfluous) information.\\xa0 Alternatively, the user can enter in the link of the page of interest to the Sphere search engine to get similar results based on the full text of the site.\\xa0 An example search yielded results of similar entries to this page.\\nNow, if only Sphere could find blog pages similar to what Im thinking rather than to what Im reading, Id be happy! \\n\\n', 'excerpt': ' Several of our recent projects have involved different methods of data sorting, manipulation, and visualization. An example of this is now available with the University of Virginia Librarys BlacklightDL project. One of the issues that we run into is determining similarity and trying to predict whether or not certain results will actually be similar to […] \\n', 'post_date': '2007-06-15T00:00:00-0400', 'categories': ['blog', 'Software'], 'id': 'https://opensourceconnections.com/blog/2007/06/15/showing-sphereit/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/06/26/continuous-integration-war-stories-meetup-in-nova/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Continuous Integration War Stories Meetup in NoVA', 'url': 'https://opensourceconnections.com/blog/2007/06/26/continuous-integration-war-stories-meetup-in-nova/', 'author': 'eric-pugh', 'content': ' I wanted to let folks know that Andrew Glover and Paul Duvall are hosting a “Share your Continous Integration War Stories” meetup in Northern Virginia. Andrew and I met at CITCon, and he and Paul have written “The Book” on Continous Integration. Below are the details: \\n\\n \\n   Weâ€™re hosting a â€œShare your Continuous Integration War Storiesâ€� (http://www.stelligent.com/content/view/128/62/) event this Thursday evening at our offices in Reston, VA â€“ it should be a great opportunity to hang out and discuss CI over wine, beer, and other refreshments. In addition, weâ€™ll be raffling off the first signed copy of the CI book Paul authored. \\n \\n\\n \\n   When: Thursday, June 28th from 5:30 PM to 7 P.M\\nWhere: Stelligents headquarters \\n \\n\\n \\n   11495 Commerce Park Drive \\n \\n\\n \\n   Reston, VA 20191\\nWho: Anyone who is using CI or thinking about CI (and loves wine) \\n \\n\\n \\n   If youâ€™re interested, please RSVP (mandy.owens@stelligent.com). Hope to see you on Thursday! \\n \\n\\n Andy writes the very entertaining Disco Blog covering software development and testing practices. \\n', 'excerpt': ' I wanted to let folks know that Andrew Glover and Paul Duvall are hosting a “Share your Continous Integration War Stories” meetup in Northern Virginia. Andrew and I met at CITCon, and he and Paul have written “The Book” on Continous Integration. Below are the details: &gt; Weâ€™re hosting a â€œShare your Continuous Integration War […] \\n', 'post_date': '2007-06-26T00:00:00-0400', 'categories': ['blog', 'Code', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2007/06/26/continuous-integration-war-stories-meetup-in-nova/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/06/26/hi-my-name-is-michael-and-im-a-programmerdesigner/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Hi, My name is Michael and Im a programmer/designer', 'url': 'https://opensourceconnections.com/blog/2007/06/26/hi-my-name-is-michael-and-im-a-programmerdesigner/', 'author': 'scott-stults', 'content': ' Sorry for the AA style header for the introduction blog post. I tend to abuse witty repertoire to set off a style of writing to call my own and yet still find a way to stay informative. My name is Michael, Im a sagittarius, Im originally from an area south of Richmond, and Im what you refer to as the “new guy” at Opensource Connections. I specialize in C# on the .net platform, working both on the web and windows side of things. Im also a communications major with a media specialization, which means my skills range from desktop publishing, to web design, audio/visual media, radio, public relations, and marketing. I know it might seem like a bit of a paradox for someone like me, who develops using Microsoft Technologies, to work for an company that specializes in open source software. \\n\\n However Im a big proponent of open source software and agile style programming, so much so, that Im spending time developing an open source application framework for .Net for my BHAG (big hairy audacious goal(s)) this year. In fact, there is an alpha version of the site and blog for the opensource framework at www.codeaccessory.net, where you can find more information about the BHAG on an ongoing basis as well as code samples. If you have an open sourced project, or even just want a place to write about software, feel free to contact me if youre interested on doing something on the code accessory domain. The framework itself does have a name, but Im waiting for the first alpha version to be released before I reveal the name. \\n\\n In the mean time expect to see postings from me, about semantic xhtml markup, css, c#, javascript, .net, design principles, code patterns, ruby, php, the current state of my BHAG project and all sorts of User Interface goodness. Lets not forget to throw in the sarcasm drenched humor and random comments like “fuzzy pants” (it keeps you reading to see what I type next, doesnt it?). Coming soon: table-less layouts, using code_highligher.js, and ways to free your mind when it comes using CSS to separate presentation from markup/content. \\n\\n', 'excerpt': ' Sorry for the AA style header for the introduction blog post. I tend to abuse witty repertoire to set off a style of writing to call my own and yet still find a way to stay informative. My name is Michael, Im a sagittarius, Im originally from an area south of Richmond, and Im what […] \\n', 'post_date': '2007-06-26T00:00:00-0400', 'categories': ['blog', 'solr'], 'id': 'https://opensourceconnections.com/blog/2007/06/26/hi-my-name-is-michael-and-im-a-programmerdesigner/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/06/29/enhancing-tests-is-the-way-to-join-a-community/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Enhancing Tests is the way to join a community', 'url': 'https://opensourceconnections.com/blog/2007/06/29/enhancing-tests-is-the-way-to-join-a-community/', 'author': 'eric-pugh', 'content': ' Yesterday Yonik committed my first contribution to Solr. It was a simple simplification of the test code infrastruture. Some of the tests depend on Java System properties, however if you are not running the tests from Ant, you dont have them… For example, running them from Eclipse. The advice was to pass them in using -D parameters, but that isnt very user friendly! So I did a tweak that set those System properties in the Java code. I posted the patch to the mailing list, and Yonik committed them as revision 551701 \\n\\n What I realized is that one of the best ways to get to know a new community is to contribute to the test code. As an unknown quantity, suggesting major new features or architecture changes wont go over well, but contributing/fixing/updating tests shows that you are eager to learn how the community works, and not just trying to get your cool new feature added. Writing tests for OSWorkflow and OSUser was how I became a committer over at OpenSymphony, only later did I start writing actual product code. \\n\\n Also, by digging through the unit tests, you really get to learn how the code works, and where the pitfalls are as well! \\n', 'excerpt': ' Yesterday Yonik committed my first contribution to Solr. It was a simple simplification of the test code infrastruture. Some of the tests depend on Java System properties, however if you are not running the tests from Ant, you dont have them… For example, running them from Eclipse. The advice was to pass them in using […] \\n', 'post_date': '2007-06-29T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2007/06/29/enhancing-tests-is-the-way-to-join-a-community/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/03/getting-business-is-not-an-entitlement/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Getting business is not an entitlement', 'url': 'https://opensourceconnections.com/blog/2007/07/03/getting-business-is-not-an-entitlement/', 'author': 'jason-hull', 'content': ' I just came back from the National Veterans Small Business Conference and Expo. I was really impressed at the outreach that prime contractors and government agencies showed. They are making a good faith effort to live up to the 3% service disabled veteran owned small business (SDVOSB) goals set forth in Public Law 106-50 even though historically, they have had trouble meeting those goals. \\n\\n I think that it is laudable that the government wants to give back to the veterans who gave their service to the nation. I applaud and admire the set asides not just for SDVOSBs, but for all disadvantaged groups. However, the government, first and foremost, owes a duty of responsibility to all of those it serves, which includes getting the maximum value for the tax dollars that we all pay to it. By not getting the best value out of money that it spends for the goods and services that it procures, the government is doing everyone a disservice. \\n\\n\\n\\n How does that paragraph not contain a contradiction in terms? It is not when the companies representing disadvantaged groups offer goods and services at a fair value to the government and to the prime contractors who are trying to meet those goals. This does not include exhibiting an entitlement culture, as many of the representatives of small disadvantaged businesses showed during the Veterans Conference. Far too many times, I heard a question along the lines of when was the government going to start holding its people (and, by proxy, its prime contractors) responsible for hitting the goals that were laid out in 106-50. \\n\\n Prime contractors are in business to make money and to provide value, not to pander to special interests. Rather than griping and whining about how the government is not providing enough of what amounts to be handouts, these small businesses should be going out there and demonstrating and providing valuable goods and services. If they provide something that people want to pay money for rather than a corporate shell which is demanding entitlements, then they will find that profits accrue. Prime contractors did not become large businesses through whining and begging. They got there through hard work and through providing value to others. They did it through the basic tenets of business: find a market niche where demand is greater than supply, and provide supply. Its not easier done than said, or else wed all run behemouth businesses, but, at the same time, no business is going to grow through the increased use of whining and begging and complaining to the government that its not giving them enough entitlements. \\n\\n To those who attended the conference and went there to network, find opportunities, and create value, I offer applause and thanks that you represent the best of the veterans who have decided to go into business for themselves. To those who attended the conference to badger, harass, and pester government and prime contractor representatives about when they were going to increase entitlements and not provide taxpayers and shareholders with the best possible value for the money, I shake my head in disappointment. You did not ask your drill sergeants for a break or to not make you pass PT or marksmanship tests. Why are you asking for the free ride now? \\n\\n', 'excerpt': ' I just came back from the National Veterans Small Business Conference and Expo. I was really impressed at the outreach that prime contractors and government agencies showed. They are making a good faith effort to live up to the 3% service disabled veteran owned small business (SDVOSB) goals set forth in Public Law 106-50 even […] \\n', 'post_date': '2007-07-03T00:00:00-0400', 'categories': ['blog', 'Business', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/07/03/getting-business-is-not-an-entitlement/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/05/why-contributing-back-to-the-community-is-important/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Why contributing back to the community is important', 'url': 'https://opensourceconnections.com/blog/2007/07/05/why-contributing-back-to-the-community-is-important/', 'author': 'jason-hull', 'content': ' As a general rule, our company does not design and develop small websites. However, there is one exception. We run the website for the Middlebrook Horse Show, run by the Middlebrook Ruritans. Why do we spend our time on this website? We spend time working on and supporting this website because it is a charitable organization, and we want to give back to the community from which we come. \\n\\n Were it not for the local community, we would not be in the position that we are in. Schools, infrastructure, and friends all come from our surroundings, and we feel obligated to give in some small part back to the community that gave so much to us. \\n\\n While it is a simple site, the Middlebrook Horse Show site also gives us a chance to test out concepts in Ruby, which is always a good thing! \\n\\n Generally, a high end services company does not want to dilute its brand by taking on simpler or cheaper work. Mercedes does not build competitors to the Yugo for a good reason. However, we feel that providing a simple service for a good organization in our community helps us give back and be better community citizens–a concept more important than profit motive. \\n\\n See the site at http://www.middlebrookva.org. \\n\\n', 'excerpt': ' As a general rule, our company does not design and develop small websites. However, there is one exception. We run the website for the Middlebrook Horse Show, run by the Middlebrook Ruritans. Why do we spend our time on this website? We spend time working on and supporting this website because it is a charitable […] \\n', 'post_date': '2007-07-05T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2007/07/05/why-contributing-back-to-the-community-is-important/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/09/eric-pugh-chosen-to-present-at-oreilly-open-source-convention/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric Pugh Chosen To Present at OReilly Open Source Convention', 'url': 'https://opensourceconnections.com/blog/2007/07/09/eric-pugh-chosen-to-present-at-oreilly-open-source-convention/', 'author': 'jason-hull', 'content': ' Eric Pugh has been chosen to present at the 2007 OReilly Open Source Convention on using and writing Rails plugins. \\n\\n OSCON is the worlds largest open source convention, with over 2,500 participants.\\xa0 It will be held July 23-27, 2007. \\n\\n Erics presentation will be held on Thursday, July 26 at 11:35 AM. More information on his presentation can be found on the OReilly page. \\n\\n', 'excerpt': ' Eric Pugh has been chosen to present at the 2007 OReilly Open Source Convention on using and writing Rails plugins. OSCON is the worlds largest open source convention, with over 2,500 participants.\\xa0 It will be held July 23-27, 2007. Erics presentation will be held on Thursday, July 26 at 11:35 AM. More information on his […] \\n', 'post_date': '2007-07-09T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2007/07/09/eric-pugh-chosen-to-present-at-oreilly-open-source-convention/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/20/come-join-us-at-oscon/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Come join us at OSCON', 'url': 'https://opensourceconnections.com/blog/2007/07/20/come-join-us-at-oscon/', 'author': 'jason-hull', 'content': ' Were going to be presenting and exhibiting at the OReilly Open Source Convention in Portland, Oregon next week, July 23-27. \\n\\n Eric will be presenting on using and writing Rails plugins on Thursday, July 26 at 11:35 AM – 12:20 PM in room Portland 255 at the Oregon Convention Center.\\nWe will also be hosting a Birds of a Feather session on Scrum War Stories Wednesday, July 25 at 7:30-8:30 PM in room D136 at the Oregon Convention Center. \\n\\n If youre going to be there, let us know, and well be on the lookout for you! \\n\\n See you in Portland! \\n\\n', 'excerpt': ' Were going to be presenting and exhibiting at the OReilly Open Source Convention in Portland, Oregon next week, July 23-27. Eric will be presenting on using and writing Rails plugins on Thursday, July 26 at 11:35 AM – 12:20 PM in room Portland 255 at the Oregon Convention Center. We will also be hosting a […] \\n', 'post_date': '2007-07-20T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2007/07/20/come-join-us-at-oscon/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/25/subversionits-not-just-for-geeks/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Subversion…it’s not just for geeks', 'url': 'https://opensourceconnections.com/blog/2007/07/25/subversionits-not-just-for-geeks/', 'author': 'jason-hull', 'content': ' We met Joe “Zonker” Brockmeier on the train last night going to Kelt (if youre at OSCON and you like Irish pubs, hop on Max and go to Kelt). He saw our OSCON shirts, which have the moniker Ruby + SVN == Committed on the back and asked if there was a Ruby front-end for Subversion. We replied that there wasnt; it is a geek play on words. He told us that he used Subversion for editing his journalistic writing. “Wow,” I thought, “a non-geek way to use Subversion. Brilliant!” Of course, we followed that up with a visit to the Irish pub and had Guinness-cooked foods. Brilliant! \\n\\n So, what other uses are there for Subversion besides just checking in code? \\n\\n', 'excerpt': ' We met Joe “Zonker” Brockmeier on the train last night going to Kelt (if youre at OSCON and you like Irish pubs, hop on Max and go to Kelt). He saw our OSCON shirts, which have the moniker Ruby + SVN == Committed on the back and asked if there was a Ruby front-end for […] \\n', 'post_date': '2007-07-25T00:00:00-0400', 'categories': ['blog', 'Productivity', 'Software'], 'id': 'https://opensourceconnections.com/blog/2007/07/25/subversionits-not-just-for-geeks/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/26/ruby-on-windows-textmate-clone-and-ides/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Ruby on windows (textmate clone and IDEs)', 'url': 'https://opensourceconnections.com/blog/2007/07/26/ruby-on-windows-textmate-clone-and-ides/', 'author': 'scott-stults', 'content': ' Ive been plowing through a lot of ruby editors for doing rails development on a windows box. I know some would say it is a lost cause. However, I do tend to do a lot of .Net development. Despite the fact i spent like 4 years in a mac lab in college, and you can run things like parallels on a mac, you always run into those extreme cases during development that can cripple your development process and spend hours, or even days to fix the issue. Sometimes you can find that you have a road block that you cant get past due to the operating system and interoperability. So rather than burning hours ( a precious resource ) fixing these special case problems, it would be best to stick with what works for now. \\n\\n Well Ive tried Ruby In Steel, which was not half bad, but it crippled any Intellisense in the .rhtml files and it just seemed to make visual studio somewhat clunky and it didnt provide as much Intellisense as you would expect from visual studio. As far as an IDE goes, Id have to say the Komodo IDE has the edge right now, as it also provides working with the prototype library as well as rails. There is also a Komodo Editor that has less features, but is a free download. \\n\\n However for those people looking for text mate on windows, I ran across the text mate blog that pointed out E-TextEditor. This editor makes use of existing text mates bundles. Now, it would be nice if you could use ctrl+space instead of tab and if the HTML bundle would have better designed snippets. But after some major tweaking of the colors and some of the bundles, its not a bad editor and will probably replace my use of notepad++, which makes use of scintilla. \\n\\n Sooner or later, I should make an attempt to export the color settings for both Komodo and E-TextEditor and post them, since decent color settings for a black background are hard to create. \\n\\n', 'excerpt': ' Ive been plowing through a lot of ruby editors for doing rails development on a windows box. I know some would say it is a lost cause. However, I do tend to do a lot of .Net development. Despite the fact i spent like 4 years in a mac lab in college, and you can […] \\n', 'post_date': '2007-07-26T00:00:00-0400', 'categories': ['blog', 'solr'], 'id': 'https://opensourceconnections.com/blog/2007/07/26/ruby-on-windows-textmate-clone-and-ides/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/28/knowing-when-to-shut-down-a-project/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Knowing when to shut down a project', 'url': 'https://opensourceconnections.com/blog/2007/07/28/knowing-when-to-shut-down-a-project/', 'author': 'jason-hull', 'content': ' Property law (at least, as taught to me by Elizabeth Scott) seeks to have owned property utilized at its highest value use. Thus, according to the basics of property law, raw land has the lowest value, since its the least utilized in comparison to houses, factories, etc. \\n\\n The same can be said for all sorts of things Internet. One example is parked domains. According to Domain Tools, there are 71,083,043 registered domains, but 217,385,494 deleted domains. While there is value in appreciation, particularly of the potentially higher demand sites–the example of sex.com comes to mind–many sites are simply either parked or have become link farms. However, as a property rights advocate, I believe that if someone has paid a fair value for a piece of property, be it land or internet domains, then that person has the right to do with that property what they want. \\n\\n\\n This does not extend to dead projects, though. There are currently 153,954 projects registered on \\n\\n SourceForge, and a long tail truly exists for these. Take the 950th most popular project, the Jedi Code Library. It averages about 100 hits a day. This is for a project that is in the top .5%ile of the existing projects on SourceForge. \\n\\n While a project like Jedi Code Library certainly is still fulfilling a need, there are many, many projects down the charts which are either no longer serving the needs of the users or, more likely, never fulfilled those needs. Keeping them on the SourceForge servers is certainly fine (I do not deign to recommend to the SourceForge team what they should do with their disk space), for projects that have become overcome by events, the owners should consider winding down the project. This will serve two purposes. It allows the better, or more relevant projects, to rise to the top, get more viewership, and, therefore, serve the community better. Secondly, it allows the developers who are on the team still piecing together the code to keep it running long past its expiration date to free up valuable time to work on other, potentially more useful projects. \\n\\n The projects are not property, per se, but the time of the developers is a valuable resource. Tie up projects which have served their useful life and put them in a state where patches will no longer be applied. Refocus developers who are donating their time to projects where the hours can have a great impact. Sometimes houses need to be razed so that newer, more livable houses can be built. The same can be done with projects which have run their useful lives, where the hours spent have passed the point of diminishing returns. \\n\\n', 'excerpt': ' Property law (at least, as taught to me by Elizabeth Scott) seeks to have owned property utilized at its highest value use. Thus, according to the basics of property law, raw land has the lowest value, since its the least utilized in comparison to houses, factories, etc. The same can be said for all sorts […] \\n', 'post_date': '2007-07-28T00:00:00-0400', 'categories': ['blog', 'Productivity', 'Project Management'], 'id': 'https://opensourceconnections.com/blog/2007/07/28/knowing-when-to-shut-down-a-project/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/31/is-poker-the-newest-vc/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Is Poker the Newest Venture Capitalist?', 'url': 'https://opensourceconnections.com/blog/2007/07/31/is-poker-the-newest-vc/', 'author': 'jason-hull', 'content': ' Some deep little part of nearly everyone I know has that inner burning desire to start up their own company. They dont know what they want to do, how theyre going to do it, or even why they want to, but the desire is there. Most of it has to do with the notion of getting out of the day-to-day grind of the 9 6 to 5 11 job, the Dilbert boss, the monkey-like sycophantic coworkers whose seeming purpose in life is to say “yes” to requests as many times as possible during work hours. Theres also the dreams of making it big, getting rich quick, and living the life of luxury. \\n\\n Similar aspirations drove us to start OSC. However, it wasnt a hasty decision, and weve learned some lessons along the way. \\n\\n Have a backup source of income. The guys at ClearContext played poker on the side to pay the bills. Others have spouses who work and can afford to be a single income family. Others rode Enron to the top and got off at the right time. Unless you get some sympathetic angel to fund your income or you have an idea that is an immediate hit and provides revenue right away (which can be done if youve doing the on-the-side work for a while), youre not going to be cashing a paycheck for a while. \\n\\n\\n\\n **Make sure that your partners all trust each other. ** Most startups are a slog. Most dont work. Theres a lot of sacrifice and a lot of risk involved. If youre adding to the risk and the stress by working with people you dont trust and believe in, then youre exponentially increasing the probability that youre going to be one of the majority of failures. \\n\\n **Figure out your make or break timing. ** It can be mentally lucrative to think that prosperity is right around the corner. Dont be the Herbert Hoover of your startup. Its much easier to continue to sink time and money into a failure than it is to admit that it didnt work and its time to move on. Set that break point up front and stick to it. Learn your lessons to apply the next time rather than grind yourself into a bankrupt oblivion. \\n\\n Network like your life depended on it. It does. Figuratively. The life of your company certainly does. Unless you happen to be the one in a million viral idea that catches on with the world, youre going to have to go out and find customers. The only way to do that is to pound pavement. The best idea in the world that sits in your head will always have an audience of one. \\n\\n Yes, I was inspired to write this because theres a successful start-up out there which funded itself out of poker winnings, for which I am endlessly jealous, but it also caused me to think about how we ran for a while. If it werent for the things above, we would have been forced to take rash risks which would have most likely ended up with us being a failure and going back to real jobs. \\n', 'excerpt': ' Some deep little part of nearly everyone I know has that inner burning desire to start up their own company. They dont know what they want to do, how theyre going to do it, or even why they want to, but the desire is there. Most of it has to do with the notion of […] \\n', 'post_date': '2007-07-31T00:00:00-0400', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/07/31/is-poker-the-newest-vc/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/08/09/beware-of-missing-gems-in-rails/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Beware of missing Gems in Rails!', 'url': 'https://opensourceconnections.com/blog/2007/08/09/beware-of-missing-gems-in-rails/', 'author': 'eric-pugh', 'content': ' Ive been getting the incredibly cryptic message undefined method options for []:Array (NoMethodError) from Mongrel on startup when moving from one laptop to another. \\n\\n I googled around, and finally realized that it was due to missing gems. I like to think that this kind of error is just due to Rails immaturity. The Rails community hasnt decided how to manage reusable code. You can either use plugins, gems, or one of the various hybrid tools that make gems into plugins! It does highlight that until we have tools to verify that our dependencies are available, versus blindly throwing a cryptic misleading exception, that the best approach is to “Vender Everything”. \\n\\n Im going to take a stab at putting all our Gems that dont have native code into our /plugins directory, hopefully reducing the amount of hunting around the source to identify what dependencies there are that new folks have to go through. And those that cant go in the /plugins directory I am wrapping in a bit of code to put out a pretty message: \\n\\n \\nbegin\\nrequire `cache\\nrescue RuntimeError\\nraise \"Please install ruby-cache gem\"\\nend\\n \\n\\n Reducing the time it takes for a new developer to get up and running on a project means less frustration, less hand holding, and a better experience for everyone! \\n', 'excerpt': ' Ive been getting the incredibly cryptic message undefined method options for []:Array (NoMethodError) from Mongrel on startup when moving from one laptop to another. I googled around, and finally realized that it was due to missing gems. I like to think that this kind of error is just due to Rails immaturity. The Rails community […] \\n', 'post_date': '2007-08-09T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/08/09/beware-of-missing-gems-in-rails/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/08/16/beware-of-dashes-in-rails-plugin-names/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Beware of – (dashes) in Rails plugin names!', 'url': 'https://opensourceconnections.com/blog/2007/08/16/beware-of-dashes-in-rails-plugin-names/', 'author': 'eric-pugh', 'content': \" Continuing in the vein of my last blog about Beware of Missing Gems in Rails! comes my discovery of – (dashes) being verboten in plugin names. About a month ago I looked at using Selenium On Rails in an app since I liked using it in the first one I worked on. However, I kept getting an error message: \\n\\n The error occurred while evaluating nil.empty? from \\n\\n \\n./script/../config/../vendor/rails/activesupport/lib/active_support/dependencies.rb:202:in 'load_file';\\nfrom ./script/../config/../vendor/rails/activesupport/lib/active_support/dependencies.rb:94:in 'require_or_load';\\n \\n\\n So I gave up, thinking that it was because of some weird interaction with another plugin since I had so many installed for the project. Today I came back to it with a nice simple project, installed things and had the same error! Argh… So I joined the mailing list, looked around and found a post mentioning that in “Edge” Rails, which is now Rails 1.2.3 the name of the plugin needed to be changed from selenium-on-rails to selenium_on_rails! I’;ve looked around at some other plugins and realized that they all use _ characters in the name! transaction_migration, annotate_models etc. \\n\\n Amazing how Rails can make life difficult over the most innocuous things. I am fairly sure this is never an issue in the Java world! Of course, every plugin would be implementing a very complex IDynamicActiveReloadablePlugin interface :) \\n\", 'excerpt': ' Continuing in the vein of my last blog about Beware of Missing Gems in Rails! comes my discovery of – (dashes) being verboten in plugin names. About a month ago I looked at using Selenium On Rails in an app since I liked using it in the first one I worked on. However, I kept […] \\n', 'post_date': '2007-08-16T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/08/16/beware-of-dashes-in-rails-plugin-names/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/08/30/sucking-in-footer-from-remote-sites/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Sucking in the header and footer from a remote site', 'url': 'https://opensourceconnections.com/blog/2007/08/30/sucking-in-footer-from-remote-sites/', 'author': 'eric-pugh', 'content': \" How do you share a common header and footer across multiple apps? For example, you might be prototyping a new app, and want to borrow the main sites header and footer. Obviously you can do crazy stuff like have JavaScript pull something via the client, or maybe have iframes or frames. But what if you have to massage the content as it comes in, maybe only keeping part of it? \\n\\n Well fortunately Ruby on Rails makes that very easy. We simply created a Model object that uses HPricot to pull in remote content and grab the portion we want: \\n\\n ```ruby\\nrequire ‘hpricot&amp;’;\\nrequire ‘open-uri’ \\n\\n class CatalogContent\\ncattr_accessor :remote_url \\n\\n def self.footer\\nurl = remote_url\\nraise “Remote URL was not set” if url.nil? \\n\\n puts “\\\\nPulling remote content footer from #{url}\\\\n” \\n\\n begin\\ndoc = Hpricot(open(url))\\nfooter_content = doc.at(“//div[@id=footer]”)\\nraise “Didn’t find footer content in site #{url}” if footer_content.nil? \\n\\n footer_content \\n\\n rescue Errno::EHOSTUNREACH\\nfooter_content = “Can’t connect to #{url}”\\nrescue Errno::ETIMEDOUT\\nfooter_content = “Can’t connect to #{url}”\\nrescue SocketError\\nfooter_content = “Can’t connect to #{url}”\\nend\\nend\\nend\\n``` \\n\\n In this case we are loading up a website and pulling out the footer section in the HTML. We have the option here while manipulating the HPricot XML DOM to do any other types of changes we want such as: \\n\\n \\n   Remapping URLS \\n   Snipping out bits of content \\n   Changing colors or stylesheet classes \\n   Conditional inclusion of content \\n \\n\\n And then, we have a ApplicationHelper.rb method that creates the model object, populates the remote url and displays it: \\n\\n ruby\\ndef remote_footer\\nCatalogContent.remote_url = AppConfig.catalog_remote_url\\nCatalogContent.footer\\nend\\n \\n\\n Of course, people are going to jump on the fact that this means that every page is making an extra URL call right? Fortunately caching comes to the rescue in our layout: \\n\\n ```ruby \\n \\n  &lt; % cache(:controller=&gt; 'remote_content', :action =&gt; 'remote_footer') do %&gt;  &lt; %= render(:partial=&gt;'/partial/bottom_panel') %&gt;  &lt; % end %&gt;\\n \\n ``` \\n\\n Note, however, we don’t actually have a controller called remote_content with an action called remote_footer, you just have to have those bits so the caching support knows what keys to store the cached content under! Could have been: \\n\\n ruby\\n&lt; % cache(:controller=&gt; 'foo', :action =&gt; 'bar') do %&gt;\\n&lt; %= render(:partial=&gt;'/partial/bottom_panel') %&gt;\\n&lt; % end %&gt;\\n \\n\\n And in our partial we just have: \\n\\n ruby\\n&lt; %= remote_footer %&gt;\\n \\n\\n So, the only downside is that in development we are constantly pulling in the content because the caching is turned off, which slows things down a bit, and that the only way (out of the box) to update the cache is to “sweep” out the contents of the /tmp/cache directory. \\n\\n Also, be aware that if what you are importing has lots of relative paths or references relative JavaScripts and CSS that you are going to have to make those parts work with your app nicely! \\n\", 'excerpt': ' How do you share a common header and footer across multiple apps? For example, you might be prototyping a new app, and want to borrow the main sites header and footer. Obviously you can do crazy stuff like have JavaScript pull something via the client, or maybe have iframes or frames. But what if you […] \\n', 'post_date': '2007-08-30T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/08/30/sucking-in-footer-from-remote-sites/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/08/31/charlottesville-needs-more-nerds-part-deux/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Charlottesville Needs More Nerds, Part Deux', 'url': 'https://opensourceconnections.com/blog/2007/08/31/charlottesville-needs-more-nerds-part-deux/', 'author': 'jason-hull', 'content': ' Eric ran into some fellow Darden grads, Adam Healey and Charles Seilheimer yesterday at a local coffee shop because he was lured into a conversation about Ruby, Twitter, and Web 2.0 goodness. The discussion led me to go check out their blog, and I found an excellent article about the ingredients necessary for creating the right environment to foster startups. \\n\\n We run into the same issue that Adam brings up–there are not enough nerds in this area. While we certainly are comfortable leading in a location independent enterprise (the subject of our talk at OSCON 2006), having most of your people co-located does reduce managerial burden on cat herding. Its not quite as easy to have a look over the shoulder to iron out a gnarly coding problem when your team is spread across three continents as it is when youre sitting next to each other in a bullpen. \\n\\n\\n\\n There are other items coming up on the horizon which further point out the need for more nerds (besides the need to keep Charlottesvilles coffee shop economy booming): \\n\\n\\n\\n –The National Ground Intelligence Center is growing. The Global War On Terror is one that focuses on using technology to interdict the bad guys before they can do harmful things to us. The National Ground Intelligence Center is one of the main nexuses of information collection and analysis. Until we beat the bad guys, the NGIC is going to continue to get business, and it needs nerds to help gather that technology. \\n\\n –The Defense Intelligence Agency is coming to Charlottesville. Theyre bringing about 1,000 jobs to the 29 North corridor, and that doesnt include everything needed to support them (like coffee shops). Just like the National Ground Intelligence Center, the Defense Intelligence Agency relies on nerds to make sense of signal intelligence and human intelligence. There are currently not enough nerds to go around. \\n\\n –The surplus of nerds from the Value America days has worked itself through the system. Right after Value America closed shop, the programmers from the company had time on their hands. Many of them started up ventures. However, venture capital money dried up, and they were forced to, for the most part, find “real” jobs. The days when labor was plentiful are no longer in the Charlottesville region because the Value America refugees have become absorbed by the greater economy. \\n\\n –Venture capital deals are on the rise. The number of deals is up, but the average per deal is down. This means that startups have to focus more on delivering the goods and less on the posh offices. In order to make this happen, startups will need good, solid nerds to get to market faster and bring in revenues more quickly. Nice chairs do not bring in revenue. The Virginia Piedmont Technology Council – Charlottesville Venture Group is working with the City of Charlottesville to determine a strategy to bring technology-based businesses into the central Virginia region. Technology companies are not going to want to come to a place where there are not enough workers to fulfill their needs. As it is, existing technology employers who are looking to grow are having significant trouble growing organically with hometown growth. The growth of the contractor community around the National Ground Intelligence Center is being pumped by imported talent with people moving in from the D.C. area rather than with people in Charlottesville. When the Defense Intelligence Agency comes down, it will be the same story. \\n\\n So, how to get more nerds to Charlottesville? Adam touched on one step in his blog article, which was focusing on improving the quality of the engineering school at the University of Virginia. He makes a fine suggestion about making a game-changing move and shelling out millions to bring in the rock star professors to draw more students and improve the quality of output at UVa. While this will work in the long run, it will take time for the trickle down effects to happen. What else can we do? \\n\\n –Give the incubators some teeth. While Charlottesville has incubators such as the Batten Institute and Spinner Technologies, they really dont provide enough of a runway for entrepreneurs to solidify and implement their ideas. Trying to live on a $1,000 a month stipend while slaving away on your laptop for 25 hours a day simply will not cut it in Charlottesville. The cost of living is too high. Not every great nerd has a burning desire to live on ramen and rice cakes for two years while trying to make his great idea a reality. The reality is that great nerds can get jobs which pay them well, and most of those jobs are not in Charlottesville, Virginia. So, in order to draw in the great nerds to the small businesses and the entrepreneurial ventures which will lead to the next big employment opportunities, the incubators have to put significant investment into the worthy incubator seatholders. This is not so that we can pay nerds tidy sums to do nothing. It is so that we can draw in the motivated great nerds who could otherwise go work for Google. Yes, the incubators will have to blur the line between incubator funding, angel funding, and venture capital funding, but otherwise, the good nerds will go elsewhere, and so will the businesses which employ them and many of their friends. \\n\\n –Get the local governments in on the action. Universities and foundations shouldnt be the only ones that are in on the incubator game. The city of Charlottesville, Albemarle county, and the surrounding counties have a vested interest in bringing in more nerds. It seems that most people who are interested in the question would rather have Charlottesville turn into Austin than Aspen, and the governments have to take part in solving that equation. Rather than spending money on Art In Place or on a bus station that takes you nowhere, spend it on things which will breed more employment. If I had $11 million to invest in budding entrepreneurial technology-based companies in Charlottesville, I am willing to bet my mortgage that I could grow jobs in the Charlottesville area and grow the citys base of tax revenue. The local governments in the area need to partner together, because this isnt a matter of divvying the pie; its a matter of growing the pie. A growing company based in Charlottesville will have residents who live in Albemarle, Green, Augusta, and other counties, who will use goods and services in those areas as well.–Look for public-private partnerships. What major corporation wouldnt want to have its name attached to the partnership which spat out the next Google? Furthermore, it would get the benefits of the goodwill associated with bringing in new jobs and philanthropy to the region. Everybody wins. The corporation gets to hand-pick the best nerds for its own ventures and gets the positive press that goes along with a public project. The local community gets more money to fund more ventures which bring in more jobs. \\n\\n –Recruit nerds who live elsewhere. Washington, D.C. is a two hour drive from Charlottesville when the traffic is not abysmally jammed. Naturally, traffic is abysmally jammed all of the time. Nerds (and everyone else) hate traffic jams. Charlottesville does not have them. So, go up to D.C. and talk to the nerds there about the joys and low-stress living that Charlottesville offers. Heres one group and another if you need a start. Were talking to their groups, but we are a drop in the ocean. The incubators and local governments need to wade into the waters. By the way, these nerds who you import can also act as great mentors for the young batch of nerds that we should be growing in the University who came in because of the rock star professors we brought in with the $150 million in allocated funds. \\n\\n –Tax breaks? How about tax credits? The City of Charlottesville is going in the right direction with a 50% tax break for technology-based companies, but its not enough. Offer tax credits instead. Dont worry about losing out on tax revenues, because youll make it up in spades from the knock-on effects of having larger employers in your region because of the incentives you offered for them to take up shop and hire employees here. Its accelerated supply-side economics working for you. If you need more help understanding this, offer to take Dr. Alan Beckenstein out to lunch. Youll get an amazing return on investment for the $10 that you spend feeding him while he enlightens you. \\n\\n –Prime the pump with the Piedmont Virginia Community College. For every great nerd we bring in, we need a couple of worker nerds to implement the supernerds great strategy. Grow those worker nerds in our own back yard as well. These people can continue in their day jobs while they become worker nerds at night. PVCC has repeatedly stated its willingness to increase the number of technology-based classes it offers, so take them up on the offer. PVCC is a great resource for helping get more nerds here, but its an underutilized resource. \\n\\n Growing a nerd population is not going to happen overnight. However, there is still time to start growing that population before the demand spikes, potential employers become frustrated at the lack of supply, and pick up and move elsewhere, leading Charlottesville to become Aspen without the great skiing. Austin did it through both importing the employers and growing them organically, and it had a great educational system at its back pumping out nerds by the bucketload. It offered incentives for companies to take root, and it offered the people to help the companies execute their missions. By combining programs to bring in and grow the nerd population of Charlottesville as well as generating the employment to keep them here instead of watching a mass nerd exodus every May at graduation time, we can build a vibrant technology community. Otherwise, we are always going to be a second-tier player posing as a first-tier location. The saying in Texas is “all hat, no cattle.” Nerds are the cattle that will drive Charlottesvilles 21st century economy and keep it from becoming an exclusive enclave where few can afford to live and jobs are scarce. \\n', 'excerpt': ' Eric ran into some fellow Darden grads, Adam Healey and Charles Seilheimer yesterday at a local coffee shop because he was lured into a conversation about Ruby, Twitter, and Web 2.0 goodness. The discussion led me to go check out their blog, and I found an excellent article about the ingredients necessary for creating the […] \\n', 'post_date': '2007-08-31T00:00:00-0400', 'categories': ['blog', 'Business', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/08/31/charlottesville-needs-more-nerds-part-deux/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/01/javascript-intellisense-documentation-visual-studio-2008-orcas/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Javascript Intellisense, Documentation, &#038; Visual Studio 2008 (Orcas)', 'url': 'https://opensourceconnections.com/blog/2007/09/01/javascript-intellisense-documentation-visual-studio-2008-orcas/', 'author': 'scott-stults', 'content': ' I’ve been working inside the quasi evil yet intriguing world of javascript for the last several weeks due to current projects and the web side of my BHAG project (Amplify.Net framework).  I’ve been rethinking a lot things, including spinning the Javascript into its own opensource project that works with the framework and without the framework.  I’ve also had to ask myself, how do I make this easy for developers to leverage/use? And how do go about streamlining  the documentation process for javascript code. \\n\\n In building this library, since I’m building most of my own controls in order to keep things simple and be able to wire them up to .NET server controls, I’m leveraging the Prototype Library so far, because its not bulky (yet), compared to the Asp.Net Ajax Library.  Also css selectors are not yet available in the Asp.Net Ajax library, but they are planned for a future release. \\n\\n I’ve also have been testing the new Javascript features of Visual Studio 2008 (Orcas). Don’t get me wrong, when I’m working in ruby, I’ve been digging the e-texteditor, which even has some features the mac version does not, like close all tabs and you can shift + tab code instead of shift + [.  However, intellisense is a compelling feature when it comes to speeding up development, also having inline documentation bundled with intellisense is a win/win for developers. \\n\\n\\n\\n Granted, Visual Studio 2008 Beta 2 (Orcas) has improved javascript intellisense, but there are still too many gotchas… \\n\\n Intellisense Gotchas \\n\\n Gotcha 1.) Visual Studio loses intellisense for all scripts if it is unable to parse one.  If you load a script like prototype.js, that doesn’t follow the rules Visual Studio can handle, it kills the intellisense for all other scripts that in the format Visual Studio can handle. ; \\n\\n html\\n&lt;script type=\"text/javascript\" src=\"../javascripts/prototype.js\"&gt;&lt;/script&gt;\\n&lt;script type=\"text/javascript\" src=\"../javascripts/amplify.js\"&gt;&lt;/script&gt;\\n \\n\\n or \\n\\n js\\n/// &lt;reference path=\"prototype.js /&gt;\\n/// &lt;reference path=\"amplify.js /&gt;\\n \\n\\n This is what happens when its working.  \\n\\n This is what happens when you add a good library that Visual Studio can’t figure out.  \\n\\n Gotcha 2.) Visual Studio crashes when you use dojo functions.  If you have a complex library like dojo and you attempt to do something “dojo.style”, this crashes visual studio, possibly due to the fact that the dojo style function does both get and set? or its just too much script in the global namespace for visual studio to handle. \\n\\n Gotcha 3.) Visual Studio is not able to do complex chaining of functions.  I love the inheritance model of Prototype 1.6.0 RC.  When you create a class using prototype, you do some thing like what is shown in the code sample below. Visual Studio doesn’t know what to make of the object “Amplify.MockWidget” and ends up killing any intellisense in the script and in any place you reference the script file would have the following code. You can even add xml comments and put in the type and visual studio isn’t currently smart enough to make light of that. \\n\\n ```js\\n// visual studio can’t make out the object type..\\nvar Amplify.MockWidget = Class.create(Amplify.UI.Control, {\\n  load: function() {\\n    this.element = $(this.element);\\n    this.element.observe(\\n      “click”,\\n      this.onClick.bind(this)\\n    );\\n  }, \\n\\n onClick: function() {\\n    $log(“hello world”);\\n  }\\n}); // should be of type Function, but visual studio does not see that.\\n``` \\n\\n So what you end up having to do is creating classes using the Asp.Net Ajax style of coding, which tends be more verbose (and doesn’t seem as elegant to me). \\n\\n Gotcha 4.) JSON style object declaration breaks intellisense.  Visual Studio Intellisense, won’t allow you to access other properties/methods using the “this” keyword. So if you do the following, Visual Studio will not have the object’s functions/properties listed in the drop-down. So in the Define method below, you will not be able to see _specs when you type this. \\n\\n js\\nvar Specification = function(name, description, functionality) {\\n  this.name = name;\\n  this.description = description;\\n  this.functionality = functionality;\\n}\\nvar Spec = {\\n  _specs: [],\\n  Define: function(specification) {\\n  ///&lt;summary&gt; Defines a new part of the specification &lt;/summary&gt;\\n  ///&lt;param name=\"specification\" type=\"Specification\"&gt; a defined piece of the total spec. &lt;/param&gt;\\n    this._specs.push(specification);\\n  }\\n}\\n \\n\\n Gotcha 5.) Visual Studio Intellisense relies on the Asp.Net Ajax framework concepts for determining object types. So if you want a class to show up as a class, you need to add __class: true or ObjectName.__class = true; or something to that effect for visual studio to recognize the object as a class. So rather than putting that overhead in the scripts, I’m making a second script that has all this type of meta data for intellisense purposes.. \\n\\n Gotcha 6.) Visual Studio finds errors with javascript.  However, because you can’t currently reference a complex javascript file like prototype.js, since it removes all the enhancement of intellisense, Visual Studio finds methods that are not defined that you may use from a library and puts up an error in error panel. It would be nice if Visual Studio would provide a pragma for javascript similar to C#’s pragmas that would allow you to ignore these type of errors. \\n\\n Documentation Gotchas \\n\\n Since the great NDoc is no more due to the evils of developer expectations of the Microsoft world when it comes to open source .net projects, you’re pretty left with SandCastle if you go the route of xml comments. Now if you plan to leverage the intellisense of visual studio, you’re pretty much stuck with xml comments. The only other way around this is use something like Aptana which uses JsDoc style of comments. (the YUI library also uses this format.) However, I find JsDoc style of documents ugly and I want to minimize the burden of tweaking the styled pages not to mention I don’t feel like installing and running active pearl and creating yet another ugly dependency on a project. \\n\\n Gotcha 1.) Parsing XML Comments In Javascript. SandCastle only parses xml documents, it does not go through code and pull out the xml format from the code files such as .js, .cs, .vb files. When you build your dll or exe, thats when visual studio pulls out those xml comments and puts them into one xml file. Right now SandCastle, nor Visual Studio handles parsing xml comments from javascript files. \\n\\n Enter Bertand Le Roy’s Ajax Doc which parses out the xml comments in javascript files and puts them into one xml document. However… this brings up more gotchas. \\n\\n Gotcha 2.) Ajax Doc requires extra dependencies. Ajax Doc uses the Asp.Net Ajax Library, which is an extra dependency on the project, however this Ajax Doc is totally written in Javascript, but requires Internet Explorer, probably for writing the xml file or something to that effect. \\n\\n Gotcha 3.) Ajax Doc relies on Asp.Net Ajax Object Types.  Ajax Doc only documents comments based upon the Asp.Net Ajax Object model. Which means functions who have declared class types of class, interface, enum, etc, are the only ones that get documented. So your classes must have those __class = true;  or __enum = true; defined in your objects otherwise the Ajax Doc will skip your objects. \\n\\n Gotcha 4.) Ajax Doc relies on the inheritance model of the Asp.Net Ajax library. This means that if you are using libraries like the new Prototype 1.6.0 RC, which has inheritance, Ajax Doc is not smart enough to be able to parse that inheritance model out to put into the xml comments file. \\n\\n Gotcha 5.) Ajax Doc has limited tag parsing.  Tags like &lt;remarks&gt; are not included, in fact the only thing it really handles at this point is on Bertand’s posting on Javascript xml comments. \\n\\n In closing, I’m still digging the fact that the visual studio team is putting in better intellisense for javascript, however, I’m hoping one of them reads this in order to provide better support for javascript overall, since the style of javascript is so diverse. Even if you have rely on documenting your scripts to allow for this, I think this would push well documented libraries to evolve, rather than obscure scripts that are impossible to read. \\n\\n track17 Naruto Bad Situation \\n\\n', 'excerpt': ' I’ve been working inside the quasi evil yet intriguing world of javascript for the last several weeks due to current projects and the web side of my BHAG project (Amplify.Net framework).  I’ve been rethinking a lot things, including spinning the Javascript into its own open source project that works with the framework and without the framework.  […] \\n', 'post_date': '2007-09-01T00:00:00-0400', 'categories': ['blog', 'solr'], 'id': 'https://opensourceconnections.com/blog/2007/09/01/javascript-intellisense-documentation-visual-studio-2008-orcas/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/07/eric-pugh-will-be-presenting-at-cvreg-sept-11th/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric Pugh will be presenting at CVREG Sept 11th', 'url': 'https://opensourceconnections.com/blog/2007/09/07/eric-pugh-will-be-presenting-at-cvreg-sept-11th/', 'author': 'eric-pugh', 'content': ' Ill be at the CVREG next week talking about Lego Mindstorms and Ruby. Ill be demoing the acts-as-nxt plugin providing an interface between a Ruby on Rails app and a Lego robot!. As Mel Riffe puts it “ROBOTS!” \\n\\n We are participating in this weekends Rails Rumble contest, so Ill be giving a recap of that! \\n\\n More details are on Upcoming. \\n', 'excerpt': ' Ill be at the CVREG next week talking about Lego Mindstorms and Ruby. Ill be demoing the acts-as-nxt plugin providing an interface between a Ruby on Rails app and a Lego robot!. As Mel Riffe puts it “ROBOTS!” We are participating in this weekends Rails Rumble contest, so Ill be giving a recap of that! […] \\n', 'post_date': '2007-09-07T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2007/09/07/eric-pugh-will-be-presenting-at-cvreg-sept-11th/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/09/lets-get-ready-to-rumble/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Let’s Get Ready to Rumble!!!!', 'url': 'https://opensourceconnections.com/blog/2007/09/09/lets-get-ready-to-rumble/', 'author': 'jason-hull', 'content': ' Three of our team members, Eric Pugh, Michael Herndon, and Jim Nist, along with Ashish Tonse from Booz Allen Hamilton, are currently in the midst of throwing together last-minute fixes and tweaks for our entry in the Rails Rumble 2007 contest. \\n\\n On Wednesday Thursday, voting will begin, and at that time, well unveil our ultra-cool application. For now, sign up to be a judge for the Rumble so that you can let the world know what you think about our application when we make the unveiling. \\n\\n Cant wait? Come to the Neon Guild meeting Monday, September 10, 2007 at 6:00 in the Inova building and get a sneak peek. \\n\\n  \\n\\n', 'excerpt': ' Three of our team members, Eric Pugh, Michael Herndon, and Jim Nist, along with Ashish Tonse from Booz Allen Hamilton, are currently in the midst of throwing together last-minute fixes and tweaks for our entry in the Rails Rumble 2007 contest. On Wednesday Thursday, voting will begin, and at that time, well unveil our ultra-cool […] \\n', 'post_date': '2007-09-09T00:00:00-0400', 'categories': ['blog', 'Code', 'Ruby'], 'id': 'https://opensourceconnections.com/blog/2007/09/09/lets-get-ready-to-rumble/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/12/agile-open-california-oct-23-24/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Agile Open California Oct 23-24', 'url': 'https://opensourceconnections.com/blog/2007/09/12/agile-open-california-oct-23-24/', 'author': 'eric-pugh', 'content': ' Looking for a great Open Spaces format conference? Agile Open California in San Francisco may be right up your alley! I first heard about this conference from Vandana Shah of Agitar during CITCon this past year. Vendana is leader in implementing better software development practices, and is one of the hosts for Agile Open California. People like her are sure to attract really interesting participants, and make this an exceptional conference. The conference should stay small and intimate since the size is capped at 100 people. I would be there except for the impending arrival of my son on October 23rd! \\n\\n The website is at http://www.agileopencalifornia.com/ and there is some signup information at Upcoming.org. \\n\\n Oh, and if the content isnt enough to make you go, it is taking place at Ft Mason in the Golden Gate National Park! \\n\\n', 'excerpt': ' Looking for a great Open Spaces format conference? Agile Open California in San Francisco may be right up your alley! I first heard about this conference from Vandana Shah of Agitar during CITCon this past year. Vendana is leader in implementing better software development practices, and is one of the hosts for Agile Open California. […] \\n', 'post_date': '2007-09-12T00:00:00-0400', 'categories': ['blog', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2007/09/12/agile-open-california-oct-23-24/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/14/fish4brains/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Fish4Brains', 'url': 'https://opensourceconnections.com/blog/2007/09/14/fish4brains/', 'author': 'jason-hull', 'content': ' We demonstrated Fish4Brains at the Neon Guild meeting on Monday. The voting on the Rails Rumble website is now live. For those of you who were not at the Neon Guild meeting, the Rails Rumble was a contest where 150 teams of 1-4 developers had 48 hours to create a Ruby on Rails application. 48 hours and 238,053 lines of code later, Fish4Brains was born. \\n\\n Wed appreciate it if you could go to our website at http://www.fish4brains.com and take a look at our fish and vote on it. Also, if you want to provide feedback on what youd like to see in the updated version, you can send a note to fish@opensourceconnections.com. \\n\\n Thanks, and have fun fishing! \\n', 'excerpt': ' We demonstrated Fish4Brains at the Neon Guild meeting on Monday. The voting on the Rails Rumble website is now live. For those of you who were not at the Neon Guild meeting, the Rails Rumble was a contest where 150 teams of 1-4 developers had 48 hours to create a Ruby on Rails application. 48 […] \\n', 'post_date': '2007-09-14T00:00:00-0400', 'categories': ['blog', 'Code', 'Ruby'], 'id': 'https://opensourceconnections.com/blog/2007/09/14/fish4brains/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/21/saic-and-the-armys-pathfinder-intelligence-application/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'SAIC and the Armys Pathfinder Intelligence Application', 'url': 'https://opensourceconnections.com/blog/2007/09/21/saic-and-the-armys-pathfinder-intelligence-application/', 'author': 'scott-stults', 'content': ' \\n  SAIC has been a leading developer of intelligence analysis software for decades. In fact, their Pathfinder application has seen continual usage at a variety of agencies since the early 90s. It has been periodically updated with newer and better technologies as they emerged, and OpenSource Connections was an integral part of one of these latest efforts. Over the course of fourteen months, across two project teams, we helped update both the front and back ends of the application.\\n \\n\\n \\n  The front-end team improved the search functionality by developing a .Net / Service Oriented Architecture-based user interface. To ease the transition to the new interface, old views were ported, and new views were built to maximize the new capabilities, including toolbars, applets, plug-ins etc. The updated interface decreased the technical-know-how required of the analysts performing the queries, thereby allowing them to focus on the information related to the search rather than on the technical parameters required to perform the search.\\n \\n\\n \\n  For full-text searching, the open source Lucene project has singled itself out as an invaluable tool. Its speed and accuracy are second to none. It is also documented to work well with a variety of programming languages, which grants it greater future flexibility. SAIC had previously integrated it into Pathfinder by enhancing its query language and plugging it into their data feeds, but the new implementation needed to be tied directly to the central Oracle database.\\n \\n\\n \\n  To accomplish this, the back-end team indexed the text with Lucene, but only stored the record identity in the index. Searching would take place completely within Lucene, but whenever the actual text was called for it would be retrieved from Oracle. Since the database was already integrated into a great number of data feeds, this instantly added them to Pathfinder and allowed it to leverage the data access security protocols already in place.  This solution not only saves the client money in its lack of licensing fees but offers better forward compatibility.\\n \\n\\n \\n  Finally, we deployed Xen virtualization software for use by both teams as a development and testing platform. This saved additional dollars by effectively turning two servers into twenty and allowed the teams to quickly create whatever server environment their task called for.\\n \\n', 'excerpt': ' SAIC has been a leading developer of intelligence analysis software for decades. In fact, their Pathfinder application has seen continual usage at a variety of agencies since the early 90s. It has been periodically updated with newer and better technologies as they emerged, and OpenSource Connections was an integral part of one of these latest […] \\n', 'post_date': '2007-09-21T00:00:00-0400', 'categories': ['blog', 'Case Study'], 'id': 'https://opensourceconnections.com/blog/2007/09/21/saic-and-the-armys-pathfinder-intelligence-application/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/10/02/mitre-healthstoriesorg/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'MITRE&#8211;Healthstories.org', 'url': 'https://opensourceconnections.com/blog/2007/10/02/mitre-healthstoriesorg/', 'author': 'riley-wolfe', 'content': ' To address the growing attention on healthcare, the MITRE FFRDC in Bedford, Massachusetts engaged OpenSource Connections to build a website that would facilitate the exchange of patient health care experiences.  Healthstories.org was born. The website also allows medical professionals to share their experiences.  The ultimate goal of the site is to help identify challenges in the current health system. \\n  \\n', 'excerpt': ' To address the growing attention on healthcare, the MITRE FFRDC in Bedford, Massachusetts engaged OpenSource Connections to build a website that would facilitate the exchange of patient health care experiences. Healthstories.org was born. The website also allows medical professionals to share their experiences. The ultimate goal of the site is to help identify challenges in […] \\n', 'post_date': '2007-10-02T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2007/10/02/mitre-healthstoriesorg/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/10/03/eric-pugh-presents-to-rubyjam/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric Pugh presents to RubyJam', 'url': 'https://opensourceconnections.com/blog/2007/10/03/eric-pugh-presents-to-rubyjam/', 'author': 'eric-pugh', 'content': ' October 10th at 6 PM Eric Pugh will be presenting to the RubyCodeJam group some cool hackery with of Ruby and Lego Mindstorms, as well as share some lessons in using BackgroundRB with Rails. \\n\\n', 'excerpt': ' October 10th at 6 PM Eric Pugh will be presenting to the RubyCodeJam group some cool hackery with of Ruby and Lego Mindstorms, as well as share some lessons in using BackgroundRB with Rails. \\n', 'post_date': '2007-10-03T00:00:00-0400', 'categories': ['blog', 'News', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2007/10/03/eric-pugh-presents-to-rubyjam/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/10/04/is-cmmi-overrated/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Is CMMI Overrated?', 'url': 'https://opensourceconnections.com/blog/2007/10/04/is-cmmi-overrated/', 'author': 'jason-hull', 'content': ' We are not a CMMI rated company. As a small business, we think it is more important to focus on delivering excellence for our customers and growing top and bottom line numbers than being able to check certain boxes about whether or not we have a laundry list of processes documented and implemented. The causation seems to be backwards. We do things which please our customers. Our customers are pleased; therefore, we seem to be doing the right thing, QED. Having a CMMI certification does not guarantee anyone that we will perform in a manner which will satisfy our customers, only that we will perform in a manner which will ensure we can check boxes. \\n\\n What is CMMI, you ask? According to the Carnegie Mellon Software Engineering Institute CMMI page: \\n\\n “Capability Maturity Model® Integration (CMMI) is a process improvement approach that provides organizations with the essential elements of effective processes. It can be used to guide process improvement across a project, a division, or an entire organization. CMMI helps integrate traditionally separate organizational functions, set process improvement goals and priorities, provide guidance for quality processes, and provide a point of reference for appraising current processes.” \\n\\n A sample of the 23 different areas that CMMI measures includes (quoted from the CMMI v 1.2 manual): \\n\\n \\n  \\n\\n  · Causal Analysis and Resolution (CAR)\\n \\n\\n \\n  \\n\\n  · Configuration Management (CM)\\n \\n\\n \\n  \\n\\n  · Decision Analysis and Resolution (DAR)\\n \\n\\n \\n  \\n\\n  · Integrated Project Management +IPPD (IPM+IPPD)\\n\\n  \\n\\n  [1]\\n \\n\\n \\n  \\n\\n  · Measurement and Analysis (MA)\\n \\n\\n \\n  \\n\\n  · Organizational Innovation and Deployment (OID)\\n \\n\\n \\n  \\n\\n  · Organizational Process Definition +IPPD (OPD+IPPD)\\n \\n\\n \\n  \\n\\n  · Organizational Process Focus (OPF)\\n \\n\\n \\n  \\n\\n  · Organizational Process Performance (OPP)\\n \\n\\n \\n  \\n\\n  · Organizational Training (OT)\\n \\n\\n   For an organization which is not delivering the intended results to its customers, revising and revamping the processes is a good thing. I by no means wish to say that I do not believe in process. Process, within reasonable limits, is good. We are proponents of Agile Development processes. With a complete lack of process, a project will end up with variable timelines, bugs, few (if any) test, and, most likely, a product that suits the developers needs rather than the customers needs. \\n\\n To me, the question is how many companies who are CMMI-X level certified companies actually implement the CMMI processes fully rather than just showing the process in a project in order to get the certification? As Dr. Rick Hefner states (p.7), “A CMMI appraisal indicates the organization€™s capacity to perform the next project, but cannot guarantee that each new project will perform in that way.” \\n\\n According to this Washington Technology article, the trend in government contracting is to mandate CMMI maturity levels. So, government contractors who wish to do more business with the government look to get CMMI certified so that they can win more contracts. The government thinks that enforcing certain process standards will yield more predictability in results. \\n\\n Yet, this does not always happen. Government contracting officers and IT managers with whom I have spoken complain that CMMI level 4 and 5 companies are consistently delivering poor code bases, usually over budget (and/or late), and often full of critical bugs that are introduced into live environments. \\n\\n Where is the disconnect, then? It happens from both sides. \\n\\n Providers: \\n\\n \\n   Focus on the customer: The prettiest code or the coolest algorithm is worthless if it does not deliver what the customer wants. The scrum master and the development team should be in harmony with the product owner and business customer (if they are not the same person) in terms of vision and outcomes. \\n   Test, test, test: Code should not be released into a live environment unless it is unit tested, string tested, integration tested, and user tested. Fixing the nth incremental bug at a negative marginal utility cost is not the goal. Catching the critical bugs early is the goal. If the team focuses on test-driven development, then they will eliminate much of the overhead necessary to deliver working products at the end of the project. \\n   Prototype early: By developing form and function prototypes, the development team can give the customer an idea of what is going to be delivered, and the customer can provide intervening feedback to keep the development team pointed in the right direction. Prototyping reduces the amount of intent interpretation necessary, as the customer gets to see what the results will look like rather than hoping that the development team can divine intent. \\n   Dont drown in unnecessary documentation: Each report that the team has to deliver reduces the amount of time that the team can spend coding. Stick to burndown charts and product backlogs as much as possible. Scrum masters should push back where possible on excess reporting. Providing periodic performance updates is appropriate; crafting 800 page requirements documents is rarely so. Dont shirk from documenting code, though. Someone has to figure out what the team did long after the team is gone. \\n \\n\\n Customers: \\n\\n \\n   CMMI certification is not a magic bullet: Dont expect that just because a company has a CMMI certification, theyre going to magically deliver under budget, early, and with more scope than you thought. Expect the appropriate amount of coding rigor to deliver on what you need. Ask where the code tests are. Demand prototypes. Own the product backlog. \\n   Keep a gentle, guiding hand on the team, not an oppressing fist: Just as not enough oversight ruins the outcome, so does micromanagement. Expecting TPS reports every week means that youre going to have a team focused on filling out satisfactory paperwork rather than delivering outstanding code. Give guidance, vision, and direction; expect rigor, and get out of the way. \\n   Provide performance-based incentives: Periodic payments should keep the lights on with your provider. All of the profit should come at the end when the product delivers what it is supposed to, on time, and meeting the customers intent. Hourly fees are an invitation to print money. Even if the long-term total cost is unknown, set up per sprint requirements and hourly estimates and then hold the provider to those. For example, for a 3 year project, set up monthly (or whatever appropriate interval) sprints and get agreement on sprint deliveries and cost for each sprint, while holding out a percentage of the overall compensation to the end of the project contingent upon mutually agreed upon final deliverables. If those need to change, then negotiate the deliverables through the course of the project. \\n   Look at other customers besides those provided by the contractor in the proposal: Requests for proposal are inherently subject to selection bias. As a contractor and proposal provider, we are going to pick our 3 happiest customers and provide them to the requestor. Look deeper into the picture and see if all of the stories are the same. Request a dissatisfied customer in the proposal and dig into why the customer was dissatisfied. Nobody (not even us) has no unhappy customers. Everyone makes mistakes. Find out if the mistakes are systemic or have been corrected before jumping into the long-term relationship. \\n   Try before you buy: Do small contracts at first. Build the relationship and the rapport with the potential provider. See if the product is as good as the promise that came in the proposal. \\n   Dont be afraid to switch providers: Go with your hunches. If things seem to be going off course, then they probably are. Look at what youve spent as a sunk cost and move on and find the right solution. Staying in a bad marriage is not the answer in life, and its not the answer in business. \\n \\n\\n In Malcom Gladwells book Blink, he relates the story of a Pentagon exercise conducted in 2002 called Millenium Challenge. The Blue team, the Allies, were to go against the Red team, a Middle Eastern dictatorship. The Blue team, with its superior information, and its abundance of processes, was supposed to destroy the Red team. What they failed to account for is how their processes got in the way of actually doing anything, and while they were busy writing reports and doing prediction scenarios, LTG Paul van Ripers Red team was actually doing things. They were agile. The Blue team was process-obsessed and process-drowned, and they lost. Streamlined processes work. Process for the sake of process makes a team focus only on the process and not on the outcome. \\n\\n So, having a CMMI certification may be good, but only if done in synch with an organizational focus on serving the customer in the most efficient manner possible. Having a CMMI certification only to check a box or to make sure that boxes are being checked during a project so that the project lead can cover his or her tracks is not. Id rather focus on the customer and getting things right and delivering a solid product. If it means that somewhere along the way, we find that we could be CMMI certified because of the way we do business, then so be it. After all, as Jim Nist pointed out to me, software development is hard. \\n', 'excerpt': ' We are not a CMMI rated company. As a small business, we think it is more important to focus on delivering excellence for our customers and growing top and bottom line numbers than being able to check certain boxes about whether or not we have a laundry list of processes documented and implemented. The causation […] \\n', 'post_date': '2007-10-04T00:00:00-0400', 'categories': ['blog', 'Opinion', 'Productivity', 'Project Management', 'scrum'], 'id': 'https://opensourceconnections.com/blog/2007/10/04/is-cmmi-overrated/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/10/06/installing-rmagick-on-windows-using-ruby-186/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Installing Rmagick on Windows Using Ruby 1.8.6', 'url': 'https://opensourceconnections.com/blog/2007/10/06/installing-rmagick-on-windows-using-ruby-186/', 'author': 'scott-stults', 'content': ' Rmagick tends to be tricky to install, but on windows its relatively simple, except for the fact that if you freshly installed ruby 1.8.6, ruby gems needs to be updated. If you install ruby 1.8.6 and then go to ruby.forge and download rmagick for windows. Extract the zip folder, run the .exe, then open a command line, cd (change directory) to the install folder and do â€œgem install rmagick â€”localâ€�. The first time you do this, you might run into the â€œError installing gem RMagick (version) .gem[.gem]: buffer errorâ€�. To fix that run â€œgem update â€”systemâ€� with double hyphens and then run â€œgem install rmagick â€”localâ€� and everything should now install fine. \\n\\n \\n  currently listening to.. Chevelle Vena Sera Brainiac \\n \\n\\n \\n  Tags: ruby, ruby+1.8.6, windows, rmagick, gems\\n \\n\\n', 'excerpt': ' Rmagick tends to be tricky to install, but on windows its relatively simple, except for the fact that if you freshly installed ruby 1.8.6, ruby gems needs to be updated. If you install ruby 1.8.6 and then go to ruby.forge and download rmagick for windows. Extract the zip folder, run the .exe, then open a […] \\n', 'post_date': '2007-10-06T00:00:00-0400', 'categories': ['blog', 'solr'], 'id': 'https://opensourceconnections.com/blog/2007/10/06/installing-rmagick-on-windows-using-ruby-186/'}}}])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBulkIndexError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3576895fc619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mltr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrebuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_src\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marticles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ws/hello-ltr/ltr/index.py\u001b[0m in \u001b[0;36mrebuild\u001b[0;34m(client, index, doc_src)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     client.index_documents(index,\n\u001b[0;32m---> 17\u001b[0;31m                            doc_src=doc_src)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/hello-ltr/ltr/client/elastic_client.py\u001b[0m in \u001b[0;36mindex_documents\u001b[0;34m(self, index, doc_src)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0maddCmd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melasticsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbulk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbulkDocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_src\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mresp_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Streaming Bulk index DONE {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBulkResp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py\u001b[0m in \u001b[0;36mbulk\u001b[0;34m(client, actions, stats_only, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;31m# make streaming_bulk yield successful results so we can count them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'yield_ok'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstreaming_bulk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;31m# go through request-reponse pairs and detect failures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py\u001b[0m in \u001b[0;36mstreaming_bulk\u001b[0;34m(client, actions, chunk_size, max_chunk_bytes, raise_on_error, expand_action_callback, raise_on_exception, max_retries, initial_backoff, max_backoff, yield_ok, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m                             _process_bulk_chunk(client, bulk_actions, bulk_data,\n\u001b[1;32m    191\u001b[0m                                                 \u001b[0mraise_on_exception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                                                 raise_on_error, *args, **kwargs)\n\u001b[0m\u001b[1;32m    193\u001b[0m                         ):\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py\u001b[0m in \u001b[0;36m_process_bulk_chunk\u001b[0;34m(client, bulk_actions, bulk_data, raise_on_exception, raise_on_error, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mBulkIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%i document(s) failed to index.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m def streaming_bulk(client, actions, chunk_size=500, max_chunk_bytes=100 * 1024 * 1024,\n",
      "\u001b[0;31mBulkIndexError\u001b[0m: ('100 document(s) failed to index.', [{'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/06/29/rolling-out-new-blog/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Rolling out new blog', 'url': 'https://opensourceconnections.com/blog/2006/06/29/rolling-out-new-blog/', 'author': 'eric-pugh', 'content': ' Weve discussed setting up a company-wide blog for a while now, and today I decided to just go ahead and do it. We looked at some of the powerful ones, but realized that simplicity is all we need, and therefore SimpleLog is an obvious answer! \\n\\n Look for postings about what is going on at OpenSource Connections. \\n', 'excerpt': ' Weve discussed setting up a company-wide blog for a while now, and today I decided to just go ahead and do it. We looked at some of the powerful ones, but realized that simplicity is all we need, and therefore SimpleLog is an obvious answer! Look for postings about what is going on at OpenSource […] \\n', 'post_date': '2006-06-29T00:00:00-0400', 'categories': ['blog', 'News'], 'id': 'https://opensourceconnections.com/blog/2006/06/29/rolling-out-new-blog/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/06/30/preparation-for-oscon/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Preparation for OSCON', 'url': 'https://opensourceconnections.com/blog/2006/06/30/preparation-for-oscon/', 'author': 'jason-hull', 'content': ' While we did not think that we could sign up, show up, and generate business, there are many separate factors that we must consider to make sure that our first big exhibition is a success. \\n\\n Media: As a company that has always focused on word-of-mouth referrals and marketing for our business, we have not developed a robust set of marketing materials. Thus, we needed to come up with our exhibit backdrop, fliers, press releases, and determine what it was that we were going to display. If you can afford it, it is worthwhile to use a couple of different resources. First, a graphic designer. Find someone who has designed for exhibits before and who has a good understanding of your target audience. If your reaction to this is “what is my target audience,” then you have more work to do before you can get to this stage. Second, a copy writer. If you cannot capture the essence of what you do and get the reader of your materials to want to engage in further conversations in 20 words or less, rewrite it. Most technical people do not have the language savvy and skills to do this; a few hours with a professional copywriter will help you. We have used Proofrock Copy and been very happy with their results. \\n\\n Message: You cant be everything to everyone. Even if you offer several packages, trying to sell all of them will likely result in failing to close on potential deals because of lack of focus. We have chosen to focus on two main areas: strategic engagements and Agile Development training. The strategic engagements are designed for our clients to develop the appropriate roadmap for getting their IT systems to the point to where they can provide the information that decision makers need to drive business forward. Agile Development training is, for the most part, self-explanatory. Its still more of a buzzword than a practice, and many teams have tried and failed to incorporate Agile because of lack of appropriate training and methodologies. While we have other offerings, such as laboratory information management systems and content management systems, we would rather focus on 200 of the 3,000 attendees than cast a wide net and hope to snag a random hit. \\n\\n Extras: Just signing up for an exhibit and renting/buying your exhibit standup materials doesnt cover everything. Dont forget that youre going to have to rent carpet, trash cans, cleaning crew, podia, tables, chairs, etc. If youve never done an exhibition before, network with people who have to see what their costs were. If you cant find someone who has, then take your estimates and double them. Additionally, dont spend yourself down to nearly nothing to exhibit. There will be follow-up work and engagements (one hopes) after the convention, and you will need the capital to fund your follow-up sales efforts and initial engagement work. \\n\\n Were going to have some exciting things at OSCON. We look forward to meeting all of you there! \\n\\n', 'excerpt': ' While we did not think that we could sign up, show up, and generate business, there are many separate factors that we must consider to make sure that our first big exhibition is a success. Media: As a company that has always focused on word-of-mouth referrals and marketing for our business, we have not developed […] \\n', 'post_date': '2006-06-30T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/06/30/preparation-for-oscon/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/12/trying-to-explain-what-open-source-is/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Trying to explain what \"Open Source\" is?', 'url': 'https://opensourceconnections.com/blog/2006/07/12/trying-to-explain-what-open-source-is/', 'author': 'jason-hull', 'content': ' Here are a couple articles related to both open source software, as well as the culture surrounding the open source world. \\n\\n Open Source in the Public Interest \\n\\n An Overview of Open Source License by American Bar Association \\n\\n Open source software: A short interpretive history \\n\\n The Cathedral and the Bazaar \\n\\n', 'excerpt': ' Here are a couple articles related to both open source software, as well as the culture surrounding the open source world. Open Source in the Public Interest An Overview of Open Source License by American Bar Association Open source software: A short interpretive history The Cathedral and the Bazaar \\n', 'post_date': '2006-07-12T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/07/12/trying-to-explain-what-open-source-is/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/12/what-are-the-costs-and-benefits-of-integration/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'What are the costs and benefits of integration?', 'url': 'https://opensourceconnections.com/blog/2006/07/12/what-are-the-costs-and-benefits-of-integration/', 'author': 'jason-hull', 'content': ' We are working to foster a relationship with a potential client. They have clients who use tools which do not integrate with each other, causing these clients to enter in information manually. \\n\\n Some of these companies have a relatively low price point that they are willing to pay for the integration of the tools that they use. However, by not looking at the long-term opportunity costs of not using the integration tools, these companies are understating costs of inaction. \\n\\n Lets assume that failure to integrate the tools means that once a month, someone has to enter in 75 entries into two different databases rather than one. Furthermore, lets assume that each set of entries takes 2 minutes, meaning that 2.5 hours per month is spent in duplicate entry. This is 30 hours a year that someone is spending entering in duplicate information. Finally, lets assume that the fully-loaded cost of this employee is $40/hour. Thats a $1,200 cost/year that the company has which it does not need. \\n\\n Are there examples in your company where manual processes are costing time, and ultimately, money? Are you costing your company more money in the long run by not investing to fix the process issues? \\n', 'excerpt': ' We are working to foster a relationship with a potential client. They have clients who use tools which do not integrate with each other, causing these clients to enter in information manually. Some of these companies have a relatively low price point that they are willing to pay for the integration of the tools that […] \\n', 'post_date': '2006-07-12T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/07/12/what-are-the-costs-and-benefits-of-integration/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/19/running-with-scissors-overriding-latest_revision-svn-check-in-capistrano/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Running with scissors: overriding latest_revision SVN check in Capistrano', 'url': 'https://opensourceconnections.com/blog/2006/07/19/running-with-scissors-overriding-latest_revision-svn-check-in-capistrano/', 'author': 'eric-pugh', 'content': ' Ruby as a language sometimes feels like you are running with scissors. Its great to get from A to B quickly with your scissors, but there is a chance you may trip and impale yourself! \\n\\n Today I was struggling with overriding what revision Capistrano uses when checking code out of Subversion as a hack to get around the lack of support for svn+ssh:// connectivity. Be default Capistrano makes a check from your local box for the latest revision, and then uses that to check out content on the remote box. However I wanted to skip the check from my local box and just pass in “HEAD” as the revision name. \\n\\n My first solution was just to hack up the Subversion class and hard code the @latest_revision to be “HEAD”. But I realized what an ugly solution tweaking my gem was! \\n\\n After banging my head a bit, I realized that Ruby is a dynamic language, and I can do all sorts of magic that maybe I shouldnt be doing. It was time to use instance_variable_set! \\n\\n I added :before_update_code that allows me to manually set the revision in my deploy.rb and therefore bypass the check: \\n\\n task :before_update_code, :roles =&gt; [:web, :app] do\\n  revision = \"HEAD\"\\n  puts \"Revision to be deployed is #{revision}\"\\n  source.instance_variable_set(\"@latest_revision\",revision)\\nend\\n \\n\\n It does kind of make me wonder if all those OOP rules about encapsulation no longer apply! \\n', 'excerpt': ' Ruby as a language sometimes feels like you are running with scissors. Its great to get from A to B quickly with your scissors, but there is a chance you may trip and impale yourself! Today I was struggling with overriding what revision Capistrano uses when checking code out of Subversion as a hack to […] \\n', 'post_date': '2006-07-19T00:00:00-0400', 'categories': ['blog', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2006/07/19/running-with-scissors-overriding-latest_revision-svn-check-in-capistrano/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/25/we-made-it-to-oscon/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'We made it to OSCON!', 'url': 'https://opensourceconnections.com/blog/2006/07/25/we-made-it-to-oscon/', 'author': 'eric-pugh', 'content': ' After 8 hours of travel, we arrived into PDX last night at 10:50 PM. Headed down to the luggage claim and saw our pop up booth packed in a large plastic shipping case, codenamed “Napolean”, come out.. Well, actually, what first came out was a red ratchet strap that theorectically was holding the heavy plastic case together! You can imagine the feeling of panic I felt contemplating two days of exhibiting with no booth! \\n\\n  \\n\\n Fortunantly 5 minutes later “Napolean” showed up, sans ratchet strap. \\n\\n', 'excerpt': ' After 8 hours of travel, we arrived into PDX last night at 10:50 PM. Headed down to the luggage claim and saw our pop up booth packed in a large plastic shipping case, codenamed “Napolean”, come out.. Well, actually, what first came out was a red ratchet strap that theorectically was holding the heavy plastic […] \\n', 'post_date': '2006-07-25T00:00:00-0400', 'categories': ['blog', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2006/07/25/we-made-it-to-oscon/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/27/oscon-1st-day-exhibit-thoughts/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'OSCON 1st day exhibit thoughts', 'url': 'https://opensourceconnections.com/blog/2006/07/27/oscon-1st-day-exhibit-thoughts/', 'author': 'jason-hull', 'content': ' The biggest thing that surprised me was the preponderance of Perl developers at the convention. For a “dying language,” Perl seems to be pretty alive and well. \\n\\n I also expected to see a lot of people who wanted to learn more about Rails and Ruby (is this redundant or what?). Maybe they were all eyeball deep in training. \\n\\n We did build a 5 minute Rails app to show the winners of our drawing for the book “Practice of an Agile Developer” by Andy Hunt. Little did we know that wed have the pleasure of being two booths down from Andy, so its been fun dragging our winners down to Andys booth to have him autograph the book. I wonder if Ill see signed books popping up on eBay. We want 10% of the profits! :) \\n\\n We did hire two promotional models and a licensed massage therapist to help out at our booth. First off, all three of them are phenomenal! Kudos to Kelsey and Susan (our direct marketing consultants) and Pamlin (our LMT)! \\n\\n I had expected the flow of people through them to be much different than it wound up being. I thought that we could send Kelsey and Susan out on the floor and stage them at the exits to sessions and have them find people and drag them over to our booth. What they quickly ascertained was that they had no connection to people (after all, if youre looking to exit the session as quickly as possible to either go smoke or connect to the Net, youre not going to want to talk to anyone). From a conventioneers point of view, they were just another set of people to walk by en route to somewhere else. So, they came back, hung around the booth, and did a great job of engaging people and bringing them in to talk to us. Also, they were both incredibly quick studies and can now give our elevator speech better than we can! \\n\\n We also expected Pamlin to be a hit and for a line to go around the corner for her services. What we have discovered is that people are pretty reticent to have their feet rubbed. If we come back next year, were going to have her bring a backrub chair instead of the footrub recliner. However, Pamlin is also very bright and engaging, and while I doubt that she did massage services for more than 6 people (outside of the OSC team), I doubt there was more than a total of 30 minutes out of the 600 that the exhibit was open that she wasnt talking to someone. \\n\\n If youre ever going to exhibit in Portland (not for OSCON) and want to hire people who can help you out with your booth, then drop me a line and Ill put you in contact with them. One caveat: you cant have them for OSCON 2007. Theyre ours! \\n\\n We also conducted a vendor presentation yesterday, which well put online shortly. While I initially felt pretty unahppy about the results, after talking to Eric, I realized that it served its purpose. It was free advertising. Never turn down a chance to give a 20 minute spiel about what you do, even if the audience is pretty small. You never know whos going to hear the few key phrases that they need to hear to perk their ears and ask a few more questions. \\n\\n Finally, the two conversational topics that I discussed the most are Agile Development and business process analysis. Theres definitely a hunger for good information and training about Agile Development. Additionally, in my discussions, I think that I can safely say that, in general, IT managers have trouble convincing their business counterparts of the business case for changes in software systems. Knowing that a change is necessary is a first step, but being able to frame the discussion in the terms that the business managers understand is critical. A part of me is a little disappointed that the range of discussions wasnt a little wider, as I feel like our real strength is in our distributed development capabilities, namely our ability to take on projects and ramp up and integrate extremely capable teams in a rapid timeframe, but you go where the market demands, and it seems that business process analysis and Agile Development are the main pain points that Im seeing, at least of the attendees Ive spoken with. \\n', 'excerpt': ' The biggest thing that surprised me was the preponderance of Perl developers at the convention. For a “dying language,” Perl seems to be pretty alive and well. I also expected to see a lot of people who wanted to learn more about Rails and Ruby (is this redundant or what?). Maybe they were all eyeball […] \\n', 'post_date': '2006-07-27T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/07/27/oscon-1st-day-exhibit-thoughts/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/07/29/decompressing-from-oscon/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Decompressing from OSCON', 'url': 'https://opensourceconnections.com/blog/2006/07/29/decompressing-from-oscon/', 'author': 'eric-pugh', 'content': ' Im sitting at TopPot in Seattle slowly digesting all the things that we did and learned at OSCON! Ive got a stack of contacts to follow up with, and feel very invigorated about the state of the open source world. \\n\\n Our BoF: Scrum War Stories was very well recieved, with 14 particpants and some at times heated discussion! Exactly what you want at a BoF! We helped solve some job difficulties, learned about some new books, and talked about Scrum in the real world. As I promised, Ill have notes posted later this week. I also mentioned our Rugby addon for Scrum project tracking with Trac. I took advantage of Googles Project Host being unveiled at OSCON and did a quick landgrab for “rugby”. Ill have SVN updated over the next couple of days on our new site at http://code.google.com/p/rugby/. \\n\\n Ill also post the after action review of OSCON this week. \\n', 'excerpt': ' Im sitting at TopPot in Seattle slowly digesting all the things that we did and learned at OSCON! Ive got a stack of contacts to follow up with, and feel very invigorated about the state of the open source world. Our BoF: Scrum War Stories was very well recieved, with 14 particpants and some at […] \\n', 'post_date': '2006-07-29T00:00:00-0400', 'categories': ['blog', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2006/07/29/decompressing-from-oscon/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/01/battle-of-the-scaffolds-aug-9th/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Battle of the Scaffolds Aug 9th', 'url': 'https://opensourceconnections.com/blog/2006/08/01/battle-of-the-scaffolds-aug-9th/', 'author': 'eric-pugh', 'content': ' Join Eric Pugh of OpenSource Connections August 9th at RubyJam as he pits two competing scaffolds designed for quickly ripping out a CRUD interface: AjaxScaffold and Streamlined. Learn the strengths and weaknesses of each. See the design choices the developers took to minimize the code intrusion of their tools into your application. See how much fun tabluar editing of data is when you have Ajax goodness! \\n\\n 6:30 PM, Room 160 at Darden Business School \\n\\n', 'excerpt': ' Join Eric Pugh of OpenSource Connections August 9th at RubyJam as he pits two competing scaffolds designed for quickly ripping out a CRUD interface: AjaxScaffold and Streamlined. Learn the strengths and weaknesses of each. See the design choices the developers took to minimize the code intrusion of their tools into your application. See how much […] \\n', 'post_date': '2006-08-01T00:00:00-0400', 'categories': ['blog', 'Code', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2006/08/01/battle-of-the-scaffolds-aug-9th/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/02/scrum-war-stories-recap/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Scrum War Stories Recap', 'url': 'https://opensourceconnections.com/blog/2006/08/02/scrum-war-stories-recap/', 'author': 'eric-pugh', 'content': ' As I promised at the close of our BoF: Scrum War Stories, I would write up a couple of the notes I made during our discussions. They arent in any specific order, and I only have some of the names of people who spoke written down Unfortunately those name tags at OSCON seemed to really want to flip around! If I ever host a conference, I am putting the names of people on both sides of the badge. \\n\\n Before I begin I want to thank everybody who showed up! 14 people was a very healthy number of folks. Enough so that we can generate some real ideas, with people who were just learning about it up to people who are certified ScrumMasters and have been using it in the real world. \\n\\n Mauro Talevi led off with a quick introduction on Scrum. One of the key points he made is that while processes like XP or RUP are “prescriptive”, Scrum is “adaptive”. XP says: “If you take my medicine faithfully and fully, then things will be better”, whereas Scrum says: “Lets honestly try some principles that are very common sense and see if we can change peoples behavior”. I really appreciated that distinction. Medicine versus Therapy. \\n\\n He also pointed out that Scrum is a process for developers, but first and foremost is a method of communicating with the rest of the business. And that because it extends outside of the development team, what seems simple is actually incredibly hard to implement. And that lip service to Scrum processes doesnt work. \\n\\n We then chatted a lot about Jasons situation where he has internal clients at a university. He wondered if you could use Scrum with internal clients. He wants to use it, has been championing it, and it hasnt gone anywhere. After the group asked some more questions about his situation, in many ways Scrum was not a fit. In his situation, the business folks were not onboard with Scrum, and his attempts to gather requirements was failing. The advice was that: \\n\\n \\n   another job was better! A couple folks with university backgrounds had experience frustrations of the type that Jason was feeling. \\n   on a more constructive side, the group said he should just get enough requirements to start a prototype, and once the clients had something to look at, the rest of the requirements would become solid. Even if the original prototype was tossed out. \\n   Use interview process to elicit requirements. Someone mentioned a tool called DENIM (Denim?) for drawing simple GUIS for use in interviews. Another mention was made of using storyboard and tool that helps with that. Search Google for “XUL + Berlin”. \\n   Scrum doesnt work without a team. If you are a developer of one then you cant do Scrum. I showed how I organize my day to day life with a nice notebook that I scribble in. A notebook with “what I have to do” is not a stand up meeting! \\n \\n\\n The conversation drifted away from Scrum to requirements gathering for a while. The question came up, how do you take a 30 month project and figure out what you can do in 4 months of work. The answer seemed to be “ask the client, they know at some gut level what the minimum is”, or cancel the project completely, and solve the problem in a different, not IT way. \\n\\n Aaron Farr then brought the topic back to Scrum as he said he thinks Scrum works even better with internal customers then external clients. A consulting firm with external clients has to justify every billable hours, so there is more of a framework and focus on managing scope and deliverables. Internal customers rarely are directly paying the developers, so they feel more leeway to change things around. This feeds directly back to the usefulness of Scrum. He also pointed out that you should let “Management be management”. They set the budget and tasking. You as a developer dont. All you set is time. \\n\\n The improvement in your team, as measured by your Velocity was brought up. Was it a factor of using Scrum? Was it just the team becoming better developers? Or is it that over time you become more familiar with your domain? Some suggestions was that the additional stability provided to your team by Scrum leads to better developers (less stress) and the interactive approach helps build knowledge of the domain. \\n\\n A scary question was asked: “Can you lose your job?” Mauro replied yes, and explained that someone he knew in Scrum circles had “lost” their job because their job was to introduce Scrum, and while management had asked for Scrum, they were not willing to change their processes. Lip service was what they were looking for, and the ScrumMaster they brought in wanted to make actual behavior changes in how software development was handled. It was a sobering anecdote that ScrumMasters are often “Change Agents” which may ruffle a lot of feathers. And without management support, that can be a disaster. \\n\\n “Slack” by Tom DeMarco was mentioned as a good book for people interested in Scrum. I hadnt heard of it, but added it to my Amazon wish-list! \\n\\n Lastly, we talked about tools. Tools, always a favorite for software developers! Someone brought up a web based wiki/spreadsheet, and after a bit of confusion we realized it was Dan Bricklins project. Dan and I gave presentations at a symposium once, and I learned a huge amount from him! I also mentioned “Rugby”, which is almost ready for public consumption. Ill be posting more fully on it later, but it will be available from http://code.google.com/p/rugby/ . There is a Google Group where I will be posting more information. \\n\\n I was very gratified at the turnout for my BoF, and am looking forward to hosting more at future conferences! If you have any questions, want to talk more about Scrum, please feel free to contact me at epugh@opensourceconnections.com . Thanks to everyone who showed up! \\n\\n', 'excerpt': ' As I promised at the close of our BoF: Scrum War Stories, I would write up a couple of the notes I made during our discussions. They arent in any specific order, and I only have some of the names of people who spoke written down Unfortunately those name tags at OSCON seemed to really […] \\n', 'post_date': '2006-08-02T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2006/08/02/scrum-war-stories-recap/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/03/reflections-on-oscon/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Reflections on OSCON', 'url': 'https://opensourceconnections.com/blog/2006/08/03/reflections-on-oscon/', 'author': 'jason-hull', 'content': ' It appears to me that, after having talked to countless people at OSCON, there is still a significant disconnect between IT and the rest of the business. \\n\\n I say this because IT representatives had a pretty good idea of what they wanted to do and why. However, when it came to getting someone to pony up the coin to make the changes necessary to move forward, IT representatives, for the most part, were at a loss for how to shake out the money tree. \\n\\n The biggest reason is that business views IT as a cost center, and so spending on IT needs to be minimized as much as possible. When I asked what the criteria for making decisions was, the inevitable answer was money. The bottom line loomed so large that it drowned out any other competing interest. This is short-sighted and reflective of a company trying to make this quarters numbers without looking at how its going to make next quarters numbers, much less next years numbers. \\n\\n To me, this is analogous to building a house out of particle board. Sure, once the house is done, the total cost of building the house will be extremely low. It will also be a cheap house and will serve no habitable purpose. \\n\\n Even for companies that are willing to spend to improve their IT systems, often, they did not know the business purpose they were trying to achieve. They did not know where the weaknesses in process were that the appropriate application of technology could improve. Furthermore, they did not consider total cost of ownership rather than up front price. I liken this to putting caulk around a leak. It might work. But it might also be only a temporary fix and cost more in the long run. Only good solid analysis of the problem and true understanding of a set of requirements can determine if what youre seeking is truly the answer that you want. \\n\\n Finally, there is an appetite for knowledge about Agile Development, but seemingly few resources available. We gave away Andy Hunts book Practices of an Agile Developer, that can help teams and developers get started down the path. \\n\\n All in all, the convention was time well spent. We met a lot of people and got in touch with what was going on in the open source community. We will definitely plan on being at OSCON 2007, and we will make sure we leave enough time to do more discovery of the Columbia River gorge! \\n\\n', 'excerpt': ' It appears to me that, after having talked to countless people at OSCON, there is still a significant disconnect between IT and the rest of the business. I say this because IT representatives had a pretty good idea of what they wanted to do and why. However, when it came to getting someone to pony […] \\n', 'post_date': '2006-08-03T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/08/03/reflections-on-oscon/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/04/eric-pugh-to-present-at-vptc-2007-trends-seminar/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric Pugh To Present At VPTC 2007 Trends Seminar', 'url': 'https://opensourceconnections.com/blog/2006/08/04/eric-pugh-to-present-at-vptc-2007-trends-seminar/', 'author': 'jason-hull', 'content': ' Eric Pugh will be a guest panelist at the September 2006 VPTC meeting. He will be covering trends in technology that we can expect to see in 2007. More details to follow. \\n', 'excerpt': ' Eric Pugh will be a guest panelist at the September 2006 VPTC meeting. He will be covering trends in technology that we can expect to see in 2007. More details to follow. \\n', 'post_date': '2006-08-04T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2006/08/04/eric-pugh-to-present-at-vptc-2007-trends-seminar/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/04/why-open-source-works/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Why Open Source Works', 'url': 'https://opensourceconnections.com/blog/2006/08/04/why-open-source-works/', 'author': 'eric-pugh', 'content': ' Last night I experienced again why open source works. I was beating my head getting sorting to work in Ruport (Ruby Reporting Package), and instead of opening a support ticket I posted to the mailing list: \\n\\n http://lists.stonecode.org/pipermail/ruport-stonecode.org/2006-August/thread.html#227 \\n\\n `Nuff said. \\n', 'excerpt': ' Last night I experienced again why open source works. I was beating my head getting sorting to work in Ruport (Ruby Reporting Package), and instead of opening a support ticket I posted to the mailing list: http://lists.stonecode.org/pipermail/ruport-stonecode.org/2006-August/thread.html#227 `Nuff said. \\n', 'post_date': '2006-08-04T00:00:00-0400', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2006/08/04/why-open-source-works/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/09/mandatory-upgrade-of-rails-115/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Mandatory Upgrade of Rails 1.1.5!', 'url': 'https://opensourceconnections.com/blog/2006/08/09/mandatory-upgrade-of-rails-115/', 'author': 'eric-pugh', 'content': ' Saw a post on Riding Rails about an extremely dangerous security hole in Rails. Read the full warning from DHH here. \\n\\n For me to update the software for this blog meant: \\n\\n sudo gem update rails\\ncap restart\\n \\n\\n See you at RubyJam tonight! \\n\\n', 'excerpt': ' Saw a post on Riding Rails about an extremely dangerous security hole in Rails. Read the full warning from DHH here. For me to update the software for this blog meant: sudo gem update rails cap restart See you at RubyJam tonight! \\n', 'post_date': '2006-08-09T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2006/08/09/mandatory-upgrade-of-rails-115/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/15/osc-wins-3rd-place-at-ruportday/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'OSC wins 3rd Place at RuportDay', 'url': 'https://opensourceconnections.com/blog/2006/08/15/osc-wins-3rd-place-at-ruportday/', 'author': 'eric-pugh', 'content': ' Okay, so its not the SuperBowl, but I won 3rd place during the 2006 Ruport Day! \\n\\n Ruport Day was an attempt to pull together a bunch of folks and hammer out new features, documentation, and tutorials, with cash prizes for 1st through 3rd places. \\n\\n The wrap-up email is here. \\n\\n I joined the crew around 8:30 PM, and put in a couple hours, learning enough about Ruport to contribute some ideas, read a lot of Ruby source, and put in a small recipe. \\n\\n Ruport is the first project that Ive contributed to since doing development in Ruby, and they are a great group, very supportive. \\n\\n', 'excerpt': ' Okay, so its not the SuperBowl, but I won 3rd place during the 2006 Ruport Day! Ruport Day was an attempt to pull together a bunch of folks and hammer out new features, documentation, and tutorials, with cash prizes for 1st through 3rd places. The wrap-up email is here. I joined the crew around 8:30 […] \\n', 'post_date': '2006-08-15T00:00:00-0400', 'categories': ['blog', 'Community', 'News'], 'id': 'https://opensourceconnections.com/blog/2006/08/15/osc-wins-3rd-place-at-ruportday/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/16/social-networking-20-a-blessing-and-a-curse/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Social Networking 2.0, A Blessing and a Curse', 'url': 'https://opensourceconnections.com/blog/2006/08/16/social-networking-20-a-blessing-and-a-curse/', 'author': 'jason-hull', 'content': ' When I was in the Army, a useful skill that I had was knowing who could do what and being a favor broker. Managing a much larger network is vastly different. \\n\\n Gartner recently identified emerging technologies, including the Web 2.0s social networking capabilities. The network is there. The ability to readily both data mine and qualify the network is not. \\n\\n If you go to myspace or flickr or blogger, you can find a maze of people who have posted random information. As one of the Technorati people says, “50 million blogs…some of them have to be good.” \\n\\n Yes, some of them have to be good. But how do you know? \\n\\n First, it helps to know what the tools of Web 2.0 are. Tim OReilly gives a great overview here. \\n\\n The crux of the value of Web 2.0 is in information aggregation. Most any piece of information that someone could seek is available on the web, but determining where that information is, and, once found, the value of the information remains a challenge. The value creation of the web beyond mere presentation of information (funny how mere presentation of information is accepted; yet, 10 years ago, would have been a taboo thought) is in aggregation and filtering. Here is where folksonomy (defined here:) helps out. \\n\\n The basic premise behind folksonomy is the same behind market theory. Over time, collective intelligence is better than singular intelligence. So, by using tagging and then community acceptance, information is found, organized, and voted on. It is the Survivor voting off ceremony of the Internet. Good information is tagged, approved, and disseminated. Bad information gets relegated to some dark corner of the Internet or gets sent to your inbox as spam. \\n\\n However, the data mining capabilities are still in infancy. A business example that we face illustrates this point. When we are ready to take on more developers into our team, we will use a variety of methods to find those people. Craigslist, Linked In, and Sourceforge will be three of our venues, along with others. However, only directly will we be able to use a community vote to determine who the “winner” is. Resumes do not have bookmark counts like they do in del.icio.us. Code does not have a beauty contest. \\n\\n In the end, we are responsible for the decisions we make. We will still have to review code and conduct interviews ourselves. After all, even if there were a social network for resumes and candidates, we are the ones spending the money to hire, and we can only look in the mirror when we spend wisely or poorly. \\n\\n', 'excerpt': ' When I was in the Army, a useful skill that I had was knowing who could do what and being a favor broker. Managing a much larger network is vastly different. Gartner recently identified emerging technologies, including the Web 2.0s social networking capabilities. The network is there. The ability to readily both data mine and […] \\n', 'post_date': '2006-08-16T00:00:00-0400', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2006/08/16/social-networking-20-a-blessing-and-a-curse/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/08/22/selenium-boot-camp/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Selenium Boot Camp', 'url': 'https://opensourceconnections.com/blog/2006/08/22/selenium-boot-camp/', 'author': 'eric-pugh', 'content': ' In true something or other style, at last nights Selenium Boot Camp the teacher was the student. We decided to hold an after hours “boot camp” so we could beef up our skills at automated testing. And while technically I was the teacher, I ended up learning just as much about doing Selenium testing as the students! Darn those hard to answer questions from professional QA people (thanks Cristen!). \\n\\n So, the biggest thing we learned about was using the Web Developer plugin for FireFox. That plugin really helps simplify testing with Selenium. So, a couple tips: \\n\\n \\n   Trying to figure out the name or ID of some content that is returned by an AJAX call? Typically doing “View Source” wont return that content! However, with the Web Developer, henceforth called WD, you can do “View Source -&gt; View Generated Source” and see the source for your AJAX generated HTML. \\n   Trying to figure out the field names and ids? Use “Forms -&gt; Display Form Details” to see all the form element data. Much faster then digging through source. \\n   However, if you are just building up a bunch of type or select lines to populate a form, then use “Forms -&gt; Populate Form Fields” puts the names of the form elements into the fields in large text. \\n   Lastly, if you want a quick summary of the form, then use “Forms -&gt; View Form Information”. You can get information like label or max length or size and quickly write up all your form data entry actions. \\n \\n\\n We also learned how important sensible id= tags are in HTML pages. Without them you have to resort to all sorts of odd hacks and xpath queries to find what you want to click on. Unfortunantly AjaxScaffold doesnt support id= everywhere, but it was easy to add. \\n\\n', 'excerpt': ' In true something or other style, at last nights Selenium Boot Camp the teacher was the student. We decided to hold an after hours “boot camp” so we could beef up our skills at automated testing. And while technically I was the teacher, I ended up learning just as much about doing Selenium testing as […] \\n', 'post_date': '2006-08-22T00:00:00-0400', 'categories': ['blog', 'News'], 'id': 'https://opensourceconnections.com/blog/2006/08/22/selenium-boot-camp/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/09/06/developers-need-project-managers-too/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Developers need project managers too!', 'url': 'https://opensourceconnections.com/blog/2006/09/06/developers-need-project-managers-too/', 'author': 'jason-hull', 'content': ' Oftentimes, lead developers wind up playing the role of project manager. For a small project, its OK because the level of administrative overhead is small. For large projects, its the wrong call. \\n\\n In resource constrained environments, lead developers are often asked to wear many hats. In small companies, this is both understandable and acceptable. Spending the extra money on a dedicated project manager when the lead developer can play that rol–albeit not as effectively–for only the opportunity cost of time may not make financial sense. \\n\\n However, once a team is working on a project with critical mass, utilizing a project manager becomes essential. \\n\\n Reason 1: Developers develop better than they manage. Though this is a generalization, and there are developers who manage quite well, the reason that they are on projects as developers is because they can deliver solid code. While they may be good at customer management, administration, milestone setting, and all of the other things that a project manager excels at, theyre probably better at coding. In economics, its the idea of comparative advantage. \\n\\n Reason 2: Every minute a developer spends on project management is a minute not spent on coding. Most projects have timelines for a reason, and anything that could divert a developer from delivering on that timeline is something that brings on additional risk to the project. \\n\\n Project managers handle the administrative tasks that set up the developers to be able to get into a zone and crank out great code. They knock down obstacles that come up. They are the face of the project and interact with the customer, keeping the developer from having to answer the customer questions that come up. The project manager can also help manage expectations and keep the project from veering like a driverless car. \\n\\n Project managers are not a panacea to a project. Putting a project manager on a project will not guarantee delivery. Its still up to the developers on the project to actually produce the code that satisfies the customer needs. When time and resources are constrained, then a willingness to invest in project management skills can increase the chances of successful delivery. \\n', 'excerpt': ' Oftentimes, lead developers wind up playing the role of project manager. For a small project, its OK because the level of administrative overhead is small. For large projects, its the wrong call. In resource constrained environments, lead developers are often asked to wear many hats. In small companies, this is both understandable and acceptable. Spending […] \\n', 'post_date': '2006-09-06T00:00:00-0400', 'categories': ['blog', 'Productivity', 'Project Management'], 'id': 'https://opensourceconnections.com/blog/2006/09/06/developers-need-project-managers-too/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/09/07/brazilian-scrum-session/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Brazilian Scrum session', 'url': 'https://opensourceconnections.com/blog/2006/09/07/brazilian-scrum-session/', 'author': 'eric-pugh', 'content': ' Going to be in Brazil in October? Leandro Cruz from Web007 will be leading a session on Scrum during the Borland Conference on Oct. 6 through 8th. Hes done a lot of work with spreading Scrum among Brazilian agile developers and promises to have a great session. \\n', 'excerpt': ' Going to be in Brazil in October? Leandro Cruz from Web007 will be leading a session on Scrum during the Borland Conference on Oct. 6 through 8th. Hes done a lot of work with spreading Scrum among Brazilian agile developers and promises to have a great session. \\n', 'post_date': '2006-09-07T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2006/09/07/brazilian-scrum-session/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/01/the-long-tail-of-the-it-supply-chain/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'The Long Tail of the IT supply chain', 'url': 'https://opensourceconnections.com/blog/2006/10/01/the-long-tail-of-the-it-supply-chain/', 'author': 'jason-hull', 'content': ' In the past two years, Chris Andersons Long Tail has become relatively common in the business lexicon. Does the long tail apply to coders? \\n\\n Common business knowledge says that companies should focus on their core competencies. Having fat staff that doesnt contribute to the focus of the company reduces overall efficiency of the companys resources. Return on assets and revenue per employee drops. Additionally, internal teams tend to lose their edge and do not keep up with the latest trends and knowledge. \\n\\n The answer to this problem is outsourcing tasks that require specialized knowledge. A common example is utilization of external law firms for major court cases. While companies maintain legal counsel for ordinary, non-specialized tasks such as employment contracts and basic SEC filing, few companies will look to their internal corporate legal staffs to lead the defense of a lawsuit against the company. \\n\\n This process also applies to IT staffs. Internal corporate IT staffs are generally well-skilled, but generalists. They can keep the engine running, but are not staffed appropriately to handle large projects. Hence, companies look to external agencies for staff augmentation. Not only can external agencies help smooth out staffing requirements, but these contracted developers can bring in new knowledge to the existing IT teams. \\n\\n In applying Long Tail theory, corporate IT staffs are the head of the curve, and the contracted developers are the tail. \\n\\n Typical recruiting processes focus on the head rather than on the tail. This makes economic sense for corporate recruiters and for recruiting firms. They seek to place developers in full-time jobs, and the economic incentives of working to develop the capabilities to deliver short-term contract developers with specific skills do not provide the profitability and value to move down the tail. Recruiting agencies utilize push processes; coders who want full-time jobs go to recruiters, and the recruiters push those coders to companies that are looking to hire coders. \\n\\n When looking for project staffing or short-term (under 1 year in duration) staff augmentation, look down the long tail for solutions. If you want to go down the long tail for your project or staff needs, contact us. \\n\\n Also, if you are one of those coders who lives in the Long Tail and doesnt want a full-time job, but also doesnt want to have to consistently self-market, send us a resume, code sample, and rate sheet. We are constantly looking to build up our contact list of exceptional coders who are interested in doing onsite short-term contracts. \\n\\n', 'excerpt': ' In the past two years, Chris Andersons Long Tail has become relatively common in the business lexicon. Does the long tail apply to coders? Common business knowledge says that companies should focus on their core competencies. Having fat staff that doesnt contribute to the focus of the company reduces overall efficiency of the companys resources. […] \\n', 'post_date': '2006-10-01T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/10/01/the-long-tail-of-the-it-supply-chain/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/12/continous-integration-presentation-for-cojug/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Continous Integration Presentation for COJUG', 'url': 'https://opensourceconnections.com/blog/2006/10/12/continous-integration-presentation-for-cojug/', 'author': 'eric-pugh', 'content': ' On Tuesday, October 10th I had the opportunity to speak to the Columbus Ohio Java User Group. They are a pretty large group, that actually has seperate lunch and dinner sessions to fit into peoples schedules! \\n\\n I spoke on Continous Integration, focusing on the case for CI, as well as the challenges in instituting CI on a long term basis. Because this was a Java user group, I focused on CruiseControl and Continuum. I have posted the slides for download. \\n\\n Thanks to Chris Judd for the invitiation and being a great host. I met some cool people, and had a really good time. My first visit to Ohio was a great visit. \\n\\n', 'excerpt': ' On Tuesday, October 10th I had the opportunity to speak to the Columbus Ohio Java User Group. They are a pretty large group, that actually has seperate lunch and dinner sessions to fit into peoples schedules! I spoke on Continous Integration, focusing on the case for CI, as well as the challenges in instituting CI […] \\n', 'post_date': '2006-10-12T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2006/10/12/continous-integration-presentation-for-cojug/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/16/whos-watching-road-show-is-starting/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': '“Who’s Watching” road show is starting!', 'url': 'https://opensourceconnections.com/blog/2006/10/16/whos-watching-road-show-is-starting/', 'author': 'eric-pugh', 'content': '  \\n\\n Join me and others for the Cyber Security Roadshow being put on by the “Whos Watching” campaign to increase public awareness of the profile people leave using the Internet. \\n\\n Ill be talking tonight and Wednesday about the scams and “phishing” attacks that target Senior Citizens. \\n\\n', 'excerpt': ' Join me and others for the Cyber Security Roadshow being put on by the “Whos Watching” campaign to increase public awareness of the profile people leave using the Internet. Ill be talking tonight and Wednesday about the scams and “phishing” attacks that target Senior Citizens. \\n', 'post_date': '2006-10-16T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2006/10/16/whos-watching-road-show-is-starting/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/20/selenium-presentation-neon-guild/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Selenium presentation @ Neon Guild', 'url': 'https://opensourceconnections.com/blog/2006/10/20/selenium-presentation-neon-guild/', 'author': 'eric-pugh', 'content': ' Hi Guilders: \\n\\n Heres your Friday-before reminder: \\n\\n Next Neon Guild Meeting: October 23, 2006 6-8pm\\nTopic: Selenium\\nPresenter: Eric Pugh, OpenSource Connections \\n\\n Selenium is a test tool for web applications. Selenium tests run directly in\\na browser, just as real users do. And they run in Internet Explorer, Mozilla\\nand Firefox on Windows, Linux, and Macintosh. No other test tool covers such\\na wide array of platforms. \\n\\n If you do any sort of development work, this will be a very useful session\\nto attend! \\n\\n If you dont do development work, come for the pizza and chitchat before the\\npresentation. \\n', 'excerpt': ' Hi Guilders: Heres your Friday-before reminder: Next Neon Guild Meeting: October 23, 2006 6-8pm Topic: Selenium Presenter: Eric Pugh, OpenSource Connections Selenium is a test tool for web applications. Selenium tests run directly in a browser, just as real users do. And they run in Internet Explorer, Mozilla and Firefox on Windows, Linux, and Macintosh. […] \\n', 'post_date': '2006-10-20T00:00:00-0400', 'categories': ['blog', 'News', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2006/10/20/selenium-presentation-neon-guild/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/24/recap-of-seleniumneon-guild/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Recap of  Selenium@Neon Guild', 'url': 'https://opensourceconnections.com/blog/2006/10/24/recap-of-seleniumneon-guild/', 'author': 'eric-pugh', 'content': ' “Nothing is ever easy” has been my motto for a while, and last night difficulties in getting a working projector going at the Neon Guild reinforced that motto! \\n\\n To make a long story short, I left my mini DVI -&gt; VGA adapter in Columbus Ohio. I got a replacement, only to discover 90 minutes before my Selenium presentation that it was the wrong adapter! \\n\\n Eventually I ended up with my laptop VPNed into another site running the demo, the conference room desktop connected to the projector, and a free trial version of WebEx connecting the two! \\n\\n While things painted a bit slow on the projector, everything worked out. \\n\\n I wanted to thank Jason See and Jeff Cooper for their effort in making sure the network was setup for my presentation on Selenium. \\n\\n For those interested in the slides you can download them. \\n\\n If you have any other questions about Selenium, please drop me a note! \\n\\n', 'excerpt': ' “Nothing is ever easy” has been my motto for a while, and last night difficulties in getting a working projector going at the Neon Guild reinforced that motto! To make a long story short, I left my mini DVI -&gt; VGA adapter in Columbus Ohio. I got a replacement, only to discover 90 minutes before […] \\n', 'post_date': '2006-10-24T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2006/10/24/recap-of-seleniumneon-guild/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/10/25/how-to-dedupe-your-itunes-collection/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'How to dedupe your iTunes collection', 'url': 'https://opensourceconnections.com/blog/2006/10/25/how-to-dedupe-your-itunes-collection/', 'author': 'eric-pugh', 'content': ' Update 5/25/20 Rinse appears to be gone, or just out of date and bad.  Not sure, with Apple Music etc if we dedupe these days! \\n\\n Update 4/24/2011. TidySongs is now Rinse! Same great product, but new vendor with a deeper music database that seems to match better. I’ve updated the links. \\n\\n Update 5/16/2010. When I am old and grey, I am going to tell my children about the most popular blog post I ever wrote, this one about iTunes deduping! I finally have to pass the baton of deduping on to \\n\\n TidySongs, a product from a company that coincidentally is in my home town of Charlottesville, Virginia! \\n\\n While iTunes provides a “View Duplicates” function, it intentionally doesnt provide anything to help you delete all the duplicates. Apples theory being that you should be very careful with all your music! And an automated system cant detect betweend duplicate songs, and just two versions of the same song. \\n\\n There are a couple AppleScripts out there that can help find all your duplicates as well. However, then you still have to manually go through the playlist and delete them. \\n\\n I unfortunantly have duplicated 780 songs, adding an extra 1.8GB of music files! As you can imagine, manually fixing this was not going to happen. Fortunantly I was able to programmatically solve this. I used the AppleScript Corral All Dupes to find all the duplicates, and made a minor tweak to it so that it would put into my “Dupes” playlist only the second version of the song. Just fire up Script Editor, and then open up the Corral All Dupes applescript application. \\n\\n Find the line that looks like this: \\n\\n â€” copy the list of dupes to the \"Dupes\" playlist\\nrepeat with y from 1 to length of dupesRef\\n \\n\\n And change the line to look like this \\n\\n repeat with y from 1 to (length of dupesRef) - 1\\n \\n\\n This will take all but the last last duplicate and put it on your Dupes playlist. \\n\\n Then, once it is done, just highlight them all, and hold down Option and Delete. The Option key makes iTunes delete the actual music files, versus just remove them from the playlist. This was a tidbit that took quite a bit of searching to find! \\n\\n PS, Corral All Dupes is painfully slow, but making this hack was much easier then in the PERL enabled version. \\n\\n', 'excerpt': ' ong&gt;Update 4/24/2011. TidySongs is now Rinse! Same great product, but new vendor with a deeper music database that seems to match better. I’ve updated the links. Update 5/16/2010. When I am old and grey, I am going to tell my children about the most popular blog post I ever wrote, this one about iTunes deduping! […] \\n', 'post_date': '2006-10-25T00:00:00-0400', 'categories': ['blog', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2006/10/25/how-to-dedupe-your-itunes-collection/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/11/01/bug-4814103-submitted-to-apple/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Bug 4814103 submitted to Apple!', 'url': 'https://opensourceconnections.com/blog/2006/11/01/bug-4814103-submitted-to-apple/', 'author': 'eric-pugh', 'content': ' I discovered a bug in Apples implementation of Java. When selecting multiple leaves in a JTree, and then ctrl + drag, the mouseDragged event should be fired. However, on a Mac, the mouseDragged event never fires! \\n\\n We tested on Linux and Windows, and everything works. Argh. At any rate, hopefully Problem ID 4814103 will soon be fixed:-) \\n\\n Not sure if others can see it, but the site is here https://bugreport.apple.com. \\n\\n The joys of doing Swing development! \\n', 'excerpt': ' I discovered a bug in Apples implementation of Java. When selecting multiple leaves in a JTree, and then ctrl + drag, the mouseDragged event should be fired. However, on a Mac, the mouseDragged event never fires! We tested on Linux and Windows, and everything works. Argh. At any rate, hopefully Problem ID 4814103 will soon […] \\n', 'post_date': '2006-11-01T00:00:00-0500', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2006/11/01/bug-4814103-submitted-to-apple/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/11/02/roping-in-the-cowboy-coders/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Roping In the Cowboy Coders', 'url': 'https://opensourceconnections.com/blog/2006/11/02/roping-in-the-cowboy-coders/', 'author': 'jason-hull', 'content': ' When an IT team needs help with a big project or a new task, they will often look to outsiders for help in delivering their objectives. Oftentimes, they will bring in an elite coder, one with superior skills and knowledge, and look to that coder to be the white knight and save the team. \\n\\n Unfortunately, managers are overawed far too often by the elite coder, and they take a far too hands-off management style, letting that person run roughshod and do whatever he or she wants. What managers forget is that theres a horizon beyond the current project, and when the external help is gone, the remaining IT team needs to maintain and update whatever was left behind. Often, this means that the team is left holding the bag, trying to figure out the code and how to work with it. \\n\\n Just as any company that hires a consultant, just gets a deck, and lets the consultant leave, it is incumbent on the manager to MANAGE the external resources as well. \\n\\n How so? \\n\\n 1) Integrate the external resources with the internal team. For all intents and purposes, for as long as the contract lasts, the contractors are part of the team. Have a kickoff. Do some social events, even if they are on the company clock and the company dime. Managers need everyone to work together.\\n2) Set expectations. Managers should demand well documented, clean code and walkthroughs of the code base so that when the team has to do maintenance, its not the first time anyone has seen the code.\\n3) Get the contractors skin in the game. Put some percentage of the total payment into an escrow to be released a certain time after the code goes live. The contractor should be responsible for bugs, which often dont appear until the release. Demand testing, at least unit testing, and regression testing if possible.\\n4) Pair program. This isnt so that someone is consistently watching over the contractors shoulder, but, rather, so that the internal team can learn from the person who was brought in with special knowledge. There should be knowledge transfer, be it through seminars, brown bag lunches, or observation. \\n\\n This means that a manager looking to bring in external resources needs to do more than look at a resume. Solo riders cure the symptom, but probably dont cure the root cause. This means that the manager needs to do a thorough job in screening; the problems of a bad relationship will last with the team much longer than the relationship will. \\n', 'excerpt': ' When an IT team needs help with a big project or a new task, they will often look to outsiders for help in delivering their objectives. Oftentimes, they will bring in an elite coder, one with superior skills and knowledge, and look to that coder to be the white knight and save the team. Unfortunately, […] \\n', 'post_date': '2006-11-02T00:00:00-0500', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/11/02/roping-in-the-cowboy-coders/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/11/08/rails-and-functional-testing-parameter-pain/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Rails and Functional Testing parameter pain', 'url': 'https://opensourceconnections.com/blog/2006/11/08/rails-and-functional-testing-parameter-pain/', 'author': 'eric-pugh', 'content': ' Ruby on Rails once again lived up to my expectations that it is incredibly powerful, but can als cause real pain! \\n\\n I had a functional test that proved that my action for dropping days from a calender of estimates worked. However, then when running the action through the webapp, it never actually dropped the days! \\n\\n Well, thanks to Jamie Orchard Hays and Chris Hapgood at our local RubyJam, we discovered an “oddity” in how rails works. My action had logic like this: \\n\\n date = params[:date]\\n....\\nif (estimate.date == date)\\n      estimate.destroy\\nend\\n \\n\\n And the estimates were never destoyed! But in my functional test call the estimates were destroyed: \\n\\n dropdate = @sprint.start_date + 2\\n\\nget :drop_day,{:id =&gt; @sprint.id, :date=&gt; dropdate},{:current_user =&gt; @user}\\n \\n\\n So, it turns out that in my functional tests I was passing in dropdate as an actual Ruby Date object, but in the real web action, the date was coming in as a String! Therefore the call: \\n\\n estimate.date == date\\n \\n\\n was never true! I changed my call for getting date to: \\n\\n date = params[:date].to_date\\n \\n\\n and that fixed everything. However, what I think should ALSO have happened was the call to get :drop_day method should have converted everything to String, or whatever else you would expect params[] to return. \\n\\n', 'excerpt': ' Ruby on Rails once again lived up to my expectations that it is incredibly powerful, but can als cause real pain! I had a functional test that proved that my action for dropping days from a calender of estimates worked. However, then when running the action through the webapp, it never actually dropped the days! […] \\n', 'post_date': '2006-11-08T00:00:00-0500', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2006/11/08/rails-and-functional-testing-parameter-pain/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/11/11/better-itunes-song-deduping/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Better iTunes song deduping', 'url': 'https://opensourceconnections.com/blog/2006/11/11/better-itunes-song-deduping/', 'author': 'eric-pugh', 'content': ' **Update 4/24/2011. TidySongs is now Rinse! Same great product, but new vendor with a deeper music database that seems to match better. Ive updated the links. ** \\n\\n \\n   \\n     \\n       *Update 5/16/2010. When I am old and grey, I am going to tell my children about the most popular blog post I ever wrote, this one about iTunes deduping! I finally have to pass the baton of deduping on to \\n     \\n   \\n \\n\\n TidySongs, a product from a company that coincidentally is in my home town of Charlottesville, Virginia!&lt;/p&gt;\\n* * * \\n\\n Im happy to share my hacked version of Doug Adams Corral iTunes Dupes AppleScript. You can grab my version from here. \\n\\n His version uses some wicked fast PERL to find all the duplicate songs based on info in the Library, and then puts them all in a Dupes playlist. However, I wanted to filter by Name, Artist, and Album, and have a single playlist where I could delete in one fell swoop all the duplicates. So I tweaked his AppleScript to have another prompt that asks if you want all dupes to go in the playlist, or just copies 2…X to go in. \\n\\n I run it once with “All” to make sure I have what I want, and then rerun it with “Just Dupes” and build the playlist of files to delete. Works great, and Im mailing him a copy, maybe itll be in the 1.1 version! \\n\\n I was also very happy with the application Seek and Destroy Music Duplicates. It is written in Java using WebStart, and gave some good results as well. It is better in that you can pick which copy of the duplications you want to keep, and color codes each set of duplicates. \\n\\n The tool iDupe really didnt do that much for me, and the demo is limited to just doing 3 deletes. Seek and Destroy is a better choice. \\n', 'excerpt': ' Update 4/24/2011. TidySongs is now Rinse! Same great product, but new vendor with a deeper music database that seems to match better. Ive updated the links. Update 5/16/2010. When I am old and grey, I am going to tell my children about the most popular blog post I ever wrote, this one about iTunes deduping! […] \\n', 'post_date': '2006-11-11T00:00:00-0500', 'categories': ['blog', 'Productivity', 'Software'], 'id': 'https://opensourceconnections.com/blog/2006/11/11/better-itunes-song-deduping/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/11/29/labsapache-now-open/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Labs@Apache now open!', 'url': 'https://opensourceconnections.com/blog/2006/11/29/labsapache-now-open/', 'author': 'eric-pugh', 'content': ' During 2006 the Apache Incubator process has really taken off. Incubator is a place for existing projects to enter the Apache Software Foundation, and build up community around them. Once projects have attracted committers they then graduate. \\n\\n However this has led to many Apache committers (like me!) who have new ideas going off to places like Google Codes Project Hosting and SourceForge, versus going through the paperwork of the Incubator process. \\n\\n So, to provide a low cost place to start a project, Apache Labs was born. It is meant as a place that any ASF committer can start their own projects, but still leverage all the community and infrastructure that Apache has to offer! \\n\\n Hats off to the Apache Labs PMC ! \\n\\n', 'excerpt': ' During 2006 the Apache Incubator process has really taken off. Incubator is a place for existing projects to enter the Apache Software Foundation, and build up community around them. Once projects have attracted committers they then graduate. However this has led to many Apache committers (like me!) who have new ideas going off to places […] \\n', 'post_date': '2006-11-29T00:00:00-0500', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2006/11/29/labsapache-now-open/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/12/03/more-reports-means-less-information/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'More reports means less information', 'url': 'https://opensourceconnections.com/blog/2006/12/03/more-reports-means-less-information/', 'author': 'jason-hull', 'content': ' Just as people spend far too much time in meetings, they also spend far too much time sifting through reports trying to determine what the most important information to running a business is. With the proliferation of database technology and the ease of creating reports to “summarize” that information, decision makers in an enterprise often find themselves unable to get their hands on what they need to drive business forward. This is not because the information is not available, but, rather, it is not available in a useful format. \\n\\n What is necessary to complement the proliferation of information, or, as analysts like to say, “slicing and dicing” information, is a way of filtering that information. More reports exist today with an equivalent amount of utility. Therefore, filtering and sifting through the reports has become todays equivalent to filtering and sifting through the raw data 10-15 years ago. \\n\\n\\n The key to effective management is getting the right reports to the right people at the right time. Often business analysts feel the need to justify their jobs through creating and proliferating reports, most of which either waste leaders time or fill up deleted items folders and trashcans. Test what reports are necessary by eliminating them. See how many people in the organization can no longer make decisions because the reports are no longer there. \\n\\n How can IT help? Catalog and cordon off the reports. Make them accessible from a central location, but create a pull demand system instead of a push supply system. By having a central repository of reports and opt-in subscriptions, an organization can determine what it has and what it needs in a rapid fashion. Furthermore, it can cut down on the clutter in senior managements inboxes and free up time for strategic leadership and management, rather than in the weeds detail orientation. \\n\\n Another benefit of this way of managing reports is that it creates a market economy for reporting. Let the body of the organization determine what is important, much as web 2.0 sites allow for filtering of the best what is available. Find out the most popular reports, the most popular author, or trace down a trail just as you might someones movie or book preferences. \\n\\n Does your company suffer from the curse of a cornucopia of information? Contact us and see how we can help. \\n\\n', 'excerpt': ' Just as people spend far too much time in meetings, they also spend far too much time sifting through reports trying to determine what the most important information to running a business is. With the proliferation of database technology and the ease of creating reports to “summarize” that information, decision makers in an enterprise often […] \\n', 'post_date': '2006-12-03T00:00:00-0500', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2006/12/03/more-reports-means-less-information/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2006/12/13/i-got-a-great-time-slot-for-speakingcodemash/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'I got a great time slot for speaking@CodeMash', 'url': 'https://opensourceconnections.com/blog/2006/12/13/i-got-a-great-time-slot-for-speakingcodemash/', 'author': 'eric-pugh', 'content': ' I just checked the Agenda page for CodeMash and I am on Friday just before lunch! I was worried I would be on Friday after lunch, which is always a tough timeslot as people are thinking about cutting out early because their brains are too full! \\n\\n CodeMash is only $99 and has an incredible list of presenters. Im looking forward to seeing Bruce Eckel talk about why dynamic languages offer so much, and Mary Poppendieck talk about “Lean” software development. Beyond Agile is Lean? \\n\\n', 'excerpt': ' I just checked the Agenda page for CodeMash and I am on Friday just before lunch! I was worried I would be on Friday after lunch, which is always a tough timeslot as people are thinking about cutting out early because their brains are too full! CodeMash is only $99 and has an incredible list […] \\n', 'post_date': '2006-12-13T00:00:00-0500', 'categories': ['blog', 'Conference', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2006/12/13/i-got-a-great-time-slot-for-speakingcodemash/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/about-us/eric-pugh/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric Pugh', 'url': 'https://opensourceconnections.com/about-us/eric-pugh/', 'author': 'eric-pugh', 'content': ' Fascinated by the “craft” of software development, Eric Pugh has been heavily involved in the open source world as a developer, committer, and user for the past 5 years. \\n\\n He is an emeritus member of the Apache Software Foundation and lately has been mulling over how we move from the read/write web to the data web. In biotech, financial services and defense IT, he has helped European and American companies develop coherent strategies for embracing open source software. Eric became involved in Solr when he submitted the patch SOLR-284 for Parsing Rich Document types such as PDF and MS Office formats that became the single most popular patch as measured by votes! He co-authored Enterprise Solr Search. \\n', 'excerpt': ' Fascinated by the “craft” of software development, Eric Pugh has been heavily involved in the open source world as a developer, committer, and user for the past 5 years. \\n\\n He is an emeritus member of the Apache Software Foundation and lately has been mulling over how we move from the read/write web to the data web. In biotech, financial services and defense IT, he has helped European and American companies develop coherent strategies for embracing open source software. Eric became involved in Solr when he submitted the patch SOLR-284 for Parsing Rich Document types such as PDF and MS Office formats that became the single most popular patch as measured by votes! He co-authored Enterprise Solr Search. \\n', 'post_date': '2007-01-02T00:00:00-0500', 'categories': ['about-us'], 'id': 'https://opensourceconnections.com/about-us/eric-pugh/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/about-us/scott-stults/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Scott Stults', 'url': 'https://opensourceconnections.com/about-us/scott-stults/', 'author': 'scott-stults', 'content': ' Scott Stults has led implementation teams on a variety of Department of Defense, UK Ministry of Defense, and commercial projects where implementing search has been constrained by sophisticated security requirements. He has implemented Multi-Level Security (MLS) in a Lucene-based environment and is working with the Solr community to develop best practices for securing Solr. As a co-founder of OpenSource Connections, which has been working with Solr since 2007, Mr. Stults leads the Solr Security Practice for the company.  In 2011 he presented at the Basis Technology Open Source Search Conference on Multi-Level Security with Solr: Searching Documents at Various Classifications.  More recently Mr. Stults was a presenter at Lucene Revolution on Indexing Big Data on Amazon AWS. \\n', 'excerpt': ' Scott Stults has led implementation teams on a variety of Department of Defense, UK Ministry of Defense, and commercial projects where implementing search has been constrained by sophisticated security requirements. He has implemented Multi-Level Security (MLS) in a Lucene-based environment and is working with the Solr community to develop best practices for securing Solr. As a co-founder of OpenSource Connections, which has been working with Solr since 2007, Mr. Stults leads the Solr Security Practice for the company.  In 2011 he presented at the Basis Technology Open Source Search Conference on Multi-Level Security with Solr: Searching Documents at Various Classifications.  More recently Mr. Stults was a presenter at Lucene Revolution on Indexing Big Data on Amazon AWS. \\n', 'post_date': '2007-01-02T00:00:00-0500', 'categories': ['about-us'], 'id': 'https://opensourceconnections.com/about-us/scott-stults/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/01/15/you-never-know-where-people-will-find-you/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'You never know where people will find you', 'url': 'https://opensourceconnections.com/blog/2007/01/15/you-never-know-where-people-will-find-you/', 'author': 'jason-hull', 'content': ' Thanks to Pruppert, word about our iTunes deduplicate script is spreading. He posted on the Mac World Forum and had an excellent write-up on how the script differed from previous scripts. \\n\\n The surprise to us was how quickly Erics new post popped up on other places in the Internet. None of us know Pruppert from a random stranger; yet, he posted about us (and did an excellent job of writing about what it did) and generated a significant amount of traffic. Our websites traffic doubled since the posting, and just under 50% of the traffic has been from that posting. While we dont expect every blog post to hit like that and establish thought leadership, this shows the value of continuing to post blogs. \\n\\n', 'excerpt': ' Thanks to Pruppert, word about our iTunes deduplicate script is spreading. He posted on the Mac World Forum and had an excellent write-up on how the script differed from previous scripts. The surprise to us was how quickly Erics new post popped up on other places in the Internet. None of us know Pruppert from […] \\n', 'post_date': '2007-01-15T00:00:00-0500', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2007/01/15/you-never-know-where-people-will-find-you/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/01/26/migrating-from-simplelog-to-wordpress/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Migrating from Simplelog to WordPress', 'url': 'https://opensourceconnections.com/blog/2007/01/26/migrating-from-simplelog-to-wordpress/', 'author': 'eric-pugh', 'content': ' After 7 months and 34 posts, weve outgrown Simplog. Were just finishing migrating all the content to our new WordPress blog, but Im sure youll see some bumps in the road as we get URLs fix, image references resolved, and all the other malarkey that moving platforms requires. \\n\\n While Simplelog was a great tool, and its simplicity was wonderful, weve gotten to the point where we want to be able to handle things like: \\n\\n \\n   \\n     Aggregating multiple feeds \\n   \\n   \\n     Open access to many users \\n   \\n   \\n     Properly ping Technorati on updates! \\n   \\n   \\n     Be able to post using thick client tools. \\n   \\n \\n\\n If you find something broken, please feel free to drop me a note at epugh@opensourceconnections.com. \\n', 'excerpt': ' After 7 months and 34 posts, weve outgrown Simplog. Were just finishing migrating all the content to our new WordPress blog, but Im sure youll see some bumps in the road as we get URLs fix, image references resolved, and all the other malarkey that moving platforms requires. While Simplelog was a great tool, and […] \\n', 'post_date': '2007-01-26T00:00:00-0500', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/01/26/migrating-from-simplelog-to-wordpress/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/02/05/using-mod_auth_mysql-as-a-single-sign-on-tool/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Using mod_auth_mysql as a single sign-on tool', 'url': 'https://opensourceconnections.com/blog/2007/02/05/using-mod_auth_mysql-as-a-single-sign-on-tool/', 'author': 'scott-stults', 'content': ' I recently migrated our Subversion repositories and trac sites from one server to another. This gave me the chance to reorganize our layout and authentication mechanism. I chose to replace our existing .htaccess files with mod_auth_mysql because it fit two key criteria: \\n\\n \\n   Its easy to administer – Logging into the server and running htpasswd every time I need to add a user or change a password is a PITA \\n   Most of the applications we use offer MySQL authentication functions, so I can grant access to several things at once. \\n \\n\\n The docs on how to set it up were fairly clear, with one exception: I would have liked to have seen an example of how to use multiple tables for group membership. After a little more Googling I ran across such an example, taken from  Integration of Jira User Management with Apache.\\nCommon database normalization techniques suggest that users and passwords go into one table, groups in another, and a third table should be used to join the two by IDs. This is what I was after, and thats what Jiras integration doc showed me. It was also confirmation that I had chosen an appropriate central authentication mechanism. \\n\\n Eric was nice enough to whip up a Rails CRUD utility to manage the tables (which will be posted soon) and from there it was a simple matter to instruct Apache to use those tables whenever it needed authentication. By the way, a great way to do that is with a separate file such as “mysql-auth.inc” and just use the Apache Include directive to include that file wherever you need authentication. \\n\\n', 'excerpt': ' I recently migrated our Subversion repositories and trac sites from one server to another. This gave me the chance to reorganize our layout and authentication mechanism. I chose to replace our existing .htaccess files with mod_auth_mysql because it fit two key criteria: Its easy to administer – Logging into the server and running htpasswd every […] \\n', 'post_date': '2007-02-05T00:00:00-0500', 'categories': ['blog', 'Code', 'System Administration'], 'id': 'https://opensourceconnections.com/blog/2007/02/05/using-mod_auth_mysql-as-a-single-sign-on-tool/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/02/13/how-to-remove-plugins-installed-as-svnexternals/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'How to remove plugins installed as svn:externals', 'url': 'https://opensourceconnections.com/blog/2007/02/13/how-to-remove-plugins-installed-as-svnexternals/', 'author': 'eric-pugh', 'content': ' I love how easy it is to keep up with the latest and greatest of a plugin in Rails: script/plugin install -x https://some.subversion.server/plugin. \\n\\n Unfortunantly, if you then want to remove it, you need to then go and muck around with subversion externals in /vendor/plugins. It took me much hunting around and playing with svn proplist and svn propget to figure it out. It turns out to be as simple as just \\n\\n \\ncd ./vendor/plugins and then svn propedit svn:externals . --editor-cmd vi\\n \\n\\n and removing the line. Then just commit the changes plugins directory! \\n\\n The canonical information on properties is available from the Redbook \\n', 'excerpt': ' I love how easy it is to keep up with the latest and greatest of a plugin in Rails: script/plugin install -x https://some.subversion.server/plugin. Unfortunantly, if you then want to remove it, you need to then go and muck around with subversion externals in /vendor/plugins. It took me much hunting around and playing with svn proplist […] \\n', 'post_date': '2007-02-13T00:00:00-0500', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/02/13/how-to-remove-plugins-installed-as-svnexternals/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/02/16/ajaxscaffold-and-file-uploads/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'AjaxScaffold and File Uploads', 'url': 'https://opensourceconnections.com/blog/2007/02/16/ajaxscaffold-and-file-uploads/', 'author': 'eric-pugh', 'content': \" Weve had a little Expenses Rails app for tracking charges and funneling them back to Accounting. One of the key bits is that we can upload a picture of the receipt to each expense. Its remarkable how good resolution camera phones have these days, and its a lot better then walking around with a pocketful of receipts while on a business trip! \\n\\n So we used the basic Rails scaffolding, but I am a big fan of Richard Whites Ajax Scaffold. And since it is now a Rails Plugin, I wanted to give it a try. I dropped it into the app, and everything worked fine. That is until I tried to upload my image of a receipt. Bam… I started thinking this was a weakness of Ajax Scaffold, but after a bit of digging around it turns out binary data cant be sent via AJAX calls! Ugh… \\n\\n Well, after playing around with various options for a while, i decided that I wasnt going to use something weird like a Flash based uploader or what not. Instead, when adding a new expense, I do a regular post via form_tag that takes you back to the list page, and when editing a receipt, where image changing isnt supported anyway, I use the ajax goodness via form_remote_tag. \\n\\n I can tell which method is being invoked on _new_edit.rhtml partial by doing: &lt; % if params[:action] == 'edit' %&gt; , and use the appropriate form tag. The only issue was that to keep the other Ajax calls working properly, the form_tag id had to use the full :id =&gt; element_form_id(@options) id. The only real downside is that when creating a new expense, if there is an error, you are popped out of the table view, into a page with just the new expense partial, but you can still save your data. \\n\\n At any rate, Ajax Scaffold as plugin has grown more mature then ever. I really appreciate how easy it is to do things like change sorting order, or add your own filters to the data. And the fact that all the raw Ajax Scaffold template stuff stays in /views/ajax_scaffold/, and allows you to override individual .rthtml templates by adding them to your /views/model/ directory is just great. It also become a lot cleaner and easier to understand the internal workings as well. I am very much looking forward to Ajax Scaffold 4.0! \\n\", 'excerpt': ' Weve had a little Expenses Rails app for tracking charges and funneling them back to Accounting. One of the key bits is that we can upload a picture of the receipt to each expense. Its remarkable how good resolution camera phones have these days, and its a lot better then walking around with a pocketful […] \\n', 'post_date': '2007-02-16T00:00:00-0500', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/02/16/ajaxscaffold-and-file-uploads/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/02/23/continous-integration-tools-market-is-splitting/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Continous Integration Tools Market is splitting…', 'url': 'https://opensourceconnections.com/blog/2007/02/23/continous-integration-tools-market-is-splitting/', 'author': 'eric-pugh', 'content': ' In the beginning there was CruiseControl, the original Continous Integration tool. Most people, including myself, cut there teeth on CruiseControl. Then, over time, a couple of opensource projects started spawning commercial tools, like AntHill and AntHillPro, and I thought all the new innovation in CI tooling was going to be by commercial companies. \\n\\n Well, I am glad to see that isnt the case. At the heavy/powerful, and light and simple end of the spectrum there are two new tools to add to the evaluation lists: Hudson and CruiseControl.rb. Neither of them is currently listed on the Continuous Integration Server Feature Matrix page, but they both offer new approaches and features to CI. \\n\\n Hudson is Java based, and provides similar functionality to CruiseControl and Continuum. It is better then CruiseControl in that it allows you to configure new jobs via the web interface, and has a reasonable well thought out plugin architecture. It looks like it has a leg up on Continuum because it seems more polished, and designed to manage larger numbers of projects. \\n\\n The key things that I like about Hudson is that it supports distributed builds, and scheduling builds outside of Hudson, and just reporting results. \\n\\n The distributed builds are based on deploying a “slave agent” to each slave builder. You can specify for your projects if they need to be built on one specific server, or if they can be built on any server. It also tries to move long running builds to the slaves versus the master project. You will have the usual challenges of deploying all the tools to each slave builder however. But if you are building many heterogenous projects, like C code, PHP, Java, Ruby, then you can simplify the setup task by having seperate server for each type of environment. For one client, we have seperate Continuum instance building a single .NET project on Windows, and this would have been a great place to have a slave builder instead. \\n\\n The external builds stuff is really exciting, and an original idea. If you already have a build setup, like maybe doing builds on Linux and Solaris for example, and dont want to throw it away, then you can just tweak Hudson to read in the result of your external build, so you can get the reporting and notification abilities of Hudson! This is a great way to slowly introduce CI into an organization that has preexisting processes without causing a lot of disruption. \\n\\n CruiseControl.rb, while sharing its name with CruiseControl and CruiseControl.NET looks like a completely redone implementation in Ruby. Instead of just being a rewrite of CruiseControl, like CC.NET is, it has been written in a thoroughly “Thinking in Ruby” fashion. Out goes the complex XML config file, in comes a very simple Ruby script for configuration. Still there are two seperate processes, a build agent and a dashboard gui (a simple Rails app), but both are started up together. It definitly passes the 15 Minute rule, as I was able to deploy it and have it running in no time. You can see it online at http://labs.opensourceconnections.com:3333, where I have dropped two projects, Horseshow, a Rails project, and Boozer, a user auth plugin for Rails… \\n\\n This looks like a great choice for projects who are already using Ruby, and dont need/want the complexity/power of a full blown CI tools like Continuum or Hudson. Where is looks like it falls down is if you have tens of projects that you want to manage. Or lots of different SCM systems. You also have to log on to the server and use a command line cruise tool to add projects. And edit a project config ruby file to specify who the recipients are. But, for a small team where sharing out access is fine, or for just a couple projects, it looks like just the ticket. For Ruby projects at least, its the new King of the Hill. \\n', 'excerpt': ' In the beginning there was CruiseControl, the original Continous Integration tool. Most people, including myself, cut there teeth on CruiseControl. Then, over time, a couple of opensource projects started spawning commercial tools, like AntHill and AntHillPro, and I thought all the new innovation in CI tooling was going to be by commercial companies. Well, I […] \\n', 'post_date': '2007-02-23T00:00:00-0500', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/02/23/continous-integration-tools-market-is-splitting/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/02/28/citconf-the-continuous-integration-testing-conference-is-coming/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'CitConf: The Continuous Integration Testing Conference is coming!', 'url': 'https://opensourceconnections.com/blog/2007/02/28/citconf-the-continuous-integration-testing-conference-is-coming/', 'author': 'eric-pugh', 'content': ' CitConf is a focused conference on Continuous Integration Testing, and takes place three time a year around the globe. This years North American location will be Fort Worth, Texas, on April 27th and 28th. \\n\\n CitConf uses the OpenSpaces format which was pioneered by Bruce Eckels as a way to lower the management overhead of typical conferences. At CodeMash I joined Bruce and some others in a OpenSpace format session, and as long as the group is small, and interested it works quite well. Since CitConf is capped at 100 people, it seems like an entire OpenSpaces format conference would work. \\n\\n At any rate, the conference is FREE, as most of the costs are either borne by sponsors or eliminated via the OpenSpaces format. \\n', 'excerpt': ' CitConf is a focused conference on Continuous Integration Testing, and takes place three time a year around the globe. This years North American location will be Fort Worth, Texas, on April 27th and 28th. CitConf uses the OpenSpaces format which was pioneered by Bruce Eckels as a way to lower the management overhead of typical […] \\n', 'post_date': '2007-02-28T00:00:00-0500', 'categories': ['blog', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2007/02/28/citconf-the-continuous-integration-testing-conference-is-coming/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/01/using-sqlite3-capistrano-mongrel-cluster-oh-my/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Using SQLite3 &#038; Capistrano &#038; Mongrel Cluster oh my!', 'url': 'https://opensourceconnections.com/blog/2007/03/01/using-sqlite3-capistrano-mongrel-cluster-oh-my/', 'author': 'eric-pugh', 'content': \" The biggest slam against using file based databases like SQLite is that they are actual files embedded in your application, and that you have to go through extra hoops when upgrading your application. For example, if you have your production prod.sqlite3 file in ./db, then every time you update your application using Capistrano youll replace your production database with a fresh one! \\n\\n Well, my first attempt to work around this involved excluding the ./db directory from checkout and then creating a db directory in /shared/db. Symlinking from /shared/db to ./db worked, but was clumsy, and required extra code in my deployment recipe. \\n\\n A light bulb finally dawned that the path in databases.yml for my production database could be something like: \\n\\n \\nproduction:\\nadapter: sqlite3\\ndatabase: ../../shared/db/prod.sqlite3\\n \\n\\n Just go up two directories and over to the shared/db directory and locate the database file there! I tried it out, and it worked great. I ran cap deploy_with_migrations and soon enough had a shared sqlite3 database. I then fired up the app with cap cold_deploy and everything ground to a halt :( . I was getting an error about “database cant be opened. Eventually, after pulling my hair out I discovered that while starting mongrel with ./server/script works great with relative paths to the database, starting with mongrel_rails requires a complete path: \\n\\n \\nproduction:\\nadapter: sqlite3\\ndatabase: /opt/apps/horseshow/shared/db/prod.sqlite3\\n \\n\\n Victory at last! \\n\\n To automate the generation of the shared/db directory, just add to your deploy.rb recipe: \\n\\n \\ndesc 'A setup task to put shared system, log, and database directories in place';\\ntask :setup, :roles =&gt; [:app, :db, :web] do\\nrun &lt;&lt;-CMD\\nmkdir -p -m 775 #{release_path} #{shared_path}/system #{shared_path}/db &amp;&amp;\\nmkdir -p -m 777 #{shared_path}/log\\nCMD\\nend\\n \\n\", 'excerpt': ' The biggest slam against using file based databases like SQLite is that they are actual files embedded in your application, and that you have to go through extra hoops when upgrading your application. For example, if you have your production prod.sqlite3 file in ./db, then every time you update your application using Capistrano youll replace […] \\n', 'post_date': '2007-03-01T00:00:00-0500', 'categories': ['blog', 'Code', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/03/01/using-sqlite3-capistrano-mongrel-cluster-oh-my/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/05/a-simple-example-of-tomcat-realms-and-security/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'A simple example of Tomcat Realms and Security', 'url': 'https://opensourceconnections.com/blog/2007/03/05/a-simple-example-of-tomcat-realms-and-security/', 'author': 'eric-pugh', 'content': ' Last week a colleague of mine called me up because he was struggling with setting up Tomcat JDBCRealm for use with a relatively simple straightforward webapp. Wed recently released the 1.0 version of GateKeeper, and he wanted to use it to manage his users and roles. The GateKeeper side of things went just fine, but the JDBCRealm setup on his webapp was proving very balky. \\n\\n He fired up VNC, and I logged in and checked out his settings. And there was nothing wrong! At least, nothing that looked odd in any way. We then googled for some help, maybe a simple sample setup, but to no avail! Oddly enough, nowhere on the internet is a good example of using a Tomcat Realm to protect a webapp. There are various examples, but they just show a part of the puzzle, maybe just the &lt;security -constaint/&gt; section in the web.xml, or a Realm definition: &lt;realm className=\"org.apache.catalina.realm.MemoryRealm\" /&gt;. Reading the servlet spec for web.xml helps, but doesnt give you details on the Tomcat specific details. \\n\\n So, over the weekend I set out to create a simple example, and I planned on using the jsp-examples app the ships with Tomcat. After poking around jsp-examples I discovered what I had been looking for all along! There is a full example of protecting a webapp using a Realm! The example for some odd reason is NOT linked from the home page of jsp-examples, but it is there. http://localhost:8080/security/protected and log in as user role1, with the password tomcat. \\n\\n Ill walk you really quickly through the relevant portions of the configuration files. First off you define what URLs you want protected by which roles in your web-apps web.xml file: \\n\\n ```\\n&lt;security -constraint&gt;\\n&lt;display -name&gt;Example Security Constraint&lt;/display&gt;\\n&lt;web -resource-collection&gt;\\n&lt;/web&gt;&lt;web -resource-name&gt;Protected Area&lt;/web&gt;\\n \\n\\n &lt;url -pattern&gt;/security/protected/*&lt;/url&gt;\\n \\n\\n &lt;http -method&gt;DELETE&lt;/http&gt;\\n&lt;http -method&gt;GET&lt;/http&gt;\\n&lt;http -method&gt;POST&lt;/http&gt;\\n&lt;http -method&gt;PUT&lt;/http&gt; \\n\\n &lt;auth -constraint&gt;\\n \\n\\n &lt;role -name&gt;tomcat&lt;/role&gt;\\n&lt;role -name&gt;role1&lt;/role&gt;\\n&lt;/auth&gt;\\n&lt;/security&gt; \\n\\n\\n\\n &lt;login -config&gt;\\n&lt;auth -method&gt;FORM&lt;/auth&gt;\\n&lt;realm -name&gt;Example Form-Based Authentication Area&lt;/realm&gt; \\n\\n &lt;/login&gt; \\n\\n\\n\\n &lt;security -role&gt;\\n&lt;role -name&gt;role1&lt;/role&gt;\\n&lt;/security&gt;\\n&lt;security -role&gt;\\n&lt;role -name&gt;tomcat&lt;/role&gt;\\n&lt;/security&gt;\\n``` \\n\\n The first &lt;security -constraint/&gt; stanza specifies the URLs of the pages that we want to protect, as well as what roles are required to allow access. Anything in the /security/protected/* pattern will require the user has either the role role1 or tomcat. \\n\\n The next stanza, &lt;login -config/&gt; specifies how you gain access to the protected URLs. In this example, we are using FORM based security, so we specify the URLs for the login/logout pages. If you are using BASIC authentication then your stanza is much simpler: \\n\\n \\n&lt;login -config&gt;\\n&lt;auth -method&gt;BASIC&lt;/auth&gt;\\n&lt;realm -name&gt;Example BASIC Authentication Area&lt;/realm&gt;\\n&lt;/login&gt;\\n \\n\\n The remaining stanzas, &lt;security -role/&gt; are the roles that are used in this webapp, and they are elements that are often forgotten in a web.xml. \\n\\n Now that we have defined that only users who have roles role1 or tomcat can access the application, we then need to configure Tomcat. This is done through server.xml, and can be a bit of a rat hole to figure everything out. So, extracted from server.xml we have the following XML stanzas. Ive removed most of the commenting so you can see the overall structure of the document: \\n\\n ``` \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n ``` \\n\\n Now, instead of going from top to bottom, well start from the definition for the specific host, and work our way out. The challenge that my colleague and I had was that we thought we needed to somehow map a &lt;security -constraint/&gt; in the web.xml to some sort of definition in server.xml. We were mucking around with all sorts of &lt;realm /&gt; stanzas embedded in &lt;host /&gt; stanzas and trying to match &lt;realm -name/&gt; in the web.xml to the &lt;realm name=XX/&gt; element in server.xml. What we didnt realize until I found the jsp-examples sample security code is that because the realm is defined inside of the &lt;engine /&gt; stanza, it applies to all hosts! And that there is NO explicit mapping between webapps and realms at a level more detailed then at an Engine level. All webapps defined in all hosts that share the same engine share the same realm! So the complete stanza looks like: \\n\\n ``` \\n\\n\\n\\n\\n\\n ``` \\n\\n Now, I dont know what you would do if you wanted to use different Realms for each webapp, maybe define multiple Engines I guess. Our UserDatabaseRealm is not fully defined here, instead it refers to a global resource called UserDatabase. That is defined outside in our &lt;globalnamingresources /&gt; stanza: \\n\\n ``` \\n\\n\\n\\n\\n\\n\\n\\n\\n ``` \\n\\n Weve defined a resource call UserDatabase that reads in data in the conf/tomcat-users.xml file and exposes it as a user database. \\n\\n Hopefully this will walk you through all the setup steps required for adding a Realm to your webapp. For me, the key insight was that the realm definition inside of the engine definition applies to all the web-apps in all the hosts. I am working on cutting our 1.0.1 version of Gatekeeper which will demo using a JDBCRealm. I will post a follow up on that. \\n', 'excerpt': ' Last week a colleague of mine called me up because he was struggling with setting up Tomcat JDBCRealm for use with a relatively simple straightforward webapp. Wed recently released the 1.0 version of GateKeeper, and he wanted to use it to manage his users and roles. The GateKeeper side of things went just fine, but […] \\n', 'post_date': '2007-03-05T00:00:00-0500', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/03/05/a-simple-example-of-tomcat-realms-and-security/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/06/adding-tls-support-to-tracs-wikinotifyscript/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Adding TLS Support to Tracs WikiNotifyScript', 'url': 'https://opensourceconnections.com/blog/2007/03/06/adding-tls-support-to-tracs-wikinotifyscript/', 'author': 'scott-stults', 'content': ' Weve been using the WikiNotifyScript from trac-hacks.org for quite a while now. It helps us stay appraised of changes to all of our various wikis and its pretty easy to set up. However, when I had the brilliant idea of switching it to use Gmail as the SMTP server I ran into a snag: Gmail only supports logins through TLS. Recent Trac releases support TLS through smtplib, but unfortunately WikiNotifyScript doesnt share that code. \\n\\n After a quick grep through the trac source I found the magic incantation nestled inside notification.py. It was a pretty simple matter to port what trac does over to WikiNotifyScript, so after a brief round of testing I posted the patch over on WikiNotifyScripts trac. Hopefully thatll save somebody some trouble. \\n\\n', 'excerpt': ' Weve been using the WikiNotifyScript from trac-hacks.org for quite a while now. It helps us stay appraised of changes to all of our various wikis and its pretty easy to set up. However, when I had the brilliant idea of switching it to use Gmail as the SMTP server I ran into a snag: Gmail […] \\n', 'post_date': '2007-03-06T00:00:00-0500', 'categories': ['blog', 'Code', 'System Administration'], 'id': 'https://opensourceconnections.com/blog/2007/03/06/adding-tls-support-to-tracs-wikinotifyscript/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/06/re-system-logs-as-reproducible-scripts/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'RE: System logs as reproducible scripts', 'url': 'https://opensourceconnections.com/blog/2007/03/06/re-system-logs-as-reproducible-scripts/', 'author': 'eric-pugh', 'content': ' Duane Gran recently pinged me about thoughts on “System logs as reproducible scripts”. Its a topic that Ive been running into recently as weve gone into testing a web based application, and dealing with some of our users very difficult to reproduce bug reports. \\n\\n The challenge with a log that can be “played back” is that often the system will prevent the same set of events from happening again. For example, if you record a series of events that includes creating a user, then when you play them back the user creation step will fail with a “user already exists” type of error. \\n\\n However, this isnt to say that this isnt a good idea. With in narrow scopes, this has been done. For example, there are tools that intercept your SQL transactions and record them for use in rebuilding indexes and debugging after the fact issues. Ive also seen a tool that attempted to record all your SQL statements, and then replay them in reverse to restore your database to a known state! \\n\\n Right now the tools available dont help us follow the path of execution through a web app for a specific user very well. We can see part of the picture, via grepping through a webserver log for a session id, but its difficult to tie that into a log of SQL statements issued for that session. And there arent any good simple tools for connecting data collected from Google Analytics, and matching it up to other data sources like server logs or SQL transaction logs. \\n\\n On the server side, there are tools like DTrace that provide a developer with indepth visibility into what is happening to an application. DTrace was used by some of the PostgresSQL developers at OSCON 2006 to find many bottlenecks in the performance of PostgresSQL for example. Now we need to bubble up one more level up and be able to view the actions performed by a specific user that may cause activity on multiple tiers and systems! \\n\\n I used to work with Canoo WebTest, a tool for functional testing of websites. And one thing it did that was wonderful was to record on the local filesystem a copy of every HTML page that it recieved back from the server. This meant that you could go back and “see” what your Canoo Functional Test “saw” at each step. Selenium is my current favorite for Functional testing. But it doesnt record each page as it runs through them, so you have to figure out what tests failed by just the error message that was created when running a suite of tests. \\n\\n Maybe what we need, at least from a web application perspective, is the ability to save each page displayed to the user? I can envision the webserver sending a copy of each page back to the user, but also saving a copy locally, and aggregating them based on session id, and naming (and thus ordering) them based on time? Ajax calls of course might be just the raw XML that was sent back to the client between full HTML page loads. While this might put inordinate load on a large public website, it might be just the ticket for when you are doing development/testing of a website. A bug report with a timestamp and session id could be tied back to the sequence of webpages, and the developer could visually see each step that was taken to generate the error. \\n\\n Ideally the list of pages could be tied together in some sort of slideshow that the developer could play back to see what the user did. While this approach isnt the generic “System logs as reproducible scripts” that Duane was looking for, it is a step in the right direction! \\n', 'excerpt': ' Duane Gran recently pinged me about thoughts on “System logs as reproducible scripts”. Its a topic that Ive been running into recently as weve gone into testing a web based application, and dealing with some of our users very difficult to reproduce bug reports. The challenge with a log that can be “played back” is […] \\n', 'post_date': '2007-03-06T00:00:00-0500', 'categories': ['blog', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/03/06/re-system-logs-as-reproducible-scripts/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/09/congratulations/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Congratulations!', 'url': 'https://opensourceconnections.com/blog/2007/03/09/congratulations/', 'author': 'jason-hull', 'content': ' Congratulations to OSC principal Scott Stults and his wife on the birth of their first baby, a healthy and as of yet unnamed son. \\n\\n Naturally, Scott cannot allow something like this to pass without introducing technology, so he has a webcam set up in the hospital room. \\n\\n Our hopes are that the baby takes after his mother… \\n', 'excerpt': ' Congratulations to OSC principal Scott Stults and his wife on the birth of their first baby, a healthy and as of yet unnamed son. Naturally, Scott cannot allow something like this to pass without introducing technology, so he has a webcam set up in the hospital room. Our hopes are that the baby takes after […] \\n', 'post_date': '2007-03-09T00:00:00-0500', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2007/03/09/congratulations/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/13/a-nice-surprise-courtesy-of-continuum-easy-updating-of-repository-information/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'A nice surprise courtesy of Continuum: Easy updating of repository information', 'url': 'https://opensourceconnections.com/blog/2007/03/13/a-nice-surprise-courtesy-of-continuum-easy-updating-of-repository-information/', 'author': 'eric-pugh', 'content': ' I discovered an unexpected feature that Continuum has. At one client site we are building around 30 different projects from CVS. Over the weekend the DNS name of the CVS server was changed as part of a corporate renaming process. I expected to have to go and update each projects collection of CVS\\\\Root files for the new repository, as well as update the CVS checkout information in Continuum. \\n\\n I started by updating one project in Continuum, and then when I went onto the filesystem I couldnt find the previously checked out project! My first thought was “Oh nooooo, everything has blown up”. It turned out that Continuum was smart enough to pick up the changed SCM information, and to remove the currently checked out code and replace it with the new code! \\n\\n This is one of those features that I wouldnt have expected Continuum, especially at the 1.0.3 versions level of maturity, to support, and saved us a couple hours of linux work. \\n', 'excerpt': ' I discovered an unexpected feature that Continuum has. At one client site we are building around 30 different projects from CVS. Over the weekend the DNS name of the CVS server was changed as part of a corporate renaming process. I expected to have to go and update each projects collection of CVS\\\\Root files for […] \\n', 'post_date': '2007-03-13T00:00:00-0400', 'categories': ['blog', 'Code', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/03/13/a-nice-surprise-courtesy-of-continuum-easy-updating-of-repository-information/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/21/comparing-datetime-and-date/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Comparing DateTime and Date', 'url': 'https://opensourceconnections.com/blog/2007/03/21/comparing-datetime-and-date/', 'author': 'eric-pugh', 'content': ' For my project Novo, Ive been working on a script to sync my Apple iCal to Googles gCal. Think of it as a poor mans version of SpanningSync. \\n\\n One of our challenges is that sometimes we are dealing with Ruby DateTime objects, and other times we are dealing with Date objects. And of course, you cant compare the two to each other (argh!). \\n\\n So initially I would convert them to strings, and then create Time objects and then compare them. And if they were in UTC format, I had a hardcoded value that swapped in my offset from UTC. Of course, with the early arrival (ending???) of Daylight Savings Time change in the US, this caused one week all my appointments to be synced into gCal one hour off! \\n\\n So I took advantage of chatting with Chris Hapgood about his challenges with dates and timezones and implemented TZInfo. \\n\\n But, much to my disgust, when I hand in a DateTime to TZInfo, I get back a proper UTC formatted DateTime. And when I hand in a Time to TZInfo, I get back a proper UTC formatted Time object! So, I am still stuck converting to String, and then reparsing into Time for comparisions. \\n\\n Ive looked around, and the only thing Ive found was from a site that has Ruby Cookbook tips, but it just seems like I should be able to more simply parse/compare the two! Especially since I dont know if I am dealing with DateTimes or Times, and so have to put in some funky logic to figure it out and do the right parsing…. \\n', 'excerpt': ' For my project Novo, Ive been working on a script to sync my Apple iCal to Googles gCal. Think of it as a poor mans version of SpanningSync. One of our challenges is that sometimes we are dealing with Ruby DateTime objects, and other times we are dealing with Date objects. And of course, you […] \\n', 'post_date': '2007-03-21T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/03/21/comparing-datetime-and-date/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/27/is-your-employees-time-your-time/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Is your employees’ time your time?', 'url': 'https://opensourceconnections.com/blog/2007/03/27/is-your-employees-time-your-time/', 'author': 'jason-hull', 'content': ' A recent survey by Clearswift and Yougov shows that 59% of all employees aged 18-29 believe that they should be able to use Web 2.0 social networking sites for their personal use during work time and using corporate computers. \\n\\n This is certainly a shifting tide from the corporate culture of a bygone past when your time was the companys time, and you spent all day doing company work. But is this a bad thing? \\n\\n There are benefits to allowing employees to use the web for personal business during work hours. To expect almost any employee to work for eight hours straight (or even four hours straight, then an hour for lunch, and then four hours straight) is, almost without exception, unrealistic. The average persons attention span is somewhere between 50 and 55 minutes, and beyond that, concentration and results decline. They will need to take a break somehow. Many of them will use the time wisely and take care of other business which then eliminates a potential worry and allows them to focus on the task at hand. \\n\\n\\n\\n There are also risks to allowing them to use the web for personal use. One is the possibility of using social networking sites to air corporate dirty laundry. After all, if something has happened which the employee disagrees with, then its a simple matter to anonymously log into a social networking site and begin griping. Thats life. Theyre going to gripe sometimes, and to hide from the negative side of management is disregarding a duty. \\n\\n Where the line must exist is in giving away company secrets. However, that needs to be handled up front with non-disclosure agreements and employment agreements. Establish the rules and the punishments for failing to abide by the rules up front. Trying to stifle a leak later is a calamitous exercise. \\n\\n Companies that fail to embrace web 2.0s social networking powers are missing out on a great opportunity, particularly if they fail to do so out of fear of the airing of problems. Let others see a true picture of the company, and if it is one that does good work and takes care of its people, then an internal uprising of good words will quell the occasional disgruntled posting. Trying to overly monitor activity and stifle what is being said about a company is an Orwellian road to failure. Instead, focus on creating a good environment where people get to do the work that they enjoy and want to say positive things about the company. \\n\\n', 'excerpt': ' A recent survey by Clearswift and Yougov shows that 59% of all employees aged 18-29 believe that they should be able to use Web 2.0 social networking sites for their personal use during work time and using corporate computers. This is certainly a shifting tide from the corporate culture of a bygone past when your […] \\n', 'post_date': '2007-03-27T00:00:00-0400', 'categories': ['blog', 'Opinion', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/03/27/is-your-employees-time-your-time/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/03/30/business-process-management-and-workflow/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Business Process Management and Workflow', 'url': 'https://opensourceconnections.com/blog/2007/03/30/business-process-management-and-workflow/', 'author': 'scott-stults', 'content': ' Business Process Management (BPM) is increasingly appearing in technical articles and executive seminars, but most of the developers I talk to misinterpret BPM to be MBA jargon for workflow management (WFM). Thats not surprising since workflows handle tasks in a single application, and for the majority of organizations that is sufficient. However, BPM is a much larger concept and addresses things like enterprise orchestration rather than document approval states. Here is an excellent article describing the differences in more detail. \\n\\n', 'excerpt': ' Business Process Management (BPM) is increasingly appearing in technical articles and executive seminars, but most of the developers I talk to misinterpret BPM to be MBA jargon for workflow management (WFM). Thats not surprising since workflows handle tasks in a single application, and for the majority of organizations that is sufficient. However, BPM is a […] \\n', 'post_date': '2007-03-30T00:00:00-0400', 'categories': ['blog', 'Business'], 'id': 'https://opensourceconnections.com/blog/2007/03/30/business-process-management-and-workflow/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/03/erics-ruby-gems/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric’s Ruby Gems', 'url': 'https://opensourceconnections.com/blog/2007/04/03/erics-ruby-gems/', 'author': 'eric-pugh', 'content': \" Following Mike Clark’s idea. Im curious to see what gems Ive got installed in 6 months! \\n\\n \\nxativa:~ eric$ gem list|grep '^[a-zA-Z]'\\nactionmailer (1.3.2, 1.3.1, 1.2.5, 1.2.4, 1.2.3, 1.2.1, 1.1.3, 1.0.1)\\nactionpack (1.13.2, 1.13.1, 1.12.5, 1.12.4, 1.12.3, 1.12.1, 1.11.0, 1.9.1)\\nactionwebservice (1.2.2, 1.2.1, 1.1.6, 1.1.5, 1.1.4, 1.1.2, 1.1.1, 0.9.3, 0.8.1)\\nactiverecord (1.15.2, 1.15.1, 1.14.4, 1.14.3, 1.14.2, 1.14.1, 1.13.0, 1.11.1)\\nactivesupport (1.4.1, 1.4.0, 1.3.1, 1.2.3, 1.1.1)\\najax_scaffold_generator (3.1.5, 2.1.0)\\natom (0.3)\\nbuilder (2.0.0)\\ncalendar_grid (1.0.2)\\ncamping (1.5)\\ncapistrano (1.4.0, 1.3.1, 1.2.0, 1.1.0)\\ncgi_multipart_eof_fix (2.0.2)\\ncheat (1.0.2)\\nchronic (0.1.4)\\ncolor-tools (1.3.0)\\ndaemons (1.0.4, 0.4.4)\\ndev-utils (1.0.1)\\nextensions (0.6.0)\\nezcrypto (0.7)\\nfastercsv (1.1.0, 0.2.1)\\nfastthread (0.6.3)\\nflex_egenial_scaffold (0.0.1)\\ngcalapi (0.1.0, 0.0.3)\\ngem_plugin (0.2.2, 0.2.1)\\ngooglecalendar (0.0.2)\\nhoe (1.1.7)\\nhpricot (0.4.43)\\nicalendar (0.98)\\nlibxml-ruby (0.3.8.4)\\nmailfactory (1.2.3, 1.2.2)\\nmarkaby (0.5)\\nmechanize (0.5.4)\\nmetaid (1.0)\\nmime-types (1.15)\\nmoney (1.7.1)\\nmongrel (1.0.1, 0.3.13.3)\\nmongrel_cluster (1.0.1.1, 0.2.1)\\nneedle (1.3.0)\\nnet-sftp (1.1.0)\\nnet-ssh (1.0.10, 1.0.9)\\npaginator (1.0.8)\\npayment (1.0.1)\\npdf-writer (1.1.3, 1.1.1)\\nrails (1.2.2, 1.2.1, 1.1.6, 1.1.5, 1.1.4, 1.1.2, 1.1.1, 0.14.3, 0.13.1)\\nrake (0.7.1, 0.6.2)\\nrb-appscript (0.3.0)\\nRedCloth (3.0.4)\\nruby-web (1.1.1)\\nrubyforge (0.4.0)\\nrubygems-update (0.9.2, 0.9.0)\\nrubyosa (0.1.0)\\nrubyzip (0.9.1)\\nruport (0.8.10, 0.8.1, 0.7.2, 0.7.1, 0.7.0, 0.6.1, 0.4.23, 0.4.19, 0.4.13)\\nscruffy (0.2.2)\\nSelenium (1.0.1)\\nsentry (0.3.1)\\nshipping (1.5.0, 1.3.0)\\nsources (0.0.1)\\nsqlite-ruby (2.2.2)\\nsqlite3-ruby (1.2.1, 1.1.0)\\nstreamlined_generator (0.0.3, 0.0.2)\\ntattle (1.0.1)\\ntransaction-simple (1.3.0)\\ntzinfo (0.3.3)\\nunicode (0.1)\\nvpim (0.360)\\nwebrick-webdav (1.0)\\n \\n\", 'excerpt': '\\n  \\n    \\n      Following Mike Clark’s idea. Im curious to see what gems Ive got installed in 6 months! xativa:~ eric$ gem list\\n      grep ‘^[a-zA-Z]’ actionmailer (1.3.2, 1.3.1, 1.2.5, 1.2.4, 1.2.3, 1.2.1, 1.1.3, 1.0.1) actionpack (1.13.2, 1.13.1, 1.12.5, 1.12.4, 1.12.3, 1.12.1, 1.11.0, 1.9.1) actionwebservice (1.2.2, 1.2.1, 1.1.6, 1.1.5, 1.1.4, 1.1.2, 1.1.1, 0.9.3, 0.8.1) activerecord (1.15.2, 1.15.1, 1.14.4, 1.14.3, 1.14.2, […]\\n    \\n  \\n\\n', 'post_date': '2007-04-03T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/04/03/erics-ruby-gems/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/04/does-the-virtual-world-equal-the-real-world/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Does the virtual world equal the real world?', 'url': 'https://opensourceconnections.com/blog/2007/04/04/does-the-virtual-world-equal-the-real-world/', 'author': 'jason-hull', 'content': ' This is the question that the FBI is asking of Second Life as they investigate Second Lifes casinos. The three biggest casinos, according to the CNN article, make $1,500/month each. Seems like a small thing for the FBI to be investigating given the other crimes in the country, but is this actually an effort to start to establish some sort of case precedent for potential legal scraps in the future? \\n\\n Given that more and more businesses are moving into Second Life, without a way to establish and enforce contracts, the denizens of Second Life who enter into transactions must certainly heed the warning caveat emptor. As it currently stands, people who do things in Second Life are only buying, effectively, the right to certain bits and pieces of the Linden Labs server farm. With nothing but the loosest of guidelines to provide cover, Second Life can sometimes bring back the reminiscent feel of the Internet in the early 90s. \\n\\n Enter the FBI. While the real world crackdown on online gambling by the U.S. Justice Department certainly has the Feds busy, true established case law is very sparse on the subject. I spoke with a former counsel with Party Poker while we were exhibiting at the OReilly Open Source Convention (OSCON) last year, and she told me that because of the lack of established statutes and case law, the courts could come down either way on online gambling activities. Perhaps the Justice Department is looking to get a ruling on a similar set of circumstances in Second Life to help bolster the Internet gambling ban. \\n\\n', 'excerpt': ' This is the question that the FBI is asking of Second Life as they investigate Second Lifes casinos. The three biggest casinos, according to the CNN article, make $1,500/month each. Seems like a small thing for the FBI to be investigating given the other crimes in the country, but is this actually an effort to […] \\n', 'post_date': '2007-04-04T00:00:00-0400', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/04/04/does-the-virtual-world-equal-the-real-world/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/09/figuring-out-the-local-timezone-in-ruby-on-osx/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Figuring out the local timezone in Ruby on OSX', 'url': 'https://opensourceconnections.com/blog/2007/04/09/figuring-out-the-local-timezone-in-ruby-on-osx/', 'author': 'eric-pugh', 'content': ' I am starting to hit some of the odd corners of Ruby. For example, I want to know what the local timezone of my Mac is. I can run Time.now and parse the output, but unfortunately I get back EDT, and the TZinfo library cant parse that because its not a standard timezone, throwing an TZInfo::InvalidTimezoneIdentifier. \\n\\n I did discover however that on OSX the file /etc/localtime is sym-linked to the correct timezone file! When I did ls -l /etc/localtime I got back /usr/share/zoneinfo/US/Eastern, which gives me something to parse that TZInfo will understand. \\n\\n Below is my unit test that demonstrates my progress in hacking to a solution! Hopefully this will help anyone else. \\n\\n My solution is very brittle, but should work for now. Anyone have a better suggestion, please speak up!!! \\n\\n ```ruby\\ndef test_getting_local_timezone\\nt = Time.now\\nassert_equal EDT, t.strftime(%Z) \\n\\n assert_raise(TZInfo::InvalidTimezoneIdentifier) { Timezone.get(`EDT)} \\n\\n result = %x[ls -l /etc/localtime]\\nputs result \\n\\n assert_match ‘/etc/localtime -&gt; /usr/share/zoneinfo/US/Eastern’, result, ‘Make sure we get back US/Eastern. This only works when you are in US/Eastern Timezone!’ \\n\\n string = ‘lrwxr-xr-x 1 root wheel 30 Jan 17 20:38 /etc/localtime -&gt; /usr/share/zoneinfo/US/Eastern’\\nsplit = string.split(‘/’)\\nassert_equal 8, split.size\\ntimezone = ‘#{split[split.size-2]}/#{split.last}’\\nassert_equal ‘US/Eastern’, timezone \\n\\n end\\n``` \\n', 'excerpt': ' I am starting to hit some of the odd corners of Ruby. For example, I want to know what the local timezone of my Mac is. I can run Time.now and parse the output, but unfortunately I get back EDT, and the TZinfo library cant parse that because its not a standard timezone, throwing an […] \\n', 'post_date': '2007-04-09T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/04/09/figuring-out-the-local-timezone-in-ruby-on-osx/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/11/google-calendar-api-accepts-bad-data/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Google Calendar API accepts bad data!', 'url': 'https://opensourceconnections.com/blog/2007/04/11/google-calendar-api-accepts-bad-data/', 'author': 'eric-pugh', 'content': ' If youve been reading my posts lately, youve noticed lots of posts about parsing working with Time and Dates in Ruby. This has been because my hobby project has been to write a Ruby tool for synchronizing my Apple iCal calendar to my Google Calendar. \\n\\n This project is published on RubyForge as Novo, and is finally nearing a 0.1 release. \\n\\n As Ive been working on flushing out a lot of the bugs, Ive learned quite a bit about the GData API. And one of the things Ive noticed is that you can create bad data in their system via the REST API pretty easily. My code had a bug where it wasnt converting Times properly when inserting events into gCal, so I managed to put the same event in twice, once without start and end times, and once with! Unfortunately I cant delete the bad entry through the Google Calendar interface. It shows up in searches, but not in the listing: \\n\\n  \\n\\n Because of a couple of bad calendar entries that I created during development, Ive add an ignore option so that the bad entries can be permanently ignored. \\n\\n As I get closer to the Novo 0.1 release Ill post more about the tool \\n', 'excerpt': ' If youve been reading my posts lately, youve noticed lots of posts about parsing working with Time and Dates in Ruby. This has been because my hobby project has been to write a Ruby tool for synchronizing my Apple iCal calendar to my Google Calendar. This project is published on RubyForge as Novo, and is […] \\n', 'post_date': '2007-04-11T00:00:00-0400', 'categories': ['blog', 'Code', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/04/11/google-calendar-api-accepts-bad-data/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/12/producing-html-output-from-nunit/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Producing HTML output from NUnit?', 'url': 'https://opensourceconnections.com/blog/2007/04/12/producing-html-output-from-nunit/', 'author': 'eric-pugh', 'content': ' As part of our build process we run NUnit and NCover over some C# code. We are currently focusing on getting our code coverage up from the measly ~18% that the project is at. \\n\\n One of the developers asked me to make it easier to find out which test failed versus parsing through 100s of lines of raw build output. We already have NCover producing nice HTML reports of the code coverage metrics, so I figured I could do the same with the NUnit XML file as well. \\n\\n Much to my dismay, it appears that you are expected to use the NUnit GUI application to parse the failure results! The only existing conversions to HTML that I could find was this blog posting on Automating NUnit and MSTest Builds. I tried out the conversion from XML to text output, and that was better, but very ugly. \\n\\n Daniel Irvine commenting on the new NUnit 2.4 release also mentions that the XSLT transformation of the raw data is something hes looking for as well! \\n\\n If anyone has any suggestions, please let me know. I hope I havent talked myself into creating the XSLT transformation tool for NUnit!! \\n', 'excerpt': ' As part of our build process we run NUnit and NCover over some C# code. We are currently focusing on getting our code coverage up from the measly ~18% that the project is at. One of the developers asked me to make it easier to find out which test failed versus parsing through 100s of […] \\n', 'post_date': '2007-04-12T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/04/12/producing-html-output-from-nunit/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/16/upgrading-to-subversion-14-on-a-fedora-core-4-server/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Upgrading to Subversion 1.4 on a Fedora Core 4 Server', 'url': 'https://opensourceconnections.com/blog/2007/04/16/upgrading-to-subversion-14-on-a-fedora-core-4-server/', 'author': 'scott-stults', 'content': ' Yesterday Eric asked me to upgrade our Subversion version from 1.2 to 1.4 in order to take advantage of the new XML responses needed by CruiseControl.rb. My first clue that this wasnt going to be easy was that the stock yum repositories only carry version 1.2. After a little digging I found an RPM that had version 1.4, but that carried with it a stack of other RPM dependencies that I decided not to try to untangle (been there, hated that.) \\n\\n CollabNet Subversion \\n\\n My next step was to try the recommended enterprise configuration from CollabNet. I really didnt realize what I was getting myself into, but the result was a 1.4 version of Subversion bundled with its own Apache server. Now, Ive been tweaking our trac-Apache-Subversion deployment quite a bit to make project creation quick and properly integrated. The thought of throwing in another Apache server into the mix didnt seem manageable, and recreating what I did with our current Apache server looked like a serious undertaking. So, “rpm –erase” and back to the drawing board. \\n\\n subversion-1.4.3.tar.bz2 \\n\\n “When in doubt, build from the source.” Building Subversion from the sources is pretty much what Ive come to expect from the ./configure, make, make install cycle. I made sure I also downloaded the subversion-deps tarball recommended in the release notes, and followed it to the letter. The result was a broken svn client. \\n\\n svn undefined symbol: SSL_load_error_strings \\n\\n The Subversion server seemed to be working well behind Apache and trac, but Erics CC.rb builds were failing with an SSL error. I verified the error from the command-line and did some more Googling. A few hits down I ran across this post and this email thread which helped me greatly. The only thing standing in my way was a stupid bit of automation I failed to account for. \\n\\n Could not read status line: Secure connection truncated \\n\\n I banged my head against this one for much longer. Google failed me, rebuilds failed me. I had a thought that maybe I forgot to restart Apache after one of the rebuilds, and I noticed that it was complaining that the svn modules had already been loaded so they wouldnt be loaded again. I had seen this in an earlier restart and just thought, “Okay, Ill clean that up once I get this Subversion thing to work.” However, if I had bothered to look at the httpd.conf Id have seen that my “make install” had added the correct LoadModule line pointing to the new module, but the old LoadModule was left in place pointing to the old module. The old LoadModule happened before the new one, so I was loading an incompatible module. Once I pulled out the old module there was joy in Mudville once again. \\n\\n', 'excerpt': ' Yesterday Eric asked me to upgrade our Subversion version from 1.2 to 1.4 in order to take advantage of the new XML responses needed by CruiseControl.rb. My first clue that this wasnt going to be easy was that the stock yum repositories only carry version 1.2. After a little digging I found an RPM that […] \\n', 'post_date': '2007-04-16T00:00:00-0400', 'categories': ['blog', 'System Administration'], 'id': 'https://opensourceconnections.com/blog/2007/04/16/upgrading-to-subversion-14-on-a-fedora-core-4-server/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/18/a-web-20-bubble/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'A Web 2.0 Bubble?', 'url': 'https://opensourceconnections.com/blog/2007/04/18/a-web-20-bubble/', 'author': 'jason-hull', 'content': ' Reuters reported this morning that the number of contributors to many Web 2.0 sites such as YouTube and Flickr is much smaller than the number of people who come to look at the content generated. With the glaring exception of Wikipedia, the average tends to run around 500 viewers for each contributor. At first glance, this might seem like a shock given that Web 2.0 applications are supposed to make it easier for the user to participate and contribute, but further examination shows that maybe its not surprising after all. \\n\\n First, let us look at the ease with which users can add content. The original “category killer” was the blog, where within minutes, people would be able to set up their own commentary site and become the next Bill Kristol or Fred Barnes. While creation of blogs continues at a rapid pace, Technorati reports that there are 1.5 million posts daily to a population of approximately 57 million blogs, or about a 2% contribution rate. That is for a medium which requires no additional equipment besides a computer. Once you add in digital equipment necessary to create the media for many Web 2.0 sites, it is not surprising that the contribution rate drops. \\n\\n\\n Secondly, it seems that human nature is a contributing factor to this phenomenon. Garret Hardins \\n\\n Tragedy of the Commons succinctly explains what is happening here. Any time you have a contribution to the public good (as the site owners would argue these sites are), many more people will take advantage of the public good than will contribute to it. These “free riders” are happy to take part and take advantage of the common good, but few will pony up resources to keep it going for everyone else. That is why public radio has to have fundraising drives all of the time and why street performers only have the scantest of change in their tip jars. \\n\\n Does this mean that the Web 2.0 sites should pack up and go home? No. Aside from the most altruistic of creators, the purpose of these sites is profit. Profit is generated on these sites almost exclusively from advertising revenue. What draws advertising revenue? Visits to the site. So, even if these sites have an incredibly skewed proportion of contributors to viewers, they still have viewers, and the contributors are free staff, meaning that the cost of content generation is zero. One of the biggest variable costs in a fixed media such as a newspaper, the staff needed to create the content, is eliminated in Web 2.0 sites. As Flickr and YouTube have proven, it does not take many content creators to drive an enormous amount of traffic. \\n\\n', 'excerpt': ' Reuters reported this morning that the number of contributors to many Web 2.0 sites such as YouTube and Flickr is much smaller than the number of people who come to look at the content generated. With the glaring exception of Wikipedia, the average tends to run around 500 viewers for each contributor. At first glance, […] \\n', 'post_date': '2007-04-18T00:00:00-0400', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/04/18/a-web-20-bubble/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/26/parsing-ruby-for-porting/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Parsing Ruby for Porting', 'url': 'https://opensourceconnections.com/blog/2007/04/26/parsing-ruby-for-porting/', 'author': 'scott-stults', 'content': ' Ive recently started a research project to port a Ruby workflow engine (OpenWFEru) to Python. I thought that if I could write a basic Ruby parser I could at least form the skeleton of my project (since package, module, and class notations are similar between the languages, and mapping the Abstract Syntax Tree to actual code would be a breeze.) \\n\\n I did a little Googling to find a Ruby grammar that I could work from, and there seemed to be a little activity around using Antlr. Antlr does support generating Python parsers, so I downloaded it and the Ruby grammar and gave it a shot. \\n\\n When I ran Antlr against the grammar I got a bunch of warnings about lexical non-determinism. That didnt surprise me given Rubys complexity, but a parser and a lexer was generated and I hoped that it would suffice. However, my hopes were immediately dashed when I fed actual Ruby code into the lexer: \\n\\n error: exception caught while lexing: unexpected char: `# \\n\\n It didnt understand comments!\\nI really only wanted to spend a little time on this portion of the project (whats commonly referred to as a “spike”) so thats as far as I took it. The Antlr docs spoke of comment ambiguity in the Python parsers, but I didnt have time to dig deeper.\\nAlong the way I Googled to see how the Python community handles its parser generator needs, and ran across this excellent analysis. YAPPS seemed to be the clear winner in that case, but in order to use a different parser I would probably need to translate the only Ruby grammar I found into a different syntax. \\n\\n So for now Ill be using the parser generator between my ears and lexing with my eyes. If anyones had better success at parsing Ruby, please leave a comment below. \\n\\n', 'excerpt': ' Ive recently started a research project to port a Ruby workflow engine (OpenWFEru) to Python. I thought that if I could write a basic Ruby parser I could at least form the skeleton of my project (since package, module, and class notations are similar between the languages, and mapping the Abstract Syntax Tree to actual […] \\n', 'post_date': '2007-04-26T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/04/26/parsing-ruby-for-porting/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-code-metrics/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'CITcon 2007: Code Metrics', 'url': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-code-metrics/', 'author': 'eric-pugh', 'content': ' Notes from the Code Metrics session: \\n\\n What kind of code metrics do you collect? \\n\\n \\n   Complexity \\n   Coverage \\n   Dependencies \\n   Documentation \\n   Code Style \\n   \\n     of unit tests, line of code \\n   \\n   Code Duplicates \\n   Volatility \\n   Velocity \\n \\n\\n Great first metric is volatility or churn: the number of commits in a specific area contracted to complexity. Volatility comes from version control data, complexity is produced by a script. Gives you a solid feel of where potential bugs are, typically where there are lots of commits in a complex area as measured by your complexity tool. \\n\\n “Cyclomatic Complexity” apparently has lots of research behind it proving that high complexity leads to bugs, and that this is really good spot to look at in reducing code. \\n\\n Metrics are much more valuable when you have them in a historical context. Hackystat (a favored tool of mine!) gets a plug. Sabre has developed a home grown system that parses reports and adds them to Mysql… They could use HackyStat for similar function. \\n\\n Demo/introduction of Panopticode. Visualizes metrics with the goal of making the use of metrics simple and ubiquitous. \\n\\n I think Ill be looking very closely at Panopticode, and how visualizations can help make metrics more relevant to management and teams, versus just some charts that are never acted on. \\n', 'excerpt': ' Notes from the Code Metrics session: What kind of code metrics do you collect? * Complexity * Coverage * Dependencies * Documentation * Code Style * # of unit tests, line of code * Code Duplicates * Volatility * Velocity Great first metric is volatility or churn: the number of commits in a specific area […] \\n', 'post_date': '2007-04-28T00:00:00-0400', 'categories': ['blog', 'Conference', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-code-metrics/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-notes/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'CITcon 2007 Notes', 'url': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-notes/', 'author': 'eric-pugh', 'content': ' Im at CITcon (pronounced kitcon) 2007 in Dallas/Ft Worth. There are around 60 people here from all across the United States, including some of the heavy hitters of the Testing/Agile world including Martin Fowler, Chief Scientist of ThoughtWorks, Jason Huggins, inventor of Selenium, and Bret Pettichord, inventor of Watir, plus many more. Its been a great opportunity to meet many other folks that Ive heard of like Andrew Glover, president of Stelligent, who has been one of the key users and writers about DBUnit. \\n\\n CITcon uses the “OpenSpaces” format for running a conference. OpenSpaces encourages adhoc converstation and audience involvment by leaving the schedule and topics up to the particpants. No boring lectures, just lots of group discussion. \\n\\n Last night we were given the basic schedule of sessions and rooms:\\n \\n\\n Then we came up with various session ideas. We came up with more sessions then we had time for, so over drinks people discussed the various proposals, and voted with tick marks what sessions interested them. Eventually a schedule solidified through negotiation between folks. My proposal is in “Green Lantern” at 3:15 PM, second row, fifth column in the chart!\\n \\n\\n This morning we were all standing in the hall seeing what the schedule had changed to:\\n \\n', 'excerpt': ' Im at CITcon (pronounced kitcon) 2007 in Dallas/Ft Worth. There are around 60 people here from all across the United States, including some of the heavy hitters of the Testing/Agile world including Martin Fowler, Chief Scientist of ThoughtWorks, Jason Huggins, inventor of Selenium, and Bret Pettichord, inventor of Watir, plus many more. Its been a […] \\n', 'post_date': '2007-04-28T00:00:00-0400', 'categories': ['blog', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-notes/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-retrospective/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'CITcon 2007: Retrospective', 'url': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-retrospective/', 'author': 'eric-pugh', 'content': ' Its been an incredible day of meeting amazing people who are doing amazing things. Being with 40 of my peers in the CI field for a day and a half has been wonderfully invigorating. \\n\\n We had a wonderful setup, with plenty of large rooms and some great snacks: \\n\\n  \\n\\n The rooms had many rolling office chairs in each, and no tables, which led to ad hoc groupings and a flexible mindset towards the conference: \\n\\n  \\n\\n We wrapped up with a “retrospective” where we shared what we got out of the time, and our thoughts about the conference. A little different from a 5000 person conference like OSCON! \\n\\n  \\n\\n  \\n\\n Being able to have discussions with people like Martin Fowler over a beer or in a small group environment made this possibly my best conference ever! \\n', 'excerpt': ' Its been an incredible day of meeting amazing people who are doing amazing things. Being with 40 of my peers in the CI field for a day and a half has been wonderfully invigorating. We had a wonderful setup, with plenty of large rooms and some great snacks: The rooms had many rolling office chairs […] \\n', 'post_date': '2007-04-28T00:00:00-0400', 'categories': ['blog', 'Conference', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-retrospective/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-rspec-is-the-new-testunit/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'CITcon 2007: RSpec is the new Test::Unit', 'url': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-rspec-is-the-new-testunit/', 'author': 'eric-pugh', 'content': ' My first session was entitled RSpec is great of what? and talked about a tool that helps you do “Behavior Driven Development”. The key difference between RSpec as a validation tool from other xUnit tools like JUnit or Test::Unit is that instead of using “Assert” style validations we use “Should” style validations. Here is a short example of pulling up a web page and verifying the words “Administer Bookshelf” show up. \\n\\n $ie = $ie || Watir::IE.new\\n$ie.goto http://localhost:3000/login/login\\n$ie.text.should include(Administer Bookshelf) \\n\\n Compare the last line to something in the older “Assert” style: \\n\\n assert $ie.text.include?(`Adminster Bookshelf) \\n\\n The should syntax reads much easier! And by removing the word “test” from your vocabulary you remove the Tester/Developer divide. “Should” is something you would define before writing the code. “Test” is something you do after you write the code! \\n', 'excerpt': ' My first session was entitled RSpec is great of what? and talked about a tool that helps you do “Behavior Driven Development”. The key difference between RSpec as a validation tool from other xUnit tools like JUnit or Test::Unit is that instead of using “Assert” style validations we use “Should” style validations. Here is a […] \\n', 'post_date': '2007-04-28T00:00:00-0400', 'categories': ['blog', 'Conference', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/04/28/citcon-2007-rspec-is-the-new-testunit/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/03/openwfepy-and-dynamic-language-toolkit/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'OpenWFEpy and Dynamic Languages Toolkit', 'url': 'https://opensourceconnections.com/blog/2007/05/03/openwfepy-and-dynamic-language-toolkit/', 'author': 'scott-stults', 'content': ' As I noted in an earlier post, I just started a project called OpenWFEpy. Its a Python port of the OpenWFE workflow engine, and if youd like to be on the mailing list just let me know. \\n\\n In between bouts of manually converting the files, Ive been searching for some automation I can use to help me. One possibility I explored was creating a Ruby parser using Antlr. For whatever reason that didnt prove as fruitful as Id hoped, but Andrew left me an interesting comment regarding an Eclipse plugin project called Dynamic Languages Toolkit (DLTK). \\n\\n As the name implies, DLTK is designed to be a common framework from which to build dynamic language IDEs. If youve tried to use Eclipse for anything other than Java programming, youve probably witnessed widely varying feature sets between language plugins. Its API bridges the gap between the Eclipse framework and a language parser, so once you have a parser built and plugged into the API, all the cool features of a great IDE are immediately available to you. \\n\\n Included in the toolkit is a Ruby IDE that they built on their API. They didnt include the grammar, but as long as the parser isnt coupled too tightly I could either use it stand-alone or add some sort of “Convert to Python” refactoring. This path seems a little more promising than building from scratch the parser Ill need, but as with the earlier spike, if I spend too much time getting to know the tools Ill have less time to do the actual work.   \\n', 'excerpt': ' As I noted in an earlier post, I just started a project called OpenWFEpy. Its a Python port of the OpenWFE workflow engine, and if youd like to be on the mailing list just let me know. In between bouts of manually converting the files, Ive been searching for some automation I can use to […] \\n', 'post_date': '2007-05-03T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/05/03/openwfepy-and-dynamic-language-toolkit/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/03/rspec-simplifies-communications/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'RSpec simplifies communications?', 'url': 'https://opensourceconnections.com/blog/2007/05/03/rspec-simplifies-communications/', 'author': 'eric-pugh', 'content': ' At CITcon, I learned a lot about RSpec, a Ruby library for writing out specifications that is used in BDD: Behavior Driven Development. \\n\\n This has got me to thinking about one of the key challenges in software development: communciation. We spend massive amounts of time retelling requirements from one person to another, and translating them from one format to another. A Business Analyst writes up the requirements in a Word document. A developer translates those requirements into unit tests and code, and lastly a Tester verifies the functionality using yet another suite of testing tools! Its no wonder so many software development projects suffer delays. \\n\\n One of the key points that Martin Fowler made at CITcon was that he expected the roles of Business Analyst and Tester to merge, and the roles of Developer and Tester to merge. If you think about it, it makes sense. The Business Analyst knows best what the results should be, so shouldnt that person be the one testing the code works correctly? And, the Developer is the one who knows (or should know!) what the weakest points in the code are, and so they should be best suited to test the code. \\n\\n So what does merging roles have to do with RSpec? Easy, RSpec is currently the best lightweight way of writing specifications the way a Business Analyst might, that are runnable tests that a Tester might run. Now, I know that there are lots of ways of poking holes in this statement, but as a thought experiment, Rob, a colleague of mine, and I are going to attempt this, with me filling the role of the merged Business Analyst/Tester, and him as the developer. We need to write a bit of code for a shipping module for an ecommerce site that has somewhat unusual pricing rules. I have written some RSpec specifications that currently fail, and hell write the code until they pass. All without us communicating except via the specifications that Ive written. \\n\\n I ran rake spec:doc and produced this summary of the specifications I had written: \\n\\n ```\\nShipping for non-combineable products\\n- should have the base price for just one\\n- should multiple linerarly the base price for more then one \\n\\n Shipping for combineable product\\n- should have the base price, and extra fields filled in, but not used for just one\\n- should add shipping_factor_second to shipping base for two items\\n- should add shipping_factor_third to shipping_factor_second to shipping_base for three items\\n- should keep adding on the third_shipping_factor for any additional items beyond 3 \\n\\n shipping for multiple types of products\\n- should handle combinable and noncombinable products in same cart\\n``` \\n\\n Quite nice output from just pulling data out of some RSpec code, looks somewhat like what I would write as some requirements. Ill be posting a followup on how Rob does with just those specifications to use in grokking my meaning! \\n', 'excerpt': ' At CITcon, I learned a lot about RSpec, a Ruby library for writing out specifications that is used in BDD: Behavior Driven Development. This has got me to thinking about one of the key challenges in software development: communciation. We spend massive amounts of time retelling requirements from one person to another, and translating them […] \\n', 'post_date': '2007-05-03T00:00:00-0400', 'categories': ['blog', 'Code', 'Opinion', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/05/03/rspec-simplifies-communications/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/03/scrum-war-stories-is-coming/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Scrum War Stories is coming!', 'url': 'https://opensourceconnections.com/blog/2007/05/03/scrum-war-stories-is-coming/', 'author': 'eric-pugh', 'content': ' Come share your experiences with implementing Scrum with your peers at West Main Seafood next Wednesday, May 9th from 5:30 to 8. Over beer and dinner well share hard won lessons from the trenches of Scrum, what the cool tools are to support Scrum teams, and maybe even get philosophical and talk about where we think Scrum will be in a couple of years! \\n\\n Jeff Sutherland, co-creator of Scrum came to Charlottesville to present to the Neon Guild about Scrum. When he asked who was using it, maybe 40% of the room raised their hands! So clearly there are already a pool of Scrum practitioners, but we dont have a forum for sharing our experiences. Scrum War Stories will be a very casual event, open to anyone, from those doing Scrum, to those thinking about it! \\n\\n When: May 9th from 5:30 to 8 PM \\n\\n Where: West Main Seafood (old Awful Arthurs) map \\n\\n Who: Anyone who is using Scrum, thinking about Scrum, or quit using Scrum! \\n\\n Help: Eric@ 434-466-1467 or epugh@opensourceconnections.com \\n', 'excerpt': ' Come share your experiences with implementing Scrum with your peers at West Main Seafood next Wednesday, May 9th from 5:30 to 8. Over beer and dinner well share hard won lessons from the trenches of Scrum, what the cool tools are to support Scrum teams, and maybe even get philosophical and talk about where we […] \\n', 'post_date': '2007-05-03T00:00:00-0400', 'categories': ['blog', 'Community', 'News'], 'id': 'https://opensourceconnections.com/blog/2007/05/03/scrum-war-stories-is-coming/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/03/turning-waterfall-contracts-into-scrum-contracts/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Turning Waterfall Contracts into Scrum Contracts', 'url': 'https://opensourceconnections.com/blog/2007/05/03/turning-waterfall-contracts-into-scrum-contracts/', 'author': 'scott-stults', 'content': ' This Monday we were fortunate to hear Dr. Jeff Sutherland give a presentation on Scrum at our monthly Neon Guild meeting. He was going to be doing some training at Inova Solutions, but the Guild got a great overview of Scrum as an added bonus. \\n\\n One of the difficulties Dr. Sutherland touched on during his presentation was introducing Scrum to managers who only know of the “waterfall” method of running projects. I think this mainly impacts contracting organizations at two key points: Requirements Gathering and Delivery. \\n\\n Chunking \\n\\n The first challenge is to break large projects into smaller ones. Customers envision the final product with varying clarity. However, when they put their trust in an outside organization to deliver it they want to know exactly what they are going to be getting for their money. So, at the outset of a project they seek to protect their investment through rigorous requirements gathering and design phases. This gets exacerbated every time those involved go through a failed project, because smart managers seek to fix their processes and not the minutiae particular to any one project. Therefore the process that bares the brunt of their scrutiny is Requirements Gathering (and by association, Design.)\\nI believe the key here is to show how breaking their project into smaller chunks limits their overall exposure and gives them the flexibility to adjust the project requirements as business needs change. After all, the goal of any project is to address business needs and not a particular distillation of them represented by a requirements document. The map is not the territory. \\n\\n Deliverables \\n\\n However, the chunking of the project must also include a modification of delivery expectations. In Waterfall projects, success is measured by three questions: Was it on time, Was it within budget, and Do all features work? What burns longer projects is the Sisyphean nature of technology, in that the features you build become obsolete as you create them. The longer it takes you to deliver, the more irrelevant the project becomes. Therefore, each subproject or Sprint addresses what the customer needs right now, rather than several months down the road. In a lot of ways this breaks the PMI definition of “project” in that the end state is less defined. But since you are incorporating change into the contract, that end state is going to be much more useful to the client. \\n\\n The Contract \\n\\n Which brings us to the contract itself. You will need to translate your Scrum project into a contract that will pass legal scrutiny. This means that you have to adjust traditional contracts that state “We will do X by Y for $Z.” Those contracts place little or no responsibility on the client beyond an initial requirements specification, acceptance testing, and payment. In Scrum, customer participation in the Sprint Review is essential, and belongs in the contract. One strategy could be to only contract for the initial Sprint. But if the client is already thinking Big Project, you could trade features that are contractual obligations for Sprint Reviews that are contract termination clauses. In either case, the responsibility of project “success” is going to be shared much more than in a traditional project. As compensation, “success” will no longer be check marks on a project plan but a measurable increase in business value. \\n\\n', 'excerpt': ' This Monday we were fortunate to hear Dr. Jeff Sutherland give a presentation on Scrum at our monthly Neon Guild meeting. He was going to be doing some training at Inova Solutions, but the Guild got a great overview of Scrum as an added bonus. One of the difficulties Dr. Sutherland touched on during his […] \\n', 'post_date': '2007-05-03T00:00:00-0400', 'categories': ['blog', 'Business', 'Project Management'], 'id': 'https://opensourceconnections.com/blog/2007/05/03/turning-waterfall-contracts-into-scrum-contracts/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/08/capturing-rake-return-codes/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Capturing Rake return codes', 'url': 'https://opensourceconnections.com/blog/2007/05/08/capturing-rake-return-codes/', 'author': 'eric-pugh', 'content': ' Based on Martin Fowlers whole pitch on declarative versus imperative builds, I converted a basic Ruby script into a Rake based script. However, the one gotcha I hit was that running rake dist, the return code wasnt returned. Yes, rake would say it failed: \\n\\n \\n(in E:/irocket/continuum/working-directory/6)\\nrake aborted!\\nI should fail the build\\nE:/irocket/continuum/working-directory/6/rakefile:310\\n \\n\\n We are using Continuum, a very simple to set up CI tool, and it requires whatever script it calls to return 0 on success, and &gt; 0 on failure. So even though Rake would say the build failed, it always return 0. It turns out that some people have run into this problem: \\n\\n \\n   Rake bug on Windows \\n   Ruby Gem Creates Broken Batch File for Rake \\n \\n\\n I didnt want to hack up my rake.bat and rake.cmd files, so instead I am calling ruby directly: \\n\\n \\nruby -x e:\\\\irocket\\\\ruby\\\\bin\\\\rake.bat dist\\n \\n\\n Hopefully the next version of Rake will have this resolved! The Continuum project went through this same pain for Ant and Maven scripts, and have posted their fixed batch files. \\n', 'excerpt': ' Based on Martin Fowlers whole pitch on declarative versus imperative builds, I converted a basic Ruby script into a Rake based script. However, the one gotcha I hit was that running rake dist, the return code wasnt returned. Yes, rake would say it failed: (in E:/irocket/continuum/working-directory/6) rake aborted! I should fail the build E:/irocket/continuum/working-directory/6/rakefile:310 We […] \\n', 'post_date': '2007-05-08T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/05/08/capturing-rake-return-codes/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/08/corrupting-jruby-to-my-pythonic-ways/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Corrupting JRuby to My Pythonic Ways', 'url': 'https://opensourceconnections.com/blog/2007/05/08/corrupting-jruby-to-my-pythonic-ways/', 'author': 'scott-stults', 'content': ' Last week I downloaded the source to JRuby and began poking around its source. My hope is that eventually I can convince it that converting Ruby source to Python is a better use of its time than Java class files. Ive had to decipher large Java projects before and I was dreading the prospect of untangling inter-class dependencies, but as it turns out, JRuby is a great example of how to modularize. I think its also an example of how unit tests can show developers new to a project how to use it.\\nThe packages in JRuby are mostly dedicated to interpreting Abstract Syntax Trees (AST) into Java, but the lexer and parser packages are tantalizingly close to the root. After a quick survey of the classes contained therein, I took a look at what sort of unit tests were available specifically for the parser. \\n\\n One of the things I found during my package perusal was something called an AST node visitor. Better than that, I found a specific package for node rewriting. Better still, there was a unit test for it! Presumably this is for code reformatting of Ruby itself, but\\nAfter running the unit test and checking out what it did, I created a new project and started hacking. The built in rewriter doesnt do anything interesting – it just regurgitates what its fed without comments – so my first job was to try a little tweak that rewrites a Ruby subclass from “subclass &lt; parentclass” to Pythons “subclass(parentclass):”. Since JRuby already told me how to test this thing, it was simplicity itself to verify that my change had its desired affect. \\n\\n Ive only begun to pick at the syntax differences between Ruby and Python, but going through each compilation unit has the advantage of providing a road map. Its also started me thinking about one layer above base syntax to simple code refactoring. Another interesting possibility is the use of AST graphs as a tool for code review. I guess I should reexamine the joys of Metaprogramming! \\n\\n', 'excerpt': ' Last week I downloaded the source to JRuby and began poking around its source. My hope is that eventually I can convince it that converting Ruby source to Python is a better use of its time than Java class files. Ive had to decipher large Java projects before and I was dreading the prospect of […] \\n', 'post_date': '2007-05-08T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/05/08/corrupting-jruby-to-my-pythonic-ways/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/10/scrum-war-stories-recap-2/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Scrum War Stories Recap', 'url': 'https://opensourceconnections.com/blog/2007/05/10/scrum-war-stories-recap-2/', 'author': 'eric-pugh', 'content': ' Last night we had wonderful participation for our first Scrum War Stories dinner, with 9 folks from 7 different organizations showing up at West Main. The discussions we had were wide ranging and for me the value was in the interaction with my peers! \\n\\n The main themes that came up over dinner from my POV were: \\n\\n \\n   \\n     Change is hard. People reach a comfort level in their own niche, and dont see the larger problems challenging the business that they need to change to overcome. \\n   \\n   \\n     Oldstyle approaches to supervising project teams dont work. With 3 week Sprints, there isnt enough time for an outside group to influence the Scrum team. I argued that instead of an outside group supervising/inspecting the Scrum team, they need to merge. They need to be members of the team, or be the Product Owner. \\n   \\n   \\n     Strong Product Owners are key! \\n   \\n \\n\\n  \\n\\n Scott Stults mentioned that the term “Sprint” really is a misnomer, because you arent sprinting to a finish line, but instead maintaining a constant pace, that allows time for other things like process improvement, people on vacation, technical development. He proposed the term “Relay”, which I really liked. In a relay, different people handle the baton, and the results arent measured on any individuals performance, but the performance of the team as a whole. \\n\\n Not sure how we get the Scrum world to change from “Sprint” to “Relay”, but I may start trying to use it in everyday speech. \\n\\n Many thanks to everyone who showed up, and a big thank you to Aaron Buchanan from Inova for cosponsoring the event with me, it wouldnt have happened without his enthusiasm. \\n', 'excerpt': ' Last night we had wonderful participation for our first Scrum War Stories dinner, with 9 folks from 7 different organizations showing up at West Main. The discussions we had were wide ranging and for me the value was in the interaction with my peers! The main themes that came up over dinner from my POV […] \\n', 'post_date': '2007-05-10T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2007/05/10/scrum-war-stories-recap-2/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/15/learn-about-selenium-betech-tomorrow/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Learn about Selenium @beTech tomorrow!', 'url': 'https://opensourceconnections.com/blog/2007/05/15/learn-about-selenium-betech-tomorrow/', 'author': 'eric-pugh', 'content': ' Ill be presenting Selenium for beTech tomorrow in Newcomb Hall at 2 PM! \\n\\n Im throwing out my old Selenium presentation that has served me well, taking me to such conferences as OSCON in Portland, Oregon, a testing conference in Valencia, Spain, and of course at our own local Neon Guild conference and doing something completely new, focusing on themes and possibilities of using Selenium versus dry technical details. See you tomorrow! \\n', 'excerpt': ' Ill be presenting Selenium for beTech tomorrow in Newcomb Hall at 2 PM! Im throwing out my old Selenium presentation that has served me well, taking me to such conferences as OSCON in Portland, Oregon, a testing conference in Valencia, Spain, and of course at our own local Neon Guild conference and doing something completely […] \\n', 'post_date': '2007-05-15T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2007/05/15/learn-about-selenium-betech-tomorrow/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/24/how-to-ignore-files-in-subversion/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'How to ignore files in Subversion', 'url': 'https://opensourceconnections.com/blog/2007/05/24/how-to-ignore-files-in-subversion/', 'author': 'eric-pugh', 'content': ' For some reason, adding files and directories to ignore in Subversion is much harder then in CVS. \\n\\n The syntax, as it you are editing a .cvsignore file is: \\n\\n svn propedit svn:ignore . –editor-cmd vi \\n\\n Just add your patterns and then do \\n\\n svn ci -m `adding new svn:ignore patterns . \\n', 'excerpt': ' For some reason, adding files and directories to ignore in Subversion is much harder then in CVS. The syntax, as it you are editing a .cvsignore file is: svn propedit svn:ignore . –editor-cmd vi Just add your patterns and then do svn ci -m `adding new svn:ignore patterns . \\n', 'post_date': '2007-05-24T00:00:00-0400', 'categories': ['blog', 'Productivity'], 'id': 'https://opensourceconnections.com/blog/2007/05/24/how-to-ignore-files-in-subversion/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/29/tech-leads-should-lead/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Tech leads should lead', 'url': 'https://opensourceconnections.com/blog/2007/05/29/tech-leads-should-lead/', 'author': 'jason-hull', 'content': ' Our tech leads love being eyeball deep in code because they love being coders.\\xa0 However, sometimes this creates problems because we need them to lead multiple projects.\\xa0 When tech leads get too deep into the code, two things happen: 1) they cannot pull away to perform the same role on other projects, and 2) they do not maintain perspective on the code that theyre deep into.\\xa0 Tech leads need to be there to perform code review and to crack the tough nuts.\\xa0 Other team members are there to code.\\xa0 IT managers are wise to help their tech leads maintain their distance. \\n', 'excerpt': ' Our tech leads love being eyeball deep in code because they love being coders.\\xa0 However, sometimes this creates problems because we need them to lead multiple projects.\\xa0 When tech leads get too deep into the code, two things happen: 1) they cannot pull away to perform the same role on other projects, and 2) they […] \\n', 'post_date': '2007-05-29T00:00:00-0400', 'categories': ['blog', 'Productivity', 'Project Management', 'scrum'], 'id': 'https://opensourceconnections.com/blog/2007/05/29/tech-leads-should-lead/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/05/30/rails-plugin-fixture_references-has-out-of-date-docs/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Rails plugin ‘fixture_references’ has out of date docs', 'url': 'https://opensourceconnections.com/blog/2007/05/30/rails-plugin-fixture_references-has-out-of-date-docs/', 'author': 'eric-pugh', 'content': ' So I shot about 2 hours today trying to figure out why the use of the fixture_references plugin was causing my fixtures to not load, based on a “Can not convert String to Integer” error. I mucked around with my .yml files, thinking it was in my formatting. Finally giving up, I took a quick peek at the changelog, and discovered the API had changed, but the documentation hadnt! \\n\\n In my fixture I was doing what the docs said: \\n\\n vehicle_make_id: &lt; %= vehicle_makes(:acura)[‘id’] %&gt; \\n\\n But the API had changed so it should be: \\n\\n vehicle_make_id: &lt; %= vehicle_makes(:acura, ‘id’) %&gt; \\n\\n This is why I hate when people use blogs as documentation sites versus wikis.. Blogs are temporal in nature, and dont lend themselves to updates. Hopefully this will spur the developers to update the docs, after all, the plugin is a really nice plugin! \\n\\n This was a problem with AjaxScaffold as well, but the creator didnt make the same mistake with ActiveScaffold, the successor project. \\n', 'excerpt': ' So I shot about 2 hours today trying to figure out why the use of the fixture_references plugin was causing my fixtures to not load, based on a “Can not convert String to Integer” error. I mucked around with my .yml files, thinking it was in my formatting. Finally giving up, I took a quick […] \\n', 'post_date': '2007-05-30T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/05/30/rails-plugin-fixture_references-has-out-of-date-docs/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/06/06/file-uploads-with-selenium/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'File Uploads with Selenium', 'url': 'https://opensourceconnections.com/blog/2007/06/06/file-uploads-with-selenium/', 'author': 'eric-pugh', 'content': ' A colleague pinged my on how to do a file upload from a Selenium script. My smart ass reply was “Did you look at the file_upload tag?”. And then I realized that File Upload is one of those things that the JavaScript security model in browsers makes very difficult. You have to explicitly select a file, which makes sense since you wouldnt want to visit a site that had some evil JavaScript on it that magically uploaded your Quicken data file or some other file that is in a well known location. \\n\\n There are some workarounds, including mucking around with your security model: \\n\\n http://cakebaker.wordpress.com/2006/03/29/file-upload-with-selenium/ \\n\\n The Selenium FAQ also talks about using SeleniumIDE to work around the JavaScript security model. This is also a good solution when testing across multiple servers as well! \\n\\n However, the solution I find preferable is to take advantage of the 80% solution/20% effort that Selenium is out of the box, and not test file uploads directly. Instead, add a helper action like /fileupload?file=path/to/my/file.txt that you can invoke from Selenium. Have the helper action do the basic file upload, just like the webpage does, and then return to testing your site post file upload! This is the simplest, most cross platform approach. Its also a very good pattern for working around other gotchas in Selenium. \\n', 'excerpt': ' A colleague pinged my on how to do a file upload from a Selenium script. My smart ass reply was “Did you look at the file_upload tag?”. And then I realized that File Upload is one of those things that the JavaScript security model in browsers makes very difficult. You have to explicitly select a […] \\n', 'post_date': '2007-06-06T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/06/06/file-uploads-with-selenium/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/06/15/showing-sphereit/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Showing “Sphere”it', 'url': 'https://opensourceconnections.com/blog/2007/06/15/showing-sphereit/', 'author': 'jason-hull', 'content': ' Several of our recent projects have involved different methods of data sorting, manipulation, and visualization. An example of this is now available with the University of Virginia Librarys BlacklightDL project. One of the issues that we run into is determining similarity and trying to predict whether or not certain results will actually be similar to what is being searched for. \\n\\n At issue is the balance between the engine interpolating what the searcher wants and, on the other side, making the searcher be as precise as possible with his search terms. On one end is a sample search with one term and a multitude of results (for example, a Google search for the term dog) and on the other end, a search for a long string of text. Most searchers dont want to spend their time either typing in the volumes of text or dont know exactly how to pull out the most pertinent pieces of what they are looking for. \\n\\n Enter Sphere. Sphere looks at the entirety of the content of a page that you are looking at and searches for blog posts which contain similar information. Rather than looking simply at the links within a page, it searches based on the entirety of the comment. This provides enough detail to create more accurate results without forcing the user to enter in excessive (and potentially inaccurate and superfluous) information.\\xa0 Alternatively, the user can enter in the link of the page of interest to the Sphere search engine to get similar results based on the full text of the site.\\xa0 An example search yielded results of similar entries to this page.\\nNow, if only Sphere could find blog pages similar to what Im thinking rather than to what Im reading, Id be happy! \\n\\n', 'excerpt': ' Several of our recent projects have involved different methods of data sorting, manipulation, and visualization. An example of this is now available with the University of Virginia Librarys BlacklightDL project. One of the issues that we run into is determining similarity and trying to predict whether or not certain results will actually be similar to […] \\n', 'post_date': '2007-06-15T00:00:00-0400', 'categories': ['blog', 'Software'], 'id': 'https://opensourceconnections.com/blog/2007/06/15/showing-sphereit/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/06/26/continuous-integration-war-stories-meetup-in-nova/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Continuous Integration War Stories Meetup in NoVA', 'url': 'https://opensourceconnections.com/blog/2007/06/26/continuous-integration-war-stories-meetup-in-nova/', 'author': 'eric-pugh', 'content': ' I wanted to let folks know that Andrew Glover and Paul Duvall are hosting a “Share your Continous Integration War Stories” meetup in Northern Virginia. Andrew and I met at CITCon, and he and Paul have written “The Book” on Continous Integration. Below are the details: \\n\\n \\n   Weâ€™re hosting a â€œShare your Continuous Integration War Storiesâ€� (http://www.stelligent.com/content/view/128/62/) event this Thursday evening at our offices in Reston, VA â€“ it should be a great opportunity to hang out and discuss CI over wine, beer, and other refreshments. In addition, weâ€™ll be raffling off the first signed copy of the CI book Paul authored. \\n \\n\\n \\n   When: Thursday, June 28th from 5:30 PM to 7 P.M\\nWhere: Stelligents headquarters \\n \\n\\n \\n   11495 Commerce Park Drive \\n \\n\\n \\n   Reston, VA 20191\\nWho: Anyone who is using CI or thinking about CI (and loves wine) \\n \\n\\n \\n   If youâ€™re interested, please RSVP (mandy.owens@stelligent.com). Hope to see you on Thursday! \\n \\n\\n Andy writes the very entertaining Disco Blog covering software development and testing practices. \\n', 'excerpt': ' I wanted to let folks know that Andrew Glover and Paul Duvall are hosting a “Share your Continous Integration War Stories” meetup in Northern Virginia. Andrew and I met at CITCon, and he and Paul have written “The Book” on Continous Integration. Below are the details: &gt; Weâ€™re hosting a â€œShare your Continuous Integration War […] \\n', 'post_date': '2007-06-26T00:00:00-0400', 'categories': ['blog', 'Code', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2007/06/26/continuous-integration-war-stories-meetup-in-nova/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/06/26/hi-my-name-is-michael-and-im-a-programmerdesigner/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Hi, My name is Michael and Im a programmer/designer', 'url': 'https://opensourceconnections.com/blog/2007/06/26/hi-my-name-is-michael-and-im-a-programmerdesigner/', 'author': 'scott-stults', 'content': ' Sorry for the AA style header for the introduction blog post. I tend to abuse witty repertoire to set off a style of writing to call my own and yet still find a way to stay informative. My name is Michael, Im a sagittarius, Im originally from an area south of Richmond, and Im what you refer to as the “new guy” at Opensource Connections. I specialize in C# on the .net platform, working both on the web and windows side of things. Im also a communications major with a media specialization, which means my skills range from desktop publishing, to web design, audio/visual media, radio, public relations, and marketing. I know it might seem like a bit of a paradox for someone like me, who develops using Microsoft Technologies, to work for an company that specializes in open source software. \\n\\n However Im a big proponent of open source software and agile style programming, so much so, that Im spending time developing an open source application framework for .Net for my BHAG (big hairy audacious goal(s)) this year. In fact, there is an alpha version of the site and blog for the opensource framework at www.codeaccessory.net, where you can find more information about the BHAG on an ongoing basis as well as code samples. If you have an open sourced project, or even just want a place to write about software, feel free to contact me if youre interested on doing something on the code accessory domain. The framework itself does have a name, but Im waiting for the first alpha version to be released before I reveal the name. \\n\\n In the mean time expect to see postings from me, about semantic xhtml markup, css, c#, javascript, .net, design principles, code patterns, ruby, php, the current state of my BHAG project and all sorts of User Interface goodness. Lets not forget to throw in the sarcasm drenched humor and random comments like “fuzzy pants” (it keeps you reading to see what I type next, doesnt it?). Coming soon: table-less layouts, using code_highligher.js, and ways to free your mind when it comes using CSS to separate presentation from markup/content. \\n\\n', 'excerpt': ' Sorry for the AA style header for the introduction blog post. I tend to abuse witty repertoire to set off a style of writing to call my own and yet still find a way to stay informative. My name is Michael, Im a sagittarius, Im originally from an area south of Richmond, and Im what […] \\n', 'post_date': '2007-06-26T00:00:00-0400', 'categories': ['blog', 'solr'], 'id': 'https://opensourceconnections.com/blog/2007/06/26/hi-my-name-is-michael-and-im-a-programmerdesigner/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/06/29/enhancing-tests-is-the-way-to-join-a-community/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Enhancing Tests is the way to join a community', 'url': 'https://opensourceconnections.com/blog/2007/06/29/enhancing-tests-is-the-way-to-join-a-community/', 'author': 'eric-pugh', 'content': ' Yesterday Yonik committed my first contribution to Solr. It was a simple simplification of the test code infrastruture. Some of the tests depend on Java System properties, however if you are not running the tests from Ant, you dont have them… For example, running them from Eclipse. The advice was to pass them in using -D parameters, but that isnt very user friendly! So I did a tweak that set those System properties in the Java code. I posted the patch to the mailing list, and Yonik committed them as revision 551701 \\n\\n What I realized is that one of the best ways to get to know a new community is to contribute to the test code. As an unknown quantity, suggesting major new features or architecture changes wont go over well, but contributing/fixing/updating tests shows that you are eager to learn how the community works, and not just trying to get your cool new feature added. Writing tests for OSWorkflow and OSUser was how I became a committer over at OpenSymphony, only later did I start writing actual product code. \\n\\n Also, by digging through the unit tests, you really get to learn how the code works, and where the pitfalls are as well! \\n', 'excerpt': ' Yesterday Yonik committed my first contribution to Solr. It was a simple simplification of the test code infrastruture. Some of the tests depend on Java System properties, however if you are not running the tests from Ant, you dont have them… For example, running them from Eclipse. The advice was to pass them in using […] \\n', 'post_date': '2007-06-29T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2007/06/29/enhancing-tests-is-the-way-to-join-a-community/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/03/getting-business-is-not-an-entitlement/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Getting business is not an entitlement', 'url': 'https://opensourceconnections.com/blog/2007/07/03/getting-business-is-not-an-entitlement/', 'author': 'jason-hull', 'content': ' I just came back from the National Veterans Small Business Conference and Expo. I was really impressed at the outreach that prime contractors and government agencies showed. They are making a good faith effort to live up to the 3% service disabled veteran owned small business (SDVOSB) goals set forth in Public Law 106-50 even though historically, they have had trouble meeting those goals. \\n\\n I think that it is laudable that the government wants to give back to the veterans who gave their service to the nation. I applaud and admire the set asides not just for SDVOSBs, but for all disadvantaged groups. However, the government, first and foremost, owes a duty of responsibility to all of those it serves, which includes getting the maximum value for the tax dollars that we all pay to it. By not getting the best value out of money that it spends for the goods and services that it procures, the government is doing everyone a disservice. \\n\\n\\n\\n How does that paragraph not contain a contradiction in terms? It is not when the companies representing disadvantaged groups offer goods and services at a fair value to the government and to the prime contractors who are trying to meet those goals. This does not include exhibiting an entitlement culture, as many of the representatives of small disadvantaged businesses showed during the Veterans Conference. Far too many times, I heard a question along the lines of when was the government going to start holding its people (and, by proxy, its prime contractors) responsible for hitting the goals that were laid out in 106-50. \\n\\n Prime contractors are in business to make money and to provide value, not to pander to special interests. Rather than griping and whining about how the government is not providing enough of what amounts to be handouts, these small businesses should be going out there and demonstrating and providing valuable goods and services. If they provide something that people want to pay money for rather than a corporate shell which is demanding entitlements, then they will find that profits accrue. Prime contractors did not become large businesses through whining and begging. They got there through hard work and through providing value to others. They did it through the basic tenets of business: find a market niche where demand is greater than supply, and provide supply. Its not easier done than said, or else wed all run behemouth businesses, but, at the same time, no business is going to grow through the increased use of whining and begging and complaining to the government that its not giving them enough entitlements. \\n\\n To those who attended the conference and went there to network, find opportunities, and create value, I offer applause and thanks that you represent the best of the veterans who have decided to go into business for themselves. To those who attended the conference to badger, harass, and pester government and prime contractor representatives about when they were going to increase entitlements and not provide taxpayers and shareholders with the best possible value for the money, I shake my head in disappointment. You did not ask your drill sergeants for a break or to not make you pass PT or marksmanship tests. Why are you asking for the free ride now? \\n\\n', 'excerpt': ' I just came back from the National Veterans Small Business Conference and Expo. I was really impressed at the outreach that prime contractors and government agencies showed. They are making a good faith effort to live up to the 3% service disabled veteran owned small business (SDVOSB) goals set forth in Public Law 106-50 even […] \\n', 'post_date': '2007-07-03T00:00:00-0400', 'categories': ['blog', 'Business', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/07/03/getting-business-is-not-an-entitlement/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/05/why-contributing-back-to-the-community-is-important/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Why contributing back to the community is important', 'url': 'https://opensourceconnections.com/blog/2007/07/05/why-contributing-back-to-the-community-is-important/', 'author': 'jason-hull', 'content': ' As a general rule, our company does not design and develop small websites. However, there is one exception. We run the website for the Middlebrook Horse Show, run by the Middlebrook Ruritans. Why do we spend our time on this website? We spend time working on and supporting this website because it is a charitable organization, and we want to give back to the community from which we come. \\n\\n Were it not for the local community, we would not be in the position that we are in. Schools, infrastructure, and friends all come from our surroundings, and we feel obligated to give in some small part back to the community that gave so much to us. \\n\\n While it is a simple site, the Middlebrook Horse Show site also gives us a chance to test out concepts in Ruby, which is always a good thing! \\n\\n Generally, a high end services company does not want to dilute its brand by taking on simpler or cheaper work. Mercedes does not build competitors to the Yugo for a good reason. However, we feel that providing a simple service for a good organization in our community helps us give back and be better community citizens–a concept more important than profit motive. \\n\\n See the site at http://www.middlebrookva.org. \\n\\n', 'excerpt': ' As a general rule, our company does not design and develop small websites. However, there is one exception. We run the website for the Middlebrook Horse Show, run by the Middlebrook Ruritans. Why do we spend our time on this website? We spend time working on and supporting this website because it is a charitable […] \\n', 'post_date': '2007-07-05T00:00:00-0400', 'categories': ['blog', 'Community'], 'id': 'https://opensourceconnections.com/blog/2007/07/05/why-contributing-back-to-the-community-is-important/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/09/eric-pugh-chosen-to-present-at-oreilly-open-source-convention/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric Pugh Chosen To Present at OReilly Open Source Convention', 'url': 'https://opensourceconnections.com/blog/2007/07/09/eric-pugh-chosen-to-present-at-oreilly-open-source-convention/', 'author': 'jason-hull', 'content': ' Eric Pugh has been chosen to present at the 2007 OReilly Open Source Convention on using and writing Rails plugins. \\n\\n OSCON is the worlds largest open source convention, with over 2,500 participants.\\xa0 It will be held July 23-27, 2007. \\n\\n Erics presentation will be held on Thursday, July 26 at 11:35 AM. More information on his presentation can be found on the OReilly page. \\n\\n', 'excerpt': ' Eric Pugh has been chosen to present at the 2007 OReilly Open Source Convention on using and writing Rails plugins. OSCON is the worlds largest open source convention, with over 2,500 participants.\\xa0 It will be held July 23-27, 2007. Erics presentation will be held on Thursday, July 26 at 11:35 AM. More information on his […] \\n', 'post_date': '2007-07-09T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2007/07/09/eric-pugh-chosen-to-present-at-oreilly-open-source-convention/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/20/come-join-us-at-oscon/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Come join us at OSCON', 'url': 'https://opensourceconnections.com/blog/2007/07/20/come-join-us-at-oscon/', 'author': 'jason-hull', 'content': ' Were going to be presenting and exhibiting at the OReilly Open Source Convention in Portland, Oregon next week, July 23-27. \\n\\n Eric will be presenting on using and writing Rails plugins on Thursday, July 26 at 11:35 AM – 12:20 PM in room Portland 255 at the Oregon Convention Center.\\nWe will also be hosting a Birds of a Feather session on Scrum War Stories Wednesday, July 25 at 7:30-8:30 PM in room D136 at the Oregon Convention Center. \\n\\n If youre going to be there, let us know, and well be on the lookout for you! \\n\\n See you in Portland! \\n\\n', 'excerpt': ' Were going to be presenting and exhibiting at the OReilly Open Source Convention in Portland, Oregon next week, July 23-27. Eric will be presenting on using and writing Rails plugins on Thursday, July 26 at 11:35 AM – 12:20 PM in room Portland 255 at the Oregon Convention Center. We will also be hosting a […] \\n', 'post_date': '2007-07-20T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2007/07/20/come-join-us-at-oscon/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/25/subversionits-not-just-for-geeks/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Subversion…it’s not just for geeks', 'url': 'https://opensourceconnections.com/blog/2007/07/25/subversionits-not-just-for-geeks/', 'author': 'jason-hull', 'content': ' We met Joe “Zonker” Brockmeier on the train last night going to Kelt (if youre at OSCON and you like Irish pubs, hop on Max and go to Kelt). He saw our OSCON shirts, which have the moniker Ruby + SVN == Committed on the back and asked if there was a Ruby front-end for Subversion. We replied that there wasnt; it is a geek play on words. He told us that he used Subversion for editing his journalistic writing. “Wow,” I thought, “a non-geek way to use Subversion. Brilliant!” Of course, we followed that up with a visit to the Irish pub and had Guinness-cooked foods. Brilliant! \\n\\n So, what other uses are there for Subversion besides just checking in code? \\n\\n', 'excerpt': ' We met Joe “Zonker” Brockmeier on the train last night going to Kelt (if youre at OSCON and you like Irish pubs, hop on Max and go to Kelt). He saw our OSCON shirts, which have the moniker Ruby + SVN == Committed on the back and asked if there was a Ruby front-end for […] \\n', 'post_date': '2007-07-25T00:00:00-0400', 'categories': ['blog', 'Productivity', 'Software'], 'id': 'https://opensourceconnections.com/blog/2007/07/25/subversionits-not-just-for-geeks/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/26/ruby-on-windows-textmate-clone-and-ides/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Ruby on windows (textmate clone and IDEs)', 'url': 'https://opensourceconnections.com/blog/2007/07/26/ruby-on-windows-textmate-clone-and-ides/', 'author': 'scott-stults', 'content': ' Ive been plowing through a lot of ruby editors for doing rails development on a windows box. I know some would say it is a lost cause. However, I do tend to do a lot of .Net development. Despite the fact i spent like 4 years in a mac lab in college, and you can run things like parallels on a mac, you always run into those extreme cases during development that can cripple your development process and spend hours, or even days to fix the issue. Sometimes you can find that you have a road block that you cant get past due to the operating system and interoperability. So rather than burning hours ( a precious resource ) fixing these special case problems, it would be best to stick with what works for now. \\n\\n Well Ive tried Ruby In Steel, which was not half bad, but it crippled any Intellisense in the .rhtml files and it just seemed to make visual studio somewhat clunky and it didnt provide as much Intellisense as you would expect from visual studio. As far as an IDE goes, Id have to say the Komodo IDE has the edge right now, as it also provides working with the prototype library as well as rails. There is also a Komodo Editor that has less features, but is a free download. \\n\\n However for those people looking for text mate on windows, I ran across the text mate blog that pointed out E-TextEditor. This editor makes use of existing text mates bundles. Now, it would be nice if you could use ctrl+space instead of tab and if the HTML bundle would have better designed snippets. But after some major tweaking of the colors and some of the bundles, its not a bad editor and will probably replace my use of notepad++, which makes use of scintilla. \\n\\n Sooner or later, I should make an attempt to export the color settings for both Komodo and E-TextEditor and post them, since decent color settings for a black background are hard to create. \\n\\n', 'excerpt': ' Ive been plowing through a lot of ruby editors for doing rails development on a windows box. I know some would say it is a lost cause. However, I do tend to do a lot of .Net development. Despite the fact i spent like 4 years in a mac lab in college, and you can […] \\n', 'post_date': '2007-07-26T00:00:00-0400', 'categories': ['blog', 'solr'], 'id': 'https://opensourceconnections.com/blog/2007/07/26/ruby-on-windows-textmate-clone-and-ides/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/28/knowing-when-to-shut-down-a-project/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Knowing when to shut down a project', 'url': 'https://opensourceconnections.com/blog/2007/07/28/knowing-when-to-shut-down-a-project/', 'author': 'jason-hull', 'content': ' Property law (at least, as taught to me by Elizabeth Scott) seeks to have owned property utilized at its highest value use. Thus, according to the basics of property law, raw land has the lowest value, since its the least utilized in comparison to houses, factories, etc. \\n\\n The same can be said for all sorts of things Internet. One example is parked domains. According to Domain Tools, there are 71,083,043 registered domains, but 217,385,494 deleted domains. While there is value in appreciation, particularly of the potentially higher demand sites–the example of sex.com comes to mind–many sites are simply either parked or have become link farms. However, as a property rights advocate, I believe that if someone has paid a fair value for a piece of property, be it land or internet domains, then that person has the right to do with that property what they want. \\n\\n\\n This does not extend to dead projects, though. There are currently 153,954 projects registered on \\n\\n SourceForge, and a long tail truly exists for these. Take the 950th most popular project, the Jedi Code Library. It averages about 100 hits a day. This is for a project that is in the top .5%ile of the existing projects on SourceForge. \\n\\n While a project like Jedi Code Library certainly is still fulfilling a need, there are many, many projects down the charts which are either no longer serving the needs of the users or, more likely, never fulfilled those needs. Keeping them on the SourceForge servers is certainly fine (I do not deign to recommend to the SourceForge team what they should do with their disk space), for projects that have become overcome by events, the owners should consider winding down the project. This will serve two purposes. It allows the better, or more relevant projects, to rise to the top, get more viewership, and, therefore, serve the community better. Secondly, it allows the developers who are on the team still piecing together the code to keep it running long past its expiration date to free up valuable time to work on other, potentially more useful projects. \\n\\n The projects are not property, per se, but the time of the developers is a valuable resource. Tie up projects which have served their useful life and put them in a state where patches will no longer be applied. Refocus developers who are donating their time to projects where the hours can have a great impact. Sometimes houses need to be razed so that newer, more livable houses can be built. The same can be done with projects which have run their useful lives, where the hours spent have passed the point of diminishing returns. \\n\\n', 'excerpt': ' Property law (at least, as taught to me by Elizabeth Scott) seeks to have owned property utilized at its highest value use. Thus, according to the basics of property law, raw land has the lowest value, since its the least utilized in comparison to houses, factories, etc. The same can be said for all sorts […] \\n', 'post_date': '2007-07-28T00:00:00-0400', 'categories': ['blog', 'Productivity', 'Project Management'], 'id': 'https://opensourceconnections.com/blog/2007/07/28/knowing-when-to-shut-down-a-project/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/07/31/is-poker-the-newest-vc/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Is Poker the Newest Venture Capitalist?', 'url': 'https://opensourceconnections.com/blog/2007/07/31/is-poker-the-newest-vc/', 'author': 'jason-hull', 'content': ' Some deep little part of nearly everyone I know has that inner burning desire to start up their own company. They dont know what they want to do, how theyre going to do it, or even why they want to, but the desire is there. Most of it has to do with the notion of getting out of the day-to-day grind of the 9 6 to 5 11 job, the Dilbert boss, the monkey-like sycophantic coworkers whose seeming purpose in life is to say “yes” to requests as many times as possible during work hours. Theres also the dreams of making it big, getting rich quick, and living the life of luxury. \\n\\n Similar aspirations drove us to start OSC. However, it wasnt a hasty decision, and weve learned some lessons along the way. \\n\\n Have a backup source of income. The guys at ClearContext played poker on the side to pay the bills. Others have spouses who work and can afford to be a single income family. Others rode Enron to the top and got off at the right time. Unless you get some sympathetic angel to fund your income or you have an idea that is an immediate hit and provides revenue right away (which can be done if youve doing the on-the-side work for a while), youre not going to be cashing a paycheck for a while. \\n\\n\\n\\n **Make sure that your partners all trust each other. ** Most startups are a slog. Most dont work. Theres a lot of sacrifice and a lot of risk involved. If youre adding to the risk and the stress by working with people you dont trust and believe in, then youre exponentially increasing the probability that youre going to be one of the majority of failures. \\n\\n **Figure out your make or break timing. ** It can be mentally lucrative to think that prosperity is right around the corner. Dont be the Herbert Hoover of your startup. Its much easier to continue to sink time and money into a failure than it is to admit that it didnt work and its time to move on. Set that break point up front and stick to it. Learn your lessons to apply the next time rather than grind yourself into a bankrupt oblivion. \\n\\n Network like your life depended on it. It does. Figuratively. The life of your company certainly does. Unless you happen to be the one in a million viral idea that catches on with the world, youre going to have to go out and find customers. The only way to do that is to pound pavement. The best idea in the world that sits in your head will always have an audience of one. \\n\\n Yes, I was inspired to write this because theres a successful start-up out there which funded itself out of poker winnings, for which I am endlessly jealous, but it also caused me to think about how we ran for a while. If it werent for the things above, we would have been forced to take rash risks which would have most likely ended up with us being a failure and going back to real jobs. \\n', 'excerpt': ' Some deep little part of nearly everyone I know has that inner burning desire to start up their own company. They dont know what they want to do, how theyre going to do it, or even why they want to, but the desire is there. Most of it has to do with the notion of […] \\n', 'post_date': '2007-07-31T00:00:00-0400', 'categories': ['blog', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/07/31/is-poker-the-newest-vc/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/08/09/beware-of-missing-gems-in-rails/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Beware of missing Gems in Rails!', 'url': 'https://opensourceconnections.com/blog/2007/08/09/beware-of-missing-gems-in-rails/', 'author': 'eric-pugh', 'content': ' Ive been getting the incredibly cryptic message undefined method options for []:Array (NoMethodError) from Mongrel on startup when moving from one laptop to another. \\n\\n I googled around, and finally realized that it was due to missing gems. I like to think that this kind of error is just due to Rails immaturity. The Rails community hasnt decided how to manage reusable code. You can either use plugins, gems, or one of the various hybrid tools that make gems into plugins! It does highlight that until we have tools to verify that our dependencies are available, versus blindly throwing a cryptic misleading exception, that the best approach is to “Vender Everything”. \\n\\n Im going to take a stab at putting all our Gems that dont have native code into our /plugins directory, hopefully reducing the amount of hunting around the source to identify what dependencies there are that new folks have to go through. And those that cant go in the /plugins directory I am wrapping in a bit of code to put out a pretty message: \\n\\n \\nbegin\\nrequire `cache\\nrescue RuntimeError\\nraise \"Please install ruby-cache gem\"\\nend\\n \\n\\n Reducing the time it takes for a new developer to get up and running on a project means less frustration, less hand holding, and a better experience for everyone! \\n', 'excerpt': ' Ive been getting the incredibly cryptic message undefined method options for []:Array (NoMethodError) from Mongrel on startup when moving from one laptop to another. I googled around, and finally realized that it was due to missing gems. I like to think that this kind of error is just due to Rails immaturity. The Rails community […] \\n', 'post_date': '2007-08-09T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/08/09/beware-of-missing-gems-in-rails/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/08/16/beware-of-dashes-in-rails-plugin-names/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Beware of – (dashes) in Rails plugin names!', 'url': 'https://opensourceconnections.com/blog/2007/08/16/beware-of-dashes-in-rails-plugin-names/', 'author': 'eric-pugh', 'content': \" Continuing in the vein of my last blog about Beware of Missing Gems in Rails! comes my discovery of – (dashes) being verboten in plugin names. About a month ago I looked at using Selenium On Rails in an app since I liked using it in the first one I worked on. However, I kept getting an error message: \\n\\n The error occurred while evaluating nil.empty? from \\n\\n \\n./script/../config/../vendor/rails/activesupport/lib/active_support/dependencies.rb:202:in 'load_file';\\nfrom ./script/../config/../vendor/rails/activesupport/lib/active_support/dependencies.rb:94:in 'require_or_load';\\n \\n\\n So I gave up, thinking that it was because of some weird interaction with another plugin since I had so many installed for the project. Today I came back to it with a nice simple project, installed things and had the same error! Argh… So I joined the mailing list, looked around and found a post mentioning that in “Edge” Rails, which is now Rails 1.2.3 the name of the plugin needed to be changed from selenium-on-rails to selenium_on_rails! I’;ve looked around at some other plugins and realized that they all use _ characters in the name! transaction_migration, annotate_models etc. \\n\\n Amazing how Rails can make life difficult over the most innocuous things. I am fairly sure this is never an issue in the Java world! Of course, every plugin would be implementing a very complex IDynamicActiveReloadablePlugin interface :) \\n\", 'excerpt': ' Continuing in the vein of my last blog about Beware of Missing Gems in Rails! comes my discovery of – (dashes) being verboten in plugin names. About a month ago I looked at using Selenium On Rails in an app since I liked using it in the first one I worked on. However, I kept […] \\n', 'post_date': '2007-08-16T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/08/16/beware-of-dashes-in-rails-plugin-names/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/08/30/sucking-in-footer-from-remote-sites/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Sucking in the header and footer from a remote site', 'url': 'https://opensourceconnections.com/blog/2007/08/30/sucking-in-footer-from-remote-sites/', 'author': 'eric-pugh', 'content': \" How do you share a common header and footer across multiple apps? For example, you might be prototyping a new app, and want to borrow the main sites header and footer. Obviously you can do crazy stuff like have JavaScript pull something via the client, or maybe have iframes or frames. But what if you have to massage the content as it comes in, maybe only keeping part of it? \\n\\n Well fortunately Ruby on Rails makes that very easy. We simply created a Model object that uses HPricot to pull in remote content and grab the portion we want: \\n\\n ```ruby\\nrequire ‘hpricot&amp;’;\\nrequire ‘open-uri’ \\n\\n class CatalogContent\\ncattr_accessor :remote_url \\n\\n def self.footer\\nurl = remote_url\\nraise “Remote URL was not set” if url.nil? \\n\\n puts “\\\\nPulling remote content footer from #{url}\\\\n” \\n\\n begin\\ndoc = Hpricot(open(url))\\nfooter_content = doc.at(“//div[@id=footer]”)\\nraise “Didn’t find footer content in site #{url}” if footer_content.nil? \\n\\n footer_content \\n\\n rescue Errno::EHOSTUNREACH\\nfooter_content = “Can’t connect to #{url}”\\nrescue Errno::ETIMEDOUT\\nfooter_content = “Can’t connect to #{url}”\\nrescue SocketError\\nfooter_content = “Can’t connect to #{url}”\\nend\\nend\\nend\\n``` \\n\\n In this case we are loading up a website and pulling out the footer section in the HTML. We have the option here while manipulating the HPricot XML DOM to do any other types of changes we want such as: \\n\\n \\n   Remapping URLS \\n   Snipping out bits of content \\n   Changing colors or stylesheet classes \\n   Conditional inclusion of content \\n \\n\\n And then, we have a ApplicationHelper.rb method that creates the model object, populates the remote url and displays it: \\n\\n ruby\\ndef remote_footer\\nCatalogContent.remote_url = AppConfig.catalog_remote_url\\nCatalogContent.footer\\nend\\n \\n\\n Of course, people are going to jump on the fact that this means that every page is making an extra URL call right? Fortunately caching comes to the rescue in our layout: \\n\\n ```ruby \\n \\n  &lt; % cache(:controller=&gt; 'remote_content', :action =&gt; 'remote_footer') do %&gt;  &lt; %= render(:partial=&gt;'/partial/bottom_panel') %&gt;  &lt; % end %&gt;\\n \\n ``` \\n\\n Note, however, we don’t actually have a controller called remote_content with an action called remote_footer, you just have to have those bits so the caching support knows what keys to store the cached content under! Could have been: \\n\\n ruby\\n&lt; % cache(:controller=&gt; 'foo', :action =&gt; 'bar') do %&gt;\\n&lt; %= render(:partial=&gt;'/partial/bottom_panel') %&gt;\\n&lt; % end %&gt;\\n \\n\\n And in our partial we just have: \\n\\n ruby\\n&lt; %= remote_footer %&gt;\\n \\n\\n So, the only downside is that in development we are constantly pulling in the content because the caching is turned off, which slows things down a bit, and that the only way (out of the box) to update the cache is to “sweep” out the contents of the /tmp/cache directory. \\n\\n Also, be aware that if what you are importing has lots of relative paths or references relative JavaScripts and CSS that you are going to have to make those parts work with your app nicely! \\n\", 'excerpt': ' How do you share a common header and footer across multiple apps? For example, you might be prototyping a new app, and want to borrow the main sites header and footer. Obviously you can do crazy stuff like have JavaScript pull something via the client, or maybe have iframes or frames. But what if you […] \\n', 'post_date': '2007-08-30T00:00:00-0400', 'categories': ['blog', 'Code'], 'id': 'https://opensourceconnections.com/blog/2007/08/30/sucking-in-footer-from-remote-sites/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/08/31/charlottesville-needs-more-nerds-part-deux/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Charlottesville Needs More Nerds, Part Deux', 'url': 'https://opensourceconnections.com/blog/2007/08/31/charlottesville-needs-more-nerds-part-deux/', 'author': 'jason-hull', 'content': ' Eric ran into some fellow Darden grads, Adam Healey and Charles Seilheimer yesterday at a local coffee shop because he was lured into a conversation about Ruby, Twitter, and Web 2.0 goodness. The discussion led me to go check out their blog, and I found an excellent article about the ingredients necessary for creating the right environment to foster startups. \\n\\n We run into the same issue that Adam brings up–there are not enough nerds in this area. While we certainly are comfortable leading in a location independent enterprise (the subject of our talk at OSCON 2006), having most of your people co-located does reduce managerial burden on cat herding. Its not quite as easy to have a look over the shoulder to iron out a gnarly coding problem when your team is spread across three continents as it is when youre sitting next to each other in a bullpen. \\n\\n\\n\\n There are other items coming up on the horizon which further point out the need for more nerds (besides the need to keep Charlottesvilles coffee shop economy booming): \\n\\n\\n\\n –The National Ground Intelligence Center is growing. The Global War On Terror is one that focuses on using technology to interdict the bad guys before they can do harmful things to us. The National Ground Intelligence Center is one of the main nexuses of information collection and analysis. Until we beat the bad guys, the NGIC is going to continue to get business, and it needs nerds to help gather that technology. \\n\\n –The Defense Intelligence Agency is coming to Charlottesville. Theyre bringing about 1,000 jobs to the 29 North corridor, and that doesnt include everything needed to support them (like coffee shops). Just like the National Ground Intelligence Center, the Defense Intelligence Agency relies on nerds to make sense of signal intelligence and human intelligence. There are currently not enough nerds to go around. \\n\\n –The surplus of nerds from the Value America days has worked itself through the system. Right after Value America closed shop, the programmers from the company had time on their hands. Many of them started up ventures. However, venture capital money dried up, and they were forced to, for the most part, find “real” jobs. The days when labor was plentiful are no longer in the Charlottesville region because the Value America refugees have become absorbed by the greater economy. \\n\\n –Venture capital deals are on the rise. The number of deals is up, but the average per deal is down. This means that startups have to focus more on delivering the goods and less on the posh offices. In order to make this happen, startups will need good, solid nerds to get to market faster and bring in revenues more quickly. Nice chairs do not bring in revenue. The Virginia Piedmont Technology Council – Charlottesville Venture Group is working with the City of Charlottesville to determine a strategy to bring technology-based businesses into the central Virginia region. Technology companies are not going to want to come to a place where there are not enough workers to fulfill their needs. As it is, existing technology employers who are looking to grow are having significant trouble growing organically with hometown growth. The growth of the contractor community around the National Ground Intelligence Center is being pumped by imported talent with people moving in from the D.C. area rather than with people in Charlottesville. When the Defense Intelligence Agency comes down, it will be the same story. \\n\\n So, how to get more nerds to Charlottesville? Adam touched on one step in his blog article, which was focusing on improving the quality of the engineering school at the University of Virginia. He makes a fine suggestion about making a game-changing move and shelling out millions to bring in the rock star professors to draw more students and improve the quality of output at UVa. While this will work in the long run, it will take time for the trickle down effects to happen. What else can we do? \\n\\n –Give the incubators some teeth. While Charlottesville has incubators such as the Batten Institute and Spinner Technologies, they really dont provide enough of a runway for entrepreneurs to solidify and implement their ideas. Trying to live on a $1,000 a month stipend while slaving away on your laptop for 25 hours a day simply will not cut it in Charlottesville. The cost of living is too high. Not every great nerd has a burning desire to live on ramen and rice cakes for two years while trying to make his great idea a reality. The reality is that great nerds can get jobs which pay them well, and most of those jobs are not in Charlottesville, Virginia. So, in order to draw in the great nerds to the small businesses and the entrepreneurial ventures which will lead to the next big employment opportunities, the incubators have to put significant investment into the worthy incubator seatholders. This is not so that we can pay nerds tidy sums to do nothing. It is so that we can draw in the motivated great nerds who could otherwise go work for Google. Yes, the incubators will have to blur the line between incubator funding, angel funding, and venture capital funding, but otherwise, the good nerds will go elsewhere, and so will the businesses which employ them and many of their friends. \\n\\n –Get the local governments in on the action. Universities and foundations shouldnt be the only ones that are in on the incubator game. The city of Charlottesville, Albemarle county, and the surrounding counties have a vested interest in bringing in more nerds. It seems that most people who are interested in the question would rather have Charlottesville turn into Austin than Aspen, and the governments have to take part in solving that equation. Rather than spending money on Art In Place or on a bus station that takes you nowhere, spend it on things which will breed more employment. If I had $11 million to invest in budding entrepreneurial technology-based companies in Charlottesville, I am willing to bet my mortgage that I could grow jobs in the Charlottesville area and grow the citys base of tax revenue. The local governments in the area need to partner together, because this isnt a matter of divvying the pie; its a matter of growing the pie. A growing company based in Charlottesville will have residents who live in Albemarle, Green, Augusta, and other counties, who will use goods and services in those areas as well.–Look for public-private partnerships. What major corporation wouldnt want to have its name attached to the partnership which spat out the next Google? Furthermore, it would get the benefits of the goodwill associated with bringing in new jobs and philanthropy to the region. Everybody wins. The corporation gets to hand-pick the best nerds for its own ventures and gets the positive press that goes along with a public project. The local community gets more money to fund more ventures which bring in more jobs. \\n\\n –Recruit nerds who live elsewhere. Washington, D.C. is a two hour drive from Charlottesville when the traffic is not abysmally jammed. Naturally, traffic is abysmally jammed all of the time. Nerds (and everyone else) hate traffic jams. Charlottesville does not have them. So, go up to D.C. and talk to the nerds there about the joys and low-stress living that Charlottesville offers. Heres one group and another if you need a start. Were talking to their groups, but we are a drop in the ocean. The incubators and local governments need to wade into the waters. By the way, these nerds who you import can also act as great mentors for the young batch of nerds that we should be growing in the University who came in because of the rock star professors we brought in with the $150 million in allocated funds. \\n\\n –Tax breaks? How about tax credits? The City of Charlottesville is going in the right direction with a 50% tax break for technology-based companies, but its not enough. Offer tax credits instead. Dont worry about losing out on tax revenues, because youll make it up in spades from the knock-on effects of having larger employers in your region because of the incentives you offered for them to take up shop and hire employees here. Its accelerated supply-side economics working for you. If you need more help understanding this, offer to take Dr. Alan Beckenstein out to lunch. Youll get an amazing return on investment for the $10 that you spend feeding him while he enlightens you. \\n\\n –Prime the pump with the Piedmont Virginia Community College. For every great nerd we bring in, we need a couple of worker nerds to implement the supernerds great strategy. Grow those worker nerds in our own back yard as well. These people can continue in their day jobs while they become worker nerds at night. PVCC has repeatedly stated its willingness to increase the number of technology-based classes it offers, so take them up on the offer. PVCC is a great resource for helping get more nerds here, but its an underutilized resource. \\n\\n Growing a nerd population is not going to happen overnight. However, there is still time to start growing that population before the demand spikes, potential employers become frustrated at the lack of supply, and pick up and move elsewhere, leading Charlottesville to become Aspen without the great skiing. Austin did it through both importing the employers and growing them organically, and it had a great educational system at its back pumping out nerds by the bucketload. It offered incentives for companies to take root, and it offered the people to help the companies execute their missions. By combining programs to bring in and grow the nerd population of Charlottesville as well as generating the employment to keep them here instead of watching a mass nerd exodus every May at graduation time, we can build a vibrant technology community. Otherwise, we are always going to be a second-tier player posing as a first-tier location. The saying in Texas is “all hat, no cattle.” Nerds are the cattle that will drive Charlottesvilles 21st century economy and keep it from becoming an exclusive enclave where few can afford to live and jobs are scarce. \\n', 'excerpt': ' Eric ran into some fellow Darden grads, Adam Healey and Charles Seilheimer yesterday at a local coffee shop because he was lured into a conversation about Ruby, Twitter, and Web 2.0 goodness. The discussion led me to go check out their blog, and I found an excellent article about the ingredients necessary for creating the […] \\n', 'post_date': '2007-08-31T00:00:00-0400', 'categories': ['blog', 'Business', 'Opinion'], 'id': 'https://opensourceconnections.com/blog/2007/08/31/charlottesville-needs-more-nerds-part-deux/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/01/javascript-intellisense-documentation-visual-studio-2008-orcas/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Javascript Intellisense, Documentation, &#038; Visual Studio 2008 (Orcas)', 'url': 'https://opensourceconnections.com/blog/2007/09/01/javascript-intellisense-documentation-visual-studio-2008-orcas/', 'author': 'scott-stults', 'content': ' I’ve been working inside the quasi evil yet intriguing world of javascript for the last several weeks due to current projects and the web side of my BHAG project (Amplify.Net framework).  I’ve been rethinking a lot things, including spinning the Javascript into its own opensource project that works with the framework and without the framework.  I’ve also had to ask myself, how do I make this easy for developers to leverage/use? And how do go about streamlining  the documentation process for javascript code. \\n\\n In building this library, since I’m building most of my own controls in order to keep things simple and be able to wire them up to .NET server controls, I’m leveraging the Prototype Library so far, because its not bulky (yet), compared to the Asp.Net Ajax Library.  Also css selectors are not yet available in the Asp.Net Ajax library, but they are planned for a future release. \\n\\n I’ve also have been testing the new Javascript features of Visual Studio 2008 (Orcas). Don’t get me wrong, when I’m working in ruby, I’ve been digging the e-texteditor, which even has some features the mac version does not, like close all tabs and you can shift + tab code instead of shift + [.  However, intellisense is a compelling feature when it comes to speeding up development, also having inline documentation bundled with intellisense is a win/win for developers. \\n\\n\\n\\n Granted, Visual Studio 2008 Beta 2 (Orcas) has improved javascript intellisense, but there are still too many gotchas… \\n\\n Intellisense Gotchas \\n\\n Gotcha 1.) Visual Studio loses intellisense for all scripts if it is unable to parse one.  If you load a script like prototype.js, that doesn’t follow the rules Visual Studio can handle, it kills the intellisense for all other scripts that in the format Visual Studio can handle. ; \\n\\n html\\n&lt;script type=\"text/javascript\" src=\"../javascripts/prototype.js\"&gt;&lt;/script&gt;\\n&lt;script type=\"text/javascript\" src=\"../javascripts/amplify.js\"&gt;&lt;/script&gt;\\n \\n\\n or \\n\\n js\\n/// &lt;reference path=\"prototype.js /&gt;\\n/// &lt;reference path=\"amplify.js /&gt;\\n \\n\\n This is what happens when its working.  \\n\\n This is what happens when you add a good library that Visual Studio can’t figure out.  \\n\\n Gotcha 2.) Visual Studio crashes when you use dojo functions.  If you have a complex library like dojo and you attempt to do something “dojo.style”, this crashes visual studio, possibly due to the fact that the dojo style function does both get and set? or its just too much script in the global namespace for visual studio to handle. \\n\\n Gotcha 3.) Visual Studio is not able to do complex chaining of functions.  I love the inheritance model of Prototype 1.6.0 RC.  When you create a class using prototype, you do some thing like what is shown in the code sample below. Visual Studio doesn’t know what to make of the object “Amplify.MockWidget” and ends up killing any intellisense in the script and in any place you reference the script file would have the following code. You can even add xml comments and put in the type and visual studio isn’t currently smart enough to make light of that. \\n\\n ```js\\n// visual studio can’t make out the object type..\\nvar Amplify.MockWidget = Class.create(Amplify.UI.Control, {\\n  load: function() {\\n    this.element = $(this.element);\\n    this.element.observe(\\n      “click”,\\n      this.onClick.bind(this)\\n    );\\n  }, \\n\\n onClick: function() {\\n    $log(“hello world”);\\n  }\\n}); // should be of type Function, but visual studio does not see that.\\n``` \\n\\n So what you end up having to do is creating classes using the Asp.Net Ajax style of coding, which tends be more verbose (and doesn’t seem as elegant to me). \\n\\n Gotcha 4.) JSON style object declaration breaks intellisense.  Visual Studio Intellisense, won’t allow you to access other properties/methods using the “this” keyword. So if you do the following, Visual Studio will not have the object’s functions/properties listed in the drop-down. So in the Define method below, you will not be able to see _specs when you type this. \\n\\n js\\nvar Specification = function(name, description, functionality) {\\n  this.name = name;\\n  this.description = description;\\n  this.functionality = functionality;\\n}\\nvar Spec = {\\n  _specs: [],\\n  Define: function(specification) {\\n  ///&lt;summary&gt; Defines a new part of the specification &lt;/summary&gt;\\n  ///&lt;param name=\"specification\" type=\"Specification\"&gt; a defined piece of the total spec. &lt;/param&gt;\\n    this._specs.push(specification);\\n  }\\n}\\n \\n\\n Gotcha 5.) Visual Studio Intellisense relies on the Asp.Net Ajax framework concepts for determining object types. So if you want a class to show up as a class, you need to add __class: true or ObjectName.__class = true; or something to that effect for visual studio to recognize the object as a class. So rather than putting that overhead in the scripts, I’m making a second script that has all this type of meta data for intellisense purposes.. \\n\\n Gotcha 6.) Visual Studio finds errors with javascript.  However, because you can’t currently reference a complex javascript file like prototype.js, since it removes all the enhancement of intellisense, Visual Studio finds methods that are not defined that you may use from a library and puts up an error in error panel. It would be nice if Visual Studio would provide a pragma for javascript similar to C#’s pragmas that would allow you to ignore these type of errors. \\n\\n Documentation Gotchas \\n\\n Since the great NDoc is no more due to the evils of developer expectations of the Microsoft world when it comes to open source .net projects, you’re pretty left with SandCastle if you go the route of xml comments. Now if you plan to leverage the intellisense of visual studio, you’re pretty much stuck with xml comments. The only other way around this is use something like Aptana which uses JsDoc style of comments. (the YUI library also uses this format.) However, I find JsDoc style of documents ugly and I want to minimize the burden of tweaking the styled pages not to mention I don’t feel like installing and running active pearl and creating yet another ugly dependency on a project. \\n\\n Gotcha 1.) Parsing XML Comments In Javascript. SandCastle only parses xml documents, it does not go through code and pull out the xml format from the code files such as .js, .cs, .vb files. When you build your dll or exe, thats when visual studio pulls out those xml comments and puts them into one xml file. Right now SandCastle, nor Visual Studio handles parsing xml comments from javascript files. \\n\\n Enter Bertand Le Roy’s Ajax Doc which parses out the xml comments in javascript files and puts them into one xml document. However… this brings up more gotchas. \\n\\n Gotcha 2.) Ajax Doc requires extra dependencies. Ajax Doc uses the Asp.Net Ajax Library, which is an extra dependency on the project, however this Ajax Doc is totally written in Javascript, but requires Internet Explorer, probably for writing the xml file or something to that effect. \\n\\n Gotcha 3.) Ajax Doc relies on Asp.Net Ajax Object Types.  Ajax Doc only documents comments based upon the Asp.Net Ajax Object model. Which means functions who have declared class types of class, interface, enum, etc, are the only ones that get documented. So your classes must have those __class = true;  or __enum = true; defined in your objects otherwise the Ajax Doc will skip your objects. \\n\\n Gotcha 4.) Ajax Doc relies on the inheritance model of the Asp.Net Ajax library. This means that if you are using libraries like the new Prototype 1.6.0 RC, which has inheritance, Ajax Doc is not smart enough to be able to parse that inheritance model out to put into the xml comments file. \\n\\n Gotcha 5.) Ajax Doc has limited tag parsing.  Tags like &lt;remarks&gt; are not included, in fact the only thing it really handles at this point is on Bertand’s posting on Javascript xml comments. \\n\\n In closing, I’m still digging the fact that the visual studio team is putting in better intellisense for javascript, however, I’m hoping one of them reads this in order to provide better support for javascript overall, since the style of javascript is so diverse. Even if you have rely on documenting your scripts to allow for this, I think this would push well documented libraries to evolve, rather than obscure scripts that are impossible to read. \\n\\n track17 Naruto Bad Situation \\n\\n', 'excerpt': ' I’ve been working inside the quasi evil yet intriguing world of javascript for the last several weeks due to current projects and the web side of my BHAG project (Amplify.Net framework).  I’ve been rethinking a lot things, including spinning the Javascript into its own open source project that works with the framework and without the framework.  […] \\n', 'post_date': '2007-09-01T00:00:00-0400', 'categories': ['blog', 'solr'], 'id': 'https://opensourceconnections.com/blog/2007/09/01/javascript-intellisense-documentation-visual-studio-2008-orcas/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/07/eric-pugh-will-be-presenting-at-cvreg-sept-11th/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric Pugh will be presenting at CVREG Sept 11th', 'url': 'https://opensourceconnections.com/blog/2007/09/07/eric-pugh-will-be-presenting-at-cvreg-sept-11th/', 'author': 'eric-pugh', 'content': ' Ill be at the CVREG next week talking about Lego Mindstorms and Ruby. Ill be demoing the acts-as-nxt plugin providing an interface between a Ruby on Rails app and a Lego robot!. As Mel Riffe puts it “ROBOTS!” \\n\\n We are participating in this weekends Rails Rumble contest, so Ill be giving a recap of that! \\n\\n More details are on Upcoming. \\n', 'excerpt': ' Ill be at the CVREG next week talking about Lego Mindstorms and Ruby. Ill be demoing the acts-as-nxt plugin providing an interface between a Ruby on Rails app and a Lego robot!. As Mel Riffe puts it “ROBOTS!” We are participating in this weekends Rails Rumble contest, so Ill be giving a recap of that! […] \\n', 'post_date': '2007-09-07T00:00:00-0400', 'categories': ['blog', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2007/09/07/eric-pugh-will-be-presenting-at-cvreg-sept-11th/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/09/lets-get-ready-to-rumble/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Let’s Get Ready to Rumble!!!!', 'url': 'https://opensourceconnections.com/blog/2007/09/09/lets-get-ready-to-rumble/', 'author': 'jason-hull', 'content': ' Three of our team members, Eric Pugh, Michael Herndon, and Jim Nist, along with Ashish Tonse from Booz Allen Hamilton, are currently in the midst of throwing together last-minute fixes and tweaks for our entry in the Rails Rumble 2007 contest. \\n\\n On Wednesday Thursday, voting will begin, and at that time, well unveil our ultra-cool application. For now, sign up to be a judge for the Rumble so that you can let the world know what you think about our application when we make the unveiling. \\n\\n Cant wait? Come to the Neon Guild meeting Monday, September 10, 2007 at 6:00 in the Inova building and get a sneak peek. \\n\\n  \\n\\n', 'excerpt': ' Three of our team members, Eric Pugh, Michael Herndon, and Jim Nist, along with Ashish Tonse from Booz Allen Hamilton, are currently in the midst of throwing together last-minute fixes and tweaks for our entry in the Rails Rumble 2007 contest. On Wednesday Thursday, voting will begin, and at that time, well unveil our ultra-cool […] \\n', 'post_date': '2007-09-09T00:00:00-0400', 'categories': ['blog', 'Code', 'Ruby'], 'id': 'https://opensourceconnections.com/blog/2007/09/09/lets-get-ready-to-rumble/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/12/agile-open-california-oct-23-24/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Agile Open California Oct 23-24', 'url': 'https://opensourceconnections.com/blog/2007/09/12/agile-open-california-oct-23-24/', 'author': 'eric-pugh', 'content': ' Looking for a great Open Spaces format conference? Agile Open California in San Francisco may be right up your alley! I first heard about this conference from Vandana Shah of Agitar during CITCon this past year. Vendana is leader in implementing better software development practices, and is one of the hosts for Agile Open California. People like her are sure to attract really interesting participants, and make this an exceptional conference. The conference should stay small and intimate since the size is capped at 100 people. I would be there except for the impending arrival of my son on October 23rd! \\n\\n The website is at http://www.agileopencalifornia.com/ and there is some signup information at Upcoming.org. \\n\\n Oh, and if the content isnt enough to make you go, it is taking place at Ft Mason in the Golden Gate National Park! \\n\\n', 'excerpt': ' Looking for a great Open Spaces format conference? Agile Open California in San Francisco may be right up your alley! I first heard about this conference from Vandana Shah of Agitar during CITCon this past year. Vendana is leader in implementing better software development practices, and is one of the hosts for Agile Open California. […] \\n', 'post_date': '2007-09-12T00:00:00-0400', 'categories': ['blog', 'Conference'], 'id': 'https://opensourceconnections.com/blog/2007/09/12/agile-open-california-oct-23-24/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/14/fish4brains/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Fish4Brains', 'url': 'https://opensourceconnections.com/blog/2007/09/14/fish4brains/', 'author': 'jason-hull', 'content': ' We demonstrated Fish4Brains at the Neon Guild meeting on Monday. The voting on the Rails Rumble website is now live. For those of you who were not at the Neon Guild meeting, the Rails Rumble was a contest where 150 teams of 1-4 developers had 48 hours to create a Ruby on Rails application. 48 hours and 238,053 lines of code later, Fish4Brains was born. \\n\\n Wed appreciate it if you could go to our website at http://www.fish4brains.com and take a look at our fish and vote on it. Also, if you want to provide feedback on what youd like to see in the updated version, you can send a note to fish@opensourceconnections.com. \\n\\n Thanks, and have fun fishing! \\n', 'excerpt': ' We demonstrated Fish4Brains at the Neon Guild meeting on Monday. The voting on the Rails Rumble website is now live. For those of you who were not at the Neon Guild meeting, the Rails Rumble was a contest where 150 teams of 1-4 developers had 48 hours to create a Ruby on Rails application. 48 […] \\n', 'post_date': '2007-09-14T00:00:00-0400', 'categories': ['blog', 'Code', 'Ruby'], 'id': 'https://opensourceconnections.com/blog/2007/09/14/fish4brains/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/09/21/saic-and-the-armys-pathfinder-intelligence-application/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'SAIC and the Armys Pathfinder Intelligence Application', 'url': 'https://opensourceconnections.com/blog/2007/09/21/saic-and-the-armys-pathfinder-intelligence-application/', 'author': 'scott-stults', 'content': ' \\n  SAIC has been a leading developer of intelligence analysis software for decades. In fact, their Pathfinder application has seen continual usage at a variety of agencies since the early 90s. It has been periodically updated with newer and better technologies as they emerged, and OpenSource Connections was an integral part of one of these latest efforts. Over the course of fourteen months, across two project teams, we helped update both the front and back ends of the application.\\n \\n\\n \\n  The front-end team improved the search functionality by developing a .Net / Service Oriented Architecture-based user interface. To ease the transition to the new interface, old views were ported, and new views were built to maximize the new capabilities, including toolbars, applets, plug-ins etc. The updated interface decreased the technical-know-how required of the analysts performing the queries, thereby allowing them to focus on the information related to the search rather than on the technical parameters required to perform the search.\\n \\n\\n \\n  For full-text searching, the open source Lucene project has singled itself out as an invaluable tool. Its speed and accuracy are second to none. It is also documented to work well with a variety of programming languages, which grants it greater future flexibility. SAIC had previously integrated it into Pathfinder by enhancing its query language and plugging it into their data feeds, but the new implementation needed to be tied directly to the central Oracle database.\\n \\n\\n \\n  To accomplish this, the back-end team indexed the text with Lucene, but only stored the record identity in the index. Searching would take place completely within Lucene, but whenever the actual text was called for it would be retrieved from Oracle. Since the database was already integrated into a great number of data feeds, this instantly added them to Pathfinder and allowed it to leverage the data access security protocols already in place.  This solution not only saves the client money in its lack of licensing fees but offers better forward compatibility.\\n \\n\\n \\n  Finally, we deployed Xen virtualization software for use by both teams as a development and testing platform. This saved additional dollars by effectively turning two servers into twenty and allowed the teams to quickly create whatever server environment their task called for.\\n \\n', 'excerpt': ' SAIC has been a leading developer of intelligence analysis software for decades. In fact, their Pathfinder application has seen continual usage at a variety of agencies since the early 90s. It has been periodically updated with newer and better technologies as they emerged, and OpenSource Connections was an integral part of one of these latest […] \\n', 'post_date': '2007-09-21T00:00:00-0400', 'categories': ['blog', 'Case Study'], 'id': 'https://opensourceconnections.com/blog/2007/09/21/saic-and-the-armys-pathfinder-intelligence-application/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/10/02/mitre-healthstoriesorg/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'MITRE&#8211;Healthstories.org', 'url': 'https://opensourceconnections.com/blog/2007/10/02/mitre-healthstoriesorg/', 'author': 'riley-wolfe', 'content': ' To address the growing attention on healthcare, the MITRE FFRDC in Bedford, Massachusetts engaged OpenSource Connections to build a website that would facilitate the exchange of patient health care experiences.  Healthstories.org was born. The website also allows medical professionals to share their experiences.  The ultimate goal of the site is to help identify challenges in the current health system. \\n  \\n', 'excerpt': ' To address the growing attention on healthcare, the MITRE FFRDC in Bedford, Massachusetts engaged OpenSource Connections to build a website that would facilitate the exchange of patient health care experiences. Healthstories.org was born. The website also allows medical professionals to share their experiences. The ultimate goal of the site is to help identify challenges in […] \\n', 'post_date': '2007-10-02T00:00:00-0400', 'categories': ['blog'], 'id': 'https://opensourceconnections.com/blog/2007/10/02/mitre-healthstoriesorg/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/10/03/eric-pugh-presents-to-rubyjam/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Eric Pugh presents to RubyJam', 'url': 'https://opensourceconnections.com/blog/2007/10/03/eric-pugh-presents-to-rubyjam/', 'author': 'eric-pugh', 'content': ' October 10th at 6 PM Eric Pugh will be presenting to the RubyCodeJam group some cool hackery with of Ruby and Lego Mindstorms, as well as share some lessons in using BackgroundRB with Rails. \\n\\n', 'excerpt': ' October 10th at 6 PM Eric Pugh will be presenting to the RubyCodeJam group some cool hackery with of Ruby and Lego Mindstorms, as well as share some lessons in using BackgroundRB with Rails. \\n', 'post_date': '2007-10-03T00:00:00-0400', 'categories': ['blog', 'News', 'Speaking'], 'id': 'https://opensourceconnections.com/blog/2007/10/03/eric-pugh-presents-to-rubyjam/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/10/04/is-cmmi-overrated/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Is CMMI Overrated?', 'url': 'https://opensourceconnections.com/blog/2007/10/04/is-cmmi-overrated/', 'author': 'jason-hull', 'content': ' We are not a CMMI rated company. As a small business, we think it is more important to focus on delivering excellence for our customers and growing top and bottom line numbers than being able to check certain boxes about whether or not we have a laundry list of processes documented and implemented. The causation seems to be backwards. We do things which please our customers. Our customers are pleased; therefore, we seem to be doing the right thing, QED. Having a CMMI certification does not guarantee anyone that we will perform in a manner which will satisfy our customers, only that we will perform in a manner which will ensure we can check boxes. \\n\\n What is CMMI, you ask? According to the Carnegie Mellon Software Engineering Institute CMMI page: \\n\\n “Capability Maturity Model® Integration (CMMI) is a process improvement approach that provides organizations with the essential elements of effective processes. It can be used to guide process improvement across a project, a division, or an entire organization. CMMI helps integrate traditionally separate organizational functions, set process improvement goals and priorities, provide guidance for quality processes, and provide a point of reference for appraising current processes.” \\n\\n A sample of the 23 different areas that CMMI measures includes (quoted from the CMMI v 1.2 manual): \\n\\n \\n  \\n\\n  · Causal Analysis and Resolution (CAR)\\n \\n\\n \\n  \\n\\n  · Configuration Management (CM)\\n \\n\\n \\n  \\n\\n  · Decision Analysis and Resolution (DAR)\\n \\n\\n \\n  \\n\\n  · Integrated Project Management +IPPD (IPM+IPPD)\\n\\n  \\n\\n  [1]\\n \\n\\n \\n  \\n\\n  · Measurement and Analysis (MA)\\n \\n\\n \\n  \\n\\n  · Organizational Innovation and Deployment (OID)\\n \\n\\n \\n  \\n\\n  · Organizational Process Definition +IPPD (OPD+IPPD)\\n \\n\\n \\n  \\n\\n  · Organizational Process Focus (OPF)\\n \\n\\n \\n  \\n\\n  · Organizational Process Performance (OPP)\\n \\n\\n \\n  \\n\\n  · Organizational Training (OT)\\n \\n\\n   For an organization which is not delivering the intended results to its customers, revising and revamping the processes is a good thing. I by no means wish to say that I do not believe in process. Process, within reasonable limits, is good. We are proponents of Agile Development processes. With a complete lack of process, a project will end up with variable timelines, bugs, few (if any) test, and, most likely, a product that suits the developers needs rather than the customers needs. \\n\\n To me, the question is how many companies who are CMMI-X level certified companies actually implement the CMMI processes fully rather than just showing the process in a project in order to get the certification? As Dr. Rick Hefner states (p.7), “A CMMI appraisal indicates the organization€™s capacity to perform the next project, but cannot guarantee that each new project will perform in that way.” \\n\\n According to this Washington Technology article, the trend in government contracting is to mandate CMMI maturity levels. So, government contractors who wish to do more business with the government look to get CMMI certified so that they can win more contracts. The government thinks that enforcing certain process standards will yield more predictability in results. \\n\\n Yet, this does not always happen. Government contracting officers and IT managers with whom I have spoken complain that CMMI level 4 and 5 companies are consistently delivering poor code bases, usually over budget (and/or late), and often full of critical bugs that are introduced into live environments. \\n\\n Where is the disconnect, then? It happens from both sides. \\n\\n Providers: \\n\\n \\n   Focus on the customer: The prettiest code or the coolest algorithm is worthless if it does not deliver what the customer wants. The scrum master and the development team should be in harmony with the product owner and business customer (if they are not the same person) in terms of vision and outcomes. \\n   Test, test, test: Code should not be released into a live environment unless it is unit tested, string tested, integration tested, and user tested. Fixing the nth incremental bug at a negative marginal utility cost is not the goal. Catching the critical bugs early is the goal. If the team focuses on test-driven development, then they will eliminate much of the overhead necessary to deliver working products at the end of the project. \\n   Prototype early: By developing form and function prototypes, the development team can give the customer an idea of what is going to be delivered, and the customer can provide intervening feedback to keep the development team pointed in the right direction. Prototyping reduces the amount of intent interpretation necessary, as the customer gets to see what the results will look like rather than hoping that the development team can divine intent. \\n   Dont drown in unnecessary documentation: Each report that the team has to deliver reduces the amount of time that the team can spend coding. Stick to burndown charts and product backlogs as much as possible. Scrum masters should push back where possible on excess reporting. Providing periodic performance updates is appropriate; crafting 800 page requirements documents is rarely so. Dont shirk from documenting code, though. Someone has to figure out what the team did long after the team is gone. \\n \\n\\n Customers: \\n\\n \\n   CMMI certification is not a magic bullet: Dont expect that just because a company has a CMMI certification, theyre going to magically deliver under budget, early, and with more scope than you thought. Expect the appropriate amount of coding rigor to deliver on what you need. Ask where the code tests are. Demand prototypes. Own the product backlog. \\n   Keep a gentle, guiding hand on the team, not an oppressing fist: Just as not enough oversight ruins the outcome, so does micromanagement. Expecting TPS reports every week means that youre going to have a team focused on filling out satisfactory paperwork rather than delivering outstanding code. Give guidance, vision, and direction; expect rigor, and get out of the way. \\n   Provide performance-based incentives: Periodic payments should keep the lights on with your provider. All of the profit should come at the end when the product delivers what it is supposed to, on time, and meeting the customers intent. Hourly fees are an invitation to print money. Even if the long-term total cost is unknown, set up per sprint requirements and hourly estimates and then hold the provider to those. For example, for a 3 year project, set up monthly (or whatever appropriate interval) sprints and get agreement on sprint deliveries and cost for each sprint, while holding out a percentage of the overall compensation to the end of the project contingent upon mutually agreed upon final deliverables. If those need to change, then negotiate the deliverables through the course of the project. \\n   Look at other customers besides those provided by the contractor in the proposal: Requests for proposal are inherently subject to selection bias. As a contractor and proposal provider, we are going to pick our 3 happiest customers and provide them to the requestor. Look deeper into the picture and see if all of the stories are the same. Request a dissatisfied customer in the proposal and dig into why the customer was dissatisfied. Nobody (not even us) has no unhappy customers. Everyone makes mistakes. Find out if the mistakes are systemic or have been corrected before jumping into the long-term relationship. \\n   Try before you buy: Do small contracts at first. Build the relationship and the rapport with the potential provider. See if the product is as good as the promise that came in the proposal. \\n   Dont be afraid to switch providers: Go with your hunches. If things seem to be going off course, then they probably are. Look at what youve spent as a sunk cost and move on and find the right solution. Staying in a bad marriage is not the answer in life, and its not the answer in business. \\n \\n\\n In Malcom Gladwells book Blink, he relates the story of a Pentagon exercise conducted in 2002 called Millenium Challenge. The Blue team, the Allies, were to go against the Red team, a Middle Eastern dictatorship. The Blue team, with its superior information, and its abundance of processes, was supposed to destroy the Red team. What they failed to account for is how their processes got in the way of actually doing anything, and while they were busy writing reports and doing prediction scenarios, LTG Paul van Ripers Red team was actually doing things. They were agile. The Blue team was process-obsessed and process-drowned, and they lost. Streamlined processes work. Process for the sake of process makes a team focus only on the process and not on the outcome. \\n\\n So, having a CMMI certification may be good, but only if done in synch with an organizational focus on serving the customer in the most efficient manner possible. Having a CMMI certification only to check a box or to make sure that boxes are being checked during a project so that the project lead can cover his or her tracks is not. Id rather focus on the customer and getting things right and delivering a solid product. If it means that somewhere along the way, we find that we could be CMMI certified because of the way we do business, then so be it. After all, as Jim Nist pointed out to me, software development is hard. \\n', 'excerpt': ' We are not a CMMI rated company. As a small business, we think it is more important to focus on delivering excellence for our customers and growing top and bottom line numbers than being able to check certain boxes about whether or not we have a laundry list of processes documented and implemented. The causation […] \\n', 'post_date': '2007-10-04T00:00:00-0400', 'categories': ['blog', 'Opinion', 'Productivity', 'Project Management', 'scrum'], 'id': 'https://opensourceconnections.com/blog/2007/10/04/is-cmmi-overrated/'}}}, {'index': {'_index': 'blog', '_type': 'movie', '_id': 'https://opensourceconnections.com/blog/2007/10/06/installing-rmagick-on-windows-using-ruby-186/', 'status': 400, 'error': {'type': 'illegal_argument_exception', 'reason': 'Rejecting mapping update to [blog] as the final mapping would have more than 1 type: [post, movie]'}, 'data': {'title': 'Installing Rmagick on Windows Using Ruby 1.8.6', 'url': 'https://opensourceconnections.com/blog/2007/10/06/installing-rmagick-on-windows-using-ruby-186/', 'author': 'scott-stults', 'content': ' Rmagick tends to be tricky to install, but on windows its relatively simple, except for the fact that if you freshly installed ruby 1.8.6, ruby gems needs to be updated. If you install ruby 1.8.6 and then go to ruby.forge and download rmagick for windows. Extract the zip folder, run the .exe, then open a command line, cd (change directory) to the install folder and do â€œgem install rmagick â€”localâ€�. The first time you do this, you might run into the â€œError installing gem RMagick (version) .gem[.gem]: buffer errorâ€�. To fix that run â€œgem update â€”systemâ€� with double hyphens and then run â€œgem install rmagick â€”localâ€� and everything should now install fine. \\n\\n \\n  currently listening to.. Chevelle Vena Sera Brainiac \\n \\n\\n \\n  Tags: ruby, ruby+1.8.6, windows, rmagick, gems\\n \\n\\n', 'excerpt': ' Rmagick tends to be tricky to install, but on windows its relatively simple, except for the fact that if you freshly installed ruby 1.8.6, ruby gems needs to be updated. If you install ruby 1.8.6 and then go to ruby.forge and download rmagick for windows. Extract the zip folder, run the .exe, then open a […] \\n', 'post_date': '2007-10-06T00:00:00-0400', 'categories': ['blog', 'solr'], 'id': 'https://opensourceconnections.com/blog/2007/10/06/installing-rmagick-on-windows-using-ruby-186/'}}}])"
     ]
    }
   ],
   "source": [
    "from ltr.index import rebuild\n",
    "rebuild(client, index='blog', doc_src=articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
